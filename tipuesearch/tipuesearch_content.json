{"pages":[{"title":"Leetcode 169. Majority Element","url":"/2019/04/16/leetcode-169-majority-element/","text":"题意找出数组中出现次数超过数组长度一半的那个元素。 题目来源：https://leetcode.com/problems/majority-element/ 标记难度：Easy 提交次数：1/1 代码效率：20.20% 分析哈希表，键存储元素，值存储个数，值大于数组长度 1/2 就返回。 代码1234567891011121314151617class Solution &#123; public int majorityElement(int[] nums) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); int ret = 0; for(int num : nums )&#123; if(!map.containsKey(num))&#123; map.put(num,1); &#125;else &#123; map.put(num,map.get(num)+1); &#125; if(map.get(num) &gt; nums.length/2)&#123; ret = num; &#125; &#125; return ret; &#125;&#125;","tags":"algorithms leetcode"},{"title":"IPA Sounds And Exmaples","url":"/2019/04/07/phonetic-alphabet/","text":"Examples of IPA use in common English words.List of challenging English sounds and words especially for Chinese people. Diphthong VowelsThe key is to pronounce two symbols clearly IPA Symbol Word examples remark aʊ Mouth, house, brown, cow, out, downtown əʊ No, don’t, stones, alone, hole, ghost eɪ Face, space, rain , case, eight, name two symbols aɪ My, sight, pride, kind, flight, time ɔɪ Joy, employ, toy, coil, oyster, point, coin ʊə lure, tour eə Hair, there, care, stairs, pear, fair, stare tongue back enough Short Vowels Or Single Vowels IPA Symbol Word examples remark æ Cat, hand, nap, flat, have, apple tongue back enough e Went, intend, send, letter, bed, step ʌ Fun, love, money, one, London, come, hungry, but ɒ Rob, top, watch, squat, sausage, job ə Alive, again, mother, toward, banana ʊ Put, look, should, cook, book, look, good ɪ city, skin, kill, sit expand mouth Long Vowels IPA Symbol Word examples remark ɑ: Fast, car, hard, bath, garden, park ɔ: Talk, law, bored, yawn, jaw, soft, loft tongue back enough ɜ: Nurse, heard, third, turn, earth, earn u: Few, boot, lose, gloomy, fruit, chew, do i: Need, beat, team, me, keen expand mouth Consonants Sounds IPA Symbol Word examples remark l large, milk, pill, chill, melt Approximants / tongue touch teeth m Room, mother, mad, more Nasals n Now, nobody, knew, turn Nasals ŋ King, thing, song, swimming, long, rank tongue touch roof of back mouth θ Thank, Think, Bath, Mouth ð There, those, brothers, others s snake, sense expand mouth z Zoo, crazy, lazy, zigzag, nose, close ts treats, tweets dz ends, bends, friends f Full, Friday, fish, knife, fair, fine v Vest, village, view, cave, live, very k Cash, quick, cricket, sock, kind, clock g Girl, green, grass, flag, great, egg t Time, train, tow, late, tour d Door, day, drive, down, feed, dog p Pin, cap, purpose, pause, pet b Bag, bubble, build, robe, bus ʈʃ Choose, cheese, church, watch, chance dʒ Joy, juggle, juice, stage, jar ʃ Shirt, rush, shop, cash, shut, shall ʒ Television, delusion, casual, leisure tr trend, treasure dr drive, dry h High, help, hello, have r Road, roses, river, ring, ride, rare, rest w Wall, walk, wine, world, where, what j Yellow, usual, yield, yesterday, yard.","tags":"international-phonetic-alphabet ipa pronunciation"},{"title":"Notes on Network Protocol Https","url":"/2019/04/06/notes-on-network-protocol-https/","text":"Https 总结 from 极客时间 - 趣谈网络协议","tags":"network 网络协议"},{"title":"Binary tree B tree B+ Tree","url":"/2019/04/04/binary-tree-B-tree/","text":"平衡二叉树、B树、B+树、B*树 平衡二叉树概念平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构 特点平衡二叉树是采用二分法思维把数据按规则组装成一个树形结构的数据，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度；平衡二叉树的数据结构组装过程有以下规则： 非叶子节点只能允许最多两个子节点存在 每一个非叶子节点数据分布规则为左边的子节点小当前节点的值，右边的子节点大于当前节点的值(这里值是基于自己的算法规则而定的，比如hash值) 平衡树的层级结构：因为平衡二叉树查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如AVL、Treap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1.，通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找； 总结平衡二叉树特点： 非叶子节点最多拥有两个子节点 非叶子节值大于左边子节点、小于右边子节点 树的左右两边的层级数相差不会大于1 没有值相等重复的节点 B树(B-tree)注意:之前有看到有很多文章把B树和B-tree理解成了两种不同类别的树，其实这两个是同一种树 概念B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构，让我们来看看他有什么特点; 规则 排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则 节点数：非叶节点的子节点数&gt;1，且&lt;=M ，且M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉） 关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2) 所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子 最后我们用一个图和一个实际的例子来理解B树（这里为了理解方便我就直接用实际字母的大小来排列C&gt;B&gt;A） B树的查询流程如上图我要从上图中找到E字母，查找流程如下 获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点） 拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点 拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null） B树的插入节点流程定义一个5阶树（平衡5路查找树;），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来 遵循规则 节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分） 排序规则：满足节点本身比左边节点大，比右边节点小的排序规则 先插入 3、8、31、11 再插入23、29 再插入50、28 B树节点的删除规则 节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并） 满足节点本身比左边节点大，比右边节点小的排序规则 关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放 特点 B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度 B+ 树概念 B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；我们先看看两者的区别 规则 B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加 B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样 B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针 非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现） （百度百科算法结构示意图） （维基百科算法结构示意图） 特点 B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快 B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定 B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快 B*树规则B*树是B+树的变种，相对于B+树他们的不同之处如下： 首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b树的初始化个数为（cei(2/3m)） B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来 特点在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少 总结 相同思想和策略 从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度 不同的方式的磁盘空间利用 不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的 文章转载自 https://zhuanlan.zhihu.com/p/27700617 参考 附（二分法查找）：二分法查找原理 - 知乎专栏 附（B、B+、B* 树）：从 B 树、B+ 树谈到 R 树 附（B、B+、B* 树）：end’s coding life 附： B 树和 B+ 树的插入、删除图文详解 - nullzx - 博客园","tags":"algorithms 数据结构与算法 tree 树"},{"title":"Notes on Network Protocol Http","url":"/2019/04/03/notes-on-network-protocol-http/","text":"Http 总结 from 极客时间 - 趣谈网络协议 HTTP 请求的准备 DNS解析IP HTTP基于TCP, 首先建立TCP链接 现在默认是1.1协议, 默认是开启了Keep-Alive, 多次请求中复用 HTTP 请求的构建 请求行 Request URL Request Method Version 请求首部key value, 用冒号分隔. Accapt-Charset表示客户端可以接受的字符集 Content-Type正文的格式 HTTP 请求的发送 基于TCP协议的, 使用面向连接的方式发送请求, 通过stream二进制流的方式传给对方. 同一个网段 IP层-&gt;ARP获取目标地址MAC, 添加MAC头(源和目标), 发送出去 不在同一个网段 IP层-&gt;ARP获取网关的MAC, 然后发送 HTTP 返回的构建 浏览器作为客户端也在监听某个进程. HTTP 2.0 对HTTP的头进行一定的压缩, 将原来每次都要携带的大量key value在两端监理一个索引表, 对相同的头只发送索引表中的索引 将一个TCP链接切分成多个流, 流是有优先级的. 流是双向的, 可以是客户端给服务端, 也可以是服务端给客户端. 一个TCP链接里面 帧 Header帧, 传输Header内容 Data帧, 传输正文实体 可以将多个请求分到不同的流中, 然后将请求内容拆成帧, 进行二进制传输. 这些帧可以打散乱序发送, 然后根据每个帧首部的流标识符重新组装, 并且可以根据优先级, 决定优先处理哪个流的数据. 左是HTTP 1.1, 串行请求 右是HTTP 2.0, 同时发送多个请求和回应 将三个请求变成三个流, 将数据分成帧, 乱序发送到一个TCP连接中 总结 2.0解决了1.1的队首阻塞问题, 同时, 也不需要通过HTTP 1.x的pipeline机制用多条TCP链接来实现并行请求与相应 减少了TCP连接数对服务器性能的影响, 将多个数据如css, js, jpg等通过一个数据链接进行传输 QUIC 协议from google TCP 协议在处理包时是有严格顺序的. 当其中一个数据包遇到问题, TCP 连接需要等待这个包完成重传. 虽然 HTTP 2.0 通过多个 stream, 使得逻辑上一个 TCP 连接上的并行内容, 进行多路数据的传输, 然而这中间并没有关联的数据. 一前一后, 前面 stream 2的帧没有收到, 后面stream 1的帧也会因此阻塞. TCP切换到UDP就是QUIC协议. 机制一: 自定义连接机制TCP中的 源 IP，源端口，目的 IP，目的端口 一个发生变化( 比如 wifi, 手机信号不稳 ), 就需要断开重连. 在进行三次握手。 UDP用一个64位速记数作为ID标识, UDP是无连接的. 只要ID不变, 就不需要重新建立连接. 机制二: 自定义重传机制TCP为保证可靠性, 使用序号和应答机制, 解决顺序问题和丢包问题. TCP如果发送100两次(因为第一次没有返回), 这时候返回一个ACK 101, 代表客户端收到了. 这个RTT(采样往返时间)ACK是根据那次的发送计算. 采样不准确 QUIC通过序列号递增+offset 发送100, 下次重发会递增序号101. 这样ACK返回就知道对应哪个了, 采样会准确 通过offset来判断100和101是不是同样的内容. 通过offset拼接成一个流 机制三: 无阻塞的多路复用 QUIC是基于UDP的, 一个连接上的多个stream之间没有依赖. 假如 stream2 丢了一个 UDP 包, 后面跟着 stream3 的一个 UDP 包, 虽然 stream2 的那个包需要重传,但是 stream3 的包无需等待, 就可以发给用户. 机制四: 自定义流量控制TCP流量控制是通过滑动窗口协议. QUIC是通过window_update, 来告诉对端它可以接受的字节数, 适应多路复用机制. 可以在一个连接上控制窗口. 在一个连接中的每个stream控制窗口. 在 TCP 协议中, 接收端的窗口的起始点是下一个要接收并且 ACK 的包, 即便后来的包都到了, 放在缓存里面, 窗口也不能右移, 因为 TCP 的 ACK 机制是基于序列号的累计应答, 一旦 ACK 了一个系列号, 就说明前面的都到了, 所以只要前面的没到, 后面的到了也不能 ACK, 就会导致后面的到了, 也有可能超时重传, 浪费带宽。 QUIC 的 ACK 是基于 offset 的, 每个 offset 的包来了, 进了缓存, 就可以应答, 应答后就不会重发, 中间的空挡会等待到来或者重发即可, 而窗口的起始位置为当前收到的最大 offset, 从这个 offset 到当前的 stream 所能容纳的最大缓存, 是真正的窗口大小。显然, 这样更加准确.","tags":"network 网络协议"},{"title":"Notes On Network Protocol Socket","url":"/2019/04/01/notes-on-network-protocol-socket/","text":"Socket 总结 from 极客时间 - 趣谈网络协议 Talk is cheap, show me the code Socket 编程基于TCP和UDP协议。 可以理解为，弄一根网线，一头插在客户端，一头插在服务端，然后进行通信。在通信之前，双方都要建立一个socket。 socket 参数能够设置的参数, 也只能是端到端协议之上网络层和传输层的。 AF_INET: IPv4 AF_INET6: IPv6 TCP: SOCK_STREAM( 数据流 ) UDP: SOCK_DGRAM( 数据报 ) 基于 TCP 协议IDE Socket 程序函数调用过程 服务端 TCP 的服务端要先监听一个端口, 调用bind函数, 给这个 Socket 赋予一个 IP 地址和端口 端口: 通过端口找到应用程序 IP: 可能有多个网卡（只有发给这个网卡的包才会给你) 调用listen函数进行监听, 即是TCP的状态图里面的listen状态 内核中, 为每个Socket维护两个队列 一个是已经建立了连接的队列, 这时候连接三次握手已经完毕, 处于established状态 一个是还没有完全建立连接的队列, 三次握手还没完成, 处于syn_rcvd状态 调用 accept 函数, 拿出一个已经完成的连接进行处理. 如果没有完成, 等待 客户端 调用 connect 函数发起连接(三次握手 IP 地址 端口号 内核会给客户端分配一个临时的端口 握手成功, 服务端的 accept 就会返回另一个 Socket 两个 Socket 知识点：监听的Socket和真正用来传数据的Socket是两个不同的 Socket。 监听Socket 已连接Socket 连接成功后双方通过 read 和 write 函数来读写数据, 就像往一个文件流里面写东西一样 Socket 函数调用过程 Socket 在 Linux 中就是以文件形式存在的. 在内核中,Socket 是一个文件,那对应就有文件描述符. 每一个进程都有一个数据结构 task_struct, 里面指向一个文件描述符数组, 来列出这个进程打开的所有文件的文件描述符. 文件描述符是一个整数, 是这个数组的下标. 这个数组中的内容(下标是文件描述符)是一个指针, 指向内核中所有打开的文件的列表. Socket 对应的 inode 不像真正的文件系统一样, 保存在硬盘上的, 而是在内存中的(叫做in-core inode). 在这个 inode 中, 指向了Socket在内核中的 Socket结构. Socket 结构 发送队列 接收队列 两个队列保存的是一个缓存sk_buff. 这个缓存里面能够看到完整的包的结构. 基于 UDP 协议的 Socket 程序函数调用过程UDP没有连接的, 不需要调用listen和connect. UDP仍然需要IP和端口号, 所以需要bind. UDP是没有维护连接状态的, 不需要没对连接建立一组Socket, 而是只要有一个Socket, 就能够和客户端通信. 因为没有连接状态, 每次通信的时候, 都调用sento 和 recvfrom, 都可以传入IP地址和端口号. 服务器如何提高连接并发数最大连接数四元组来标识一个 TCP 连接. 1&#123;本机 IP, 本机端口, 对端 IP, 对端端口&#125; 服务端可以一个端口来监听，只有客户端IP和客户端端口是可变的. 最大 TCP 连接数 = 客户端 IP 数 x 客户端端口数. IPv4 IP数最大: 2^32 端口数最多: 2^16 理论上服务器单机最大 TCP 连接数为 2^48. 限制 文件描述符限制: Socket都是文件, 首先要通过ulimit配置文件描述符的数目. 内存: 每个TCP链接都要占用一定内存, 操作系统是有限的. 解决方案 将项目外包给其他公司(多进程方式) 创建子进程, 将基于已链接Socket的交互给这个新的子进程来做. 在 Linux 下,创建子进程使用 fork 函数.通过名字可以看出,这是在父进程的基础上完全拷贝一个子进程.在 Linux 内核中,会复制文件描述符的列表,也会复制内存空间,还会复制一条记录当前执行到了哪一行程序的进程.显然,复制的时候在调用 fork,复制完毕之后,父进程和子进程都会记录当前刚刚执行完 fork.这两个进程刚复制完的时候,几乎一模一样,只是根据 fork 的返回值来区分到底是父进程,还是子进程.如果返回值是 0,则是子进程；如果返回值是其他的整数,就是父进程. 因为复制了文件描述符列表, 文件描述符都指向整个内核统一的打开文件列表. 因而父进程刚才因为accept创建的已连接Socket也是一个文件描述符, 同样也会被子进程获得. 子进程通过这个已连接Socket和客户端进行互通 通信完毕之后, 退出进程. 因为父进程知道子进程的ID(fork后父进程获取返回值), 通过 ID 查看子进程是否完成. 将项目转包给独立的项目组(多线程方式) 多进程: 每次接一个项目,都申请一个新公司,然后干完了,就注销掉这个公司,实在是太麻烦了.毕竟一个新公司要有新公司的资产,有新的办公家具,每次都买了再卖,不划算. 通过pthread_create创建一个线程. 在task列表会创建一项, 但是很多资源, 如文件描述符列表, 进程空间, 还是共享的. 只不过多了一个引用. c10k：新来一个TCP连接, 就需要分配一个进程或者线程. 一台机器无法创建很多进程或者线程,c10k它的意思是一台机器要维护 1 万个连接,就要创建 1 万个进程或者线程,那么操作系统是无法承受的.如果维持 1 亿用户在线需要 10 万台服务器,成本也太高了. 进程和线程类比 创建进程: 成立新公司, 购买新办公家具. 创建线程, 在同一个公司成立项目组. 一个项目组支撑多个项目(IO 多路复用, 一个线程维护多个 Socket ) Socket是文件描述符, 某个线程盯的所有Socket, 都放在一个文件描述符集合fd_set中项目进度墙, 调用select函数来监听文件描述符集合是否有变化. 一旦有变化, 就会依次查看每个文件描述符. 发生变化的文件描述符在 fd_set 对应的位都设为1, 表示Socket可读或者可写, 从而可以进行读写操作, 然后再调用select, 接着盯着下一轮的变化. 一个项目支撑多个项目(IO 多路复用, 从”派人盯着”到”有事通知”) select是通过轮询的方式, select所能监控的数量有FD_SETSIZE限制. 1如果项目进度方式变化, 不需要监控, 而是主动通知项目组, 然后项目组再根据项目进展情况做相应的操作 能完成这件事情的函数叫epoll, 是通过注册callback函数的方式, 当某个文件描述符发生变化的时候, 就会主动通知. 假设进程打开了 Socket m, n, x 等多个文件描述符,现在需要通过 epoll 来监听是否这些 Socket 都有事件发生.其中 epoll_create 创建一个 epoll_create 创建一个 epoll 对象,也是一个文件,也对应一个文件描述符,同样也对应着打开文件列表中的一项.在这项里面有一个红黑树,在红黑树里,要保存这个 epoll 要监听的所有 Socket. 当 epoll_ctl 添加一个 Socket 的时候,其实是加入这个红黑树,同时红黑树里面的节点指向一个结构,将这个结构挂在被监听的 Socket 的事件列表中.当一个 Socket 来了一个事件的时候,可以从这个列表中得到 epoll 对象,并调用 call back 通知它. epll被称为解决c10k问题的利器 References: What is the difference between a port and a socket?","tags":"network 网络协议"},{"title":"Notes On Network Protocol UDP and TCP","url":"/2019/03/15/notes-on-network-protocol-udp-and-tcp/","text":"UDP 和 TCP from 极客时间 - 趣谈网络协议 UDPUDP 包头格式 IP头里面有个8位协议, 里面会存放, 数据里面到底是TCP还是UDP。处理完传输层的事情, 内核的事情基本就干完了, 里面的数据应该交给应用程序自己去处理。根据端口号, 将数据交给响应的应用程序。 UDP 的三大特点 沟通简单, 没有复杂的数据结构, 处理逻辑, 包头字段. 相信网络通路默认就是很容易送达的，不容易被丢弃的。 轻信他人, 它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。 愣头青, 做事不懂权变。它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发。 UDP的三大使用场景 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。 DHCP就是基于UDP协议的(广播形式)。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。 PXE操作系统镜像的下载使用的TFTP，这个也是基于 UDP 协议。 不需要一对一沟通，建立连接，而是可以广播的应用。 UDP不面向连接, 使得可以继承广播或多播协议。 D类地址(组播地址), 使用这个地址, 可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要发送 IGMP 包，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。 如果实现的应用需要有自己的连接策略, 可靠保证, 时延要求, 使用UDP, 然后在应用层实现这些是再好不过了。 UDP使用的五个例子 网页或者APP的访问 HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。 QUIC（全称Quick UDP Internet Connections，快速 UDP 互联网连接）是Google提出的一种基于UDP改进的通信协议, 目的是降低网络通信的延迟, 提供更好的用户互动体验。 流媒体协议 直播协议多使用RTMP。 RTMP协议也是基于TCP的。 很多直播应用，都基于UDP实现了自己的视频传输协议。 网络层不好, 应用选择性丢帧。 实时游戏 在异步IO机制引入之前, UDP尝尝是应对海量客户端链接的策略。 游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。 IoT 物联网 物联网领域终端资源少, 维护TCP协议代价太大. 物联网对实时性要求也很高. Google推出的物联网通信协议Thread就是基于UDP协议的 移动通信领域 在4G王国利, 移动流量上网的数据面对的协议GTP-U是基于UDP的。GTP协议本身就包含复杂的手机上线下线的通信协议。 TCP TCP天然认为网络环境是恶劣的，丢包，乱序，重传，拥塞都是常用的事情，一言不合就可能送达不到了，因此要从算法层面来保证可靠性。 TCP 包头格式 序号：解决乱序问题，确认哪个先来哪个后到。 确认序号：确认发出去的包，如果没有收到就应该重新发送，知道送达。解决不丢包的问题。 TCP 状态位 SYN发起一个链接 ACK是回复 RST重新连接 FIN结束链接 TCP是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。就像人与人之间的信任会经过多次交互才能建立。 窗口大小(流量控制)：TCP要做流量控制, 通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。 拥塞控制：TCP拥塞控制。控制自己，也即控制发送速度。不能改变世界，就改变自己。 TCP 特点 顺序问题，稳重不乱 丢包问题，承诺靠谱 连接维护，有始有终 流量控制，把握分寸 拥塞控制，知进知退 TCP 三次握手请求-&gt;应答-&gt;应答之应答 A 发起一个连接请求 第一个请求杳无音信 包丢了 包饶弯路, 超时了 B没有响应, 不想和我连接 再次发送 终于到达 B, A 暂时还不知道 B 收到了请求包, 知道了 A 的存在, 知道 A 要和它建立链接. 应答 B 不乐意建立连接, A 会重试一阵后放弃, 连接建立失败 B 乐意建立链接, 则会发送应答包给 A 不能认为连接建立好 应答包会丢失 应答包会饶弯路 A 已经挂了 B 发送的应答包可能会发送多次, 但是只要一次到达 A, A 就认为连接已经建立了, 对于A来说, 他的消息有去有回 A 给 B 发送应答之应答 B 也在等待这个消息, 才能确认连接的建立, 只有等到了这个消息, 对于 B 来讲, 才算他的消息有去有回 应答之应答也会丢失, 绕路, 甚至 B 挂了. 只要双方的消息都有去有回, 就基本可以了. 需要双方发送的消息都有去有回. 大部分情况下, A 和 B 建立了连接之后, A 会马上发送数据, 一旦 A 发送数据就解决了问题. 应答之应答丢失. 当 A 连续发送数据的时候, B 可以认为这个连接已经建立. B 挂了. A 发送的数据, 会报错, 说 B 不可达, A 就知道 B 出事情了. keepalive, 即使没有真实的数据包, 也有探活包. 如果 A 长时间不发包, B 可以主动关闭。 为什么两次握手不行 A 和 B 原来建立了连接, 做了简单通信, 结束了连接 最早 A 第一次发起请求的时候, 重复发了很多次包, 如果这个时候请求到达. B 会认为这也是一个正常的请求的话, 因此建立了连接(如果两次握手就建立链接), 就没有终结了. TCP 包的序号问题 A 要告诉 B, 发起包的序号 B 同样要高速 A, 发起包的序号 序号不能从1开始, 这样往往会冲突. 123456789A 发送 1 2 3. 丢了 或者 绕路了.A 重新发送 1 2 (这次不发3）但是上次绕路的3 又回来了, 发给了B. B 就会错误的认为是下一个包. # 不能每次从1开始 每个连接都要有不同的序号. 这个序号的起始序号是随着时间变化的. 32位的计数器, 每4ms加一.如果到重复, 需要4个多小时, 绕路的包早都死了. 以为IP包头里有个TTL, 也即生存时间. 连接连接过程的状态变化 TCP 四次挥手 A: B 不玩了 B: 你不玩了, 我知道了 B 不能在 ACK 的时候, 直接关闭. 有可能A是发完了最后的数据就准备不玩了, 但是 B 还没做完自己的事情, 还是可能在发送数据的, 所以称为半关闭的状态. A 可以选择不再接收数据, 也可以选择最后再接收一段数据, 等待 B 也主动关闭. B: A 好啊, 我也不玩了, 拜拜 A: 好的, 拜拜 解释 A : B 不玩了 B: 你不玩了, 我知道了 A 没收到回复 重新发送”不玩了” A 收到回复 A 跑路了, B 发起的请求得不到A的应答 B 跑路了, A 不知道 B 是还有事情要处理, 还是过一会会发送结束 断开时序图 A : B 不玩了, FIN-WAIT-1 B: 你不玩了, 我知道了 CLOSE-WAIT A 收到回复 FIN-WAIT-2 B 跑路了, Linux调整tcp_fin_timeout这个参数, 设置超时时间 B: A 好啊, 我也不玩了, 拜拜 LAST_ACK A: 好的, 拜拜 发送 ACK, FIN-WAIT-2结束. 如果这个 ACK, B 收不到 B 重新发送一个 A 好啊, 我也不玩了, 如果这个时候 A 已经跑路了, B 就再也收不到 ACK 了 TCP协议要求 A 最后等待一段时间TIME-WAIT, 这个时间要足够长到如果 B 没收到 ACK, B说 A 好啊, 我也不玩了会重发的 A 会重新发一个 ACK 并且足够时间到达 B 如果 A 直接跑路, 端口就直接空出来了, 但是 B 不知道, B 原来发过的很多包可能都还在路上. 如果 A 的端口被一个新的应用占用了, 就会收到 B 发过来的包(虽然需要会重新生成). 双保险, 为了防止混乱, 需要等足够长的时间, 等待原来B发送的所有包都死翘翘, 再空出端口. 等待时间：等待时间设为2MSL MSL 是 Maximum Segment Liftetime, 报文最大生存时间. 它是任何报文在网络上存在的最长时间, 超过这个时间报文将被丢弃. IP头中有一个TTL, 是IP数据报可以经过的最大路由数, 每经过一个处理他的路由器此值就减1, 当此值为0则数据报将被丢弃, 同时发送ICMP报文通知主机. 协议规定MSL为2分钟, 实际应用中常用的是30秒, 1分钟和2分钟等. 超过了 2MSL 按照 TCP 的原理, B 重发FIN A 收到FIN, 表示超过时间了. 直接发送 RST TCP 状态机 数字是连接状态变化 虚线是 A 的连接 实线是 B 的连接","tags":"network 网络协议"},{"title":"Notes On MySQL Locking","url":"/2019/03/08/notes-on-MySQL-locking/","text":"MySQL里面的锁可以分为：全局锁、表级锁、行级锁 全局锁 对整个数据库实例加锁。 使用场景：做全库逻辑备份时，为了保证备份期间的库在同一个逻辑时间点，即一致性视图（类似于可重复读隔离级别的效果） 全局锁两种方式： Flush tables with read lock(FTWRL) 使数据库处于只读状态，数据的增删改、数据定义语句和更新类事务的提交语句都会被阻塞 mysqldump 官方自带的逻辑备份工具，参数 -single-transaction 会在导数据之前启动一个事务，确保拿到一致性视图 以上两种方式不同点： 使用 mysqldump 前提是 引擎支持隔离级别 ，所以single-transaction方法只适用于支持事务引擎的库；MyISAM不支持事务，所以只能使用FTWRL命令 1set global readonly = true 这条语句也可以做到全库只读，但是不建议使用： 有时 readonly 会用来判断库是主库还是备库，因此修改global变量的方式影响会比较大 异常处理方面：FTWRL后客户端异常断开，MySQL会自动释放全局锁，库恢复正常；设置readonly，客户端异常，则会保持readonly，会导致长时间处于不可写状态，风险较高 以上哪种方式，一个库被全局上锁后，对立面任何一个表做字段操作，都会被锁住的 即使没有全局加锁，有了表级锁，加字段也会遇到问题 表级锁MySQL有两种表级别的锁：一种是表锁、另一种是元数据锁( metadata lock，MDL ) 表级锁的语法：lock tables xxx read/write 例如 线程A执行了lock table t1 read,t2 write 效果是 包括A线程在内的所有线程对于t1表只可读，写被阻塞；t2表读写都被阻塞 lock tables 操作可以用 unlock tables 主动释放，也可以在客户端断开的时候自动释放。 该操作不仅阻塞其他线程的操作，也阻塞了当前线程的操作 对于innoDB这种支持行锁的引擎，一般不使用lock tables命令控制并发，影响过大 另一种表级锁：MDL(metadata lock)MDL在访问一个表的时候会自动加上，MDL的作用是，保证读写的正确性。当表做增删改查操作时，加MDL读锁；当对表结构变更的时候，加MDL写锁。 读锁之间不互斥，多线程可对同一张表增删改查 读写锁之间、写锁之间互斥。两个线程同时给一个表增加字段，则第二个需要等待第一个执行完才能继续 MDL锁在语句执行开始时申请，事务结束后释放 如何给小锁安全的加字段 解决长事务，当做DDL变更的表中正好在执行长事务，则从information_schema库的innodb_trx找到当前执行长事务，先kill掉长事务或者暂停DDL 比较理想的状态：修改表结构语句alter table可以设置等待时间，如果该时间内拿不到MDL锁，则该时间内拿不到MDL锁，则放弃执行，不会阻塞后面的语句 MariaDB/ALiSQL已经支持 DDL NOWAIT/WAIT n 这个语法 12alter table tb1_name NOWAIT add column...alter table tb1_name WAIT N add column... 行锁两阶段锁 定义：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放， 而是要等到事务结束时才释放 建议：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放 死锁 定义：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态 解决方案 通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB 引擎默认值是50s 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）。 如何解决热点行更新导致的性能问题？ 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用 控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高 Innodb 行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。","tags":"mysql database 数据库"},{"title":"Notes On Network Protocol 7 layers","url":"/2019/03/08/notes-on-network-protocol-7-layers/","text":"网络七层协议总结 from 极客时间 - 趣谈网络协议 物理层电脑和电脑使用网线连接1-3，2-6交叉接法。 水晶头的第 1、2 和第 3、6 脚， 它们分别起着收、发信号的作用。 将一端的 1 号和 3 号线、2 号和 6 号线互换一下位置， 就能够在物理层实现一端发送的信号， 另一端能收到。 Hub 集线器采取的是广播模。遗留的几个问题: 这个包是发给谁的？谁应该接收？ 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？ 如果发送的时候出现了错误，怎么办？ 数据链路层MAC背景: 上述 HUB 遗留的问题，大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？ Medium Access Control， 媒体访问控制。 控制在往媒体发数据的时候， 谁先发， 谁后发的问题。 防止发生混乱。 (解决上述第2个问题)， 学名叫多路访问， 下面是解决多路访问的三种算法方式。 信道划分 分多个车道。 每个车一个车道， 你走你的， 我走我的。 这在计算机网里叫作信道划分。 轮流协议 今天单号出行， 明天双号出行， 轮着来。 这在计算机网络里叫作轮流协议。 随机接入协议 不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作随机接入协议。著名的以太网，用的就是这个方式。 链路层地址解决: 这个包是发给谁的？谁应该接收？ 物理地址， 叫做链路层(第一层)地址。 因为第二层主要解决媒体接入控制的问题， 所以它常被称为MAC地址。 NGINX 访问示例有了这个目标 MAC 地址，，数据包在链路上广播，MAC 的网卡才能发现，这个包是给它的。MAC 的网卡把包收进来，然后打开 IP 包，发现 IP 地址也是自己的，再打开 TCP 包，发现端口是自己，也就是 80，而 nginx 就是监听 80。 于是将请求提交给 nginx，nginx 返回一个网页。然后将网页内容发回请求的机器。然后层层封装，最后到 MAC 层。因为来的时候有源 MAC 地址，返回的时候，源 MAC 就变成了目标 MAC，再返给请求的机器。 CRC循环冗余检测 解决: 如果发送的时候出现了错误，怎么办？ 通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误。 ARP 协议已知IP地址， 求MAC地址的协议。 询问和应答的报文： 机器本地会进行ARP缓存。 ARP的MAC地址缓存过一段时间就会过期。 交换机一旦机器数目增多， 问题就出现了。 因为 Hub 是广播的，不管某个接口是否需要，所有的Bit都会被发送出去，然后让主机来判断是不是需要。 产生冲突的概率就提高了。 交换机学习 一台MAC1电脑将一个包发送给另一台 MAC2 电脑，当这个包到达交换机的时候，一开始交换机也不知道 MAC2 的电脑在哪个口， 所以没办法， 它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件非常聪明的事情，就是交换机会记住， MAC1 是来自一个明确的口。以后有包的目的地址是 MAC1 的， 直接发送到这个口就可以了。 转发表 当交换机作为一个关卡一样, 过了一段时间之后, 就有了整个网络的一个结构了, 这个时候, 基本上不用广播了, 全部可以准确转发. 当然, 每个机器的 IP 地址会变, 所在的口也会变,因而交换机上的学习的结果,我们称为转发表, 是有一个过期时间的. 总结 MAC层是用来解决多路访问堵车问题的 APR是通过吼的方式来寻找目标的MAC地址的，吼完之后记住一段时间,，这个叫做缓存 交换机是有MAC地址学习能力的,，学完了它就知道谁在哪儿了，不用广播了 交换机与 VLAN多台交换机之间连接起来, 形成一个拓扑结构。 环路问题：交换机之间重复发送 ARP 广播 解决方式：STP (最小生成树) 多个交换机之间的广播问题和安全问题 一大堆机器广播, 性能下降 有的需要保密, 所有包都会在一个局域网传输, 如果没有加密会有安全问题. VLAN，虚拟局域网。 使用VLAN, 一个交换机会连属于多个局域网的机器，在原来的二层的头上加一个TAG，里面有一个VLAN ID来区分不同的局域网。交换机之间可以通过 Trunk 口互相连接 网络层也即 IP 层 ICMP 协议的格式ICMP全称Internet Control Message Protocol，互联网控制报文协议。是封装在IP报文里面的。 ICMP属于网络层(IP)协议。 发送不涉及到传输层， 没有端口的概念。 ping MAC 头和 IP 头的细节 任何一台机器，当腰访问另一个IP地址的时候， 会先判断, 这个目标 IP 地址，和当前机器的 IP 地址，是否在同一个网段.。(通过CIDR, 子网掩码) 如果是同一个网段：不经过网关直接将源地址和目标地址放入IP头中。然后通过 ARP 获得 MAC 地址， 将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了。 如果不是同一个网段：需要发往默认网关GateWay。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个。例如 192.168.1.0/24 这个网段，Gateway 往往会是192.168.1.1/24 或者 192.168.1.2/24。(通过 ARP 获得网关 MAC 地址, 然后发送) 网关往往是一个路由器，是一个三层转发的设备(网络层)。 一个路由器有多个网口 一台服务器做这个网关则会有多个网卡, 其中一个网卡是和源IP同网段的 路由器路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP地址都和局域网的IP地址相同的网段，每只手都是它握住的那个局域网的网关。 任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。 MAC 地址是一个局域网内才有效的地址。MAC地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于IP地址是否改变。不改变IP地址的网关，我们称为转发网关；改变IP地址的网关，我们称为NAT网关。 静态路由 配置复杂的策略路由, 控制转发策略 动态路由 距离矢量算法BGP 链路状态算法OSPF 路由器是一台网络设备, 有多张网卡. 当一个口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为路由表。 总结 如果离开本局域网，就需要经过网关，网关是路由器的一个网口 路由器是一个三层设备，里面有如何寻找下一跳的规则 转发网关, MAC变 IP不变 NAT网关, IP变 传输层传输层里比较重要的两个协议， TCP 和 UDP TCP 和 UDP 区别 面向连接 在互通之前, 面向连接的协议会先建立连接。TCP会三次握手，UDP不会 是为了在客户端和服务端维护连接,，而建立一定的数据结构来维护双方交互的状态, 用这样的数据结构来保证所谓的面向连接的特性。 可靠性 TCP提供可靠交付, 通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达 IP包没有任何可靠性。UDP继承了IP包的特性, 不保证不丢失, 不保证按顺序到达 传输 TCP是面向字节流的。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的IP包。之所以变成了流, 这也是TCP自己的状态维护做的事情 UDP继承了IP的特性, 基于数据报的, 一个一个地发, 一个一个地收 拥塞控制 TCP是可以拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点 UDP应用让我发，我就发，管它洪水滔天 有状态服务 TCP其实是一个有状态服务。精确地记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行 UDP是无状态服务, 发出去就发出去了 小结MAC层定义了本地局域网的传输行为,IP层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因： 网络传输是以包为单位的 二层传输叫帧 网络层叫包 传输层叫段 套接字应用层HttpHttps","tags":"network 网络协议"},{"title":"Notes on Network Protocol Overview","url":"/2019/03/07/notes-on-network-protocol-overview/","text":"网络协议大致框架 from 极客时间 - 趣谈网络协议 客户端 应用层 浏览器输入网址，DNS 查找目标 IP。HTTPS 协议打包请求信息。此处包含 HTTP 头和报文信息。 传输层 通过 socket 编程来实现 TCP ( 面向连接 ) 和 UDP 两种协议。TCP 头包含客户端和服务器监听端口。如果发生丢包，客户端会发包重试。 网络层 操作系统的网络层使用 IP 协议封装 IP 头，包括客户端和服务端 IP。 数据链路层 操作系统通过 ARP 协议查找网关 MAC，封装 MAC 头，包括客户端 MAC 和网关 MAC. 物理层 通过路由协议寻找目标服务器 IP 以及 MAC 地址 服务端和客户端相反的方向，服务器校验 MAC 地址正确，取 MAC 头，然后交给操作系统网络层检验 IP ，取 IP 头，再交给传输层，即 TCP 层。这一层里服务端收到的每一个包都要原路返回回复给客户端。TCP 头中包含服务器的端口号，找到服务端的进程对请求处理（此处处理往往通过 RPC 即远程调用方式来实现不同进程间调用通信）。最后再将处理结果原路返回给客户端浏览器。 网络分层的理解 只要在网络上跑的包，都是完整的。可以有下层没上层，绝不可能有上层没下层 二层设备收到的是整个网络包。包括 HTTP, TCP, IP, MAC都有。二层设备只把 MAC 头摘下来，看看到底是丢弃、转发、还是自己留着。二层设备是工作在数据链路层的设备，通常是交换机，可以通过地址表确定 MAC 地址和对应端口。如果都不存在会更新地址表。 三层设备就是把 MAC 头摘下来之后，再把 IP 头摘下来，看看到底是丢弃、转发、还是自己留着。三层设备是工作在网络层的设备，通常是指路由器。 ifconfig IP 是地址，有定位功能； MAC 是身份证，误定位功能 CIDR 无类型域间选路。把 IP 分为网络号和主机号，中间斜杠 / 区分 IP 分公有 IP 和私有 IP DHCP ( Dynamic Host Configuration Protocol )动态主机配置协议。新机器加入会发送一个广播包，里面封装了 MAC 头，IP 头，UDP 头，BOOTP 头，以及请求内容。MAC 地址是唯一的身份，可以确定是否需要分配新的 IP。DHCP server 会广播返回消息包。包括 MAC 头，IP 头，UDP 头，BOOTP 头，同时包含新 IP 地址的合法租用信息和其他配置信息。","tags":"network 网络协议"},{"title":"Notes on MySQL Overview","url":"/2019/03/02/notes-on-MySQL-overview/","text":"读书笔记：《 MySQL 实战 45 讲》，MySQL 基本原理介绍，极客时间笔记 MySQL 基础架构，主要包括 Server 层和储存引擎层 Server 端 连接器：管理连接、权限验证 分析器：词法分析、语法分析 优化器：执行计划生成、索引选择 执行器：操作引擎、返回结果 存储引擎层负责数据的存储和提取。场景的存储引擎有 InnoDB( 5.5 之后为默认)、MyISAM、Memory 逻辑架构图： 日志系统 redo log 和 binLog123mysql&gt; create table T(ID int primary key, c int);mysql&gt; update T set c=c+1 where ID=2; InnodDB redo log如果每次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候，这就像打烊以后掌柜做的事。 WAL技术：Write-Ahead Logging，先写日志，再写磁盘 当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里，并更新内存。其它合适时间再写入磁盘 有了redo log，Inno DB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe MySQL binlog（归档日志）redo log是 InnoDB 引擎特有的日志，而Server层也有自己的日志，称为binlog。 redo log 和 binlog 不同点 redo log 是 InnoDB 引擎特有的，binlog 是 MySQL的 Server 层实现的，所有引擎都能用 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的，写到一定大小会切换到下一个文件，不会覆盖以前的日志 我们来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID = 2 这一行。 ID 是主键，引擎直接用树搜索找到这一行。如果ID = 2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回 执行器拿到引擎给的行数据，把这个值加上 1 ，比如原来是 N ， 现在就是 N+1 ，得到新的一行数据，再调用引擎接口写入这行新数据 引擎将这行数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状体啊。然后告知执行期执行完成了，随时可以提交事务 执行器生成这个操作的 binlog，并把 binlog 写入磁盘 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成 提交（commit）状态，更新完成 redolog两阶段提交redo log 和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 事务隔离事务：ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性） 隔离级别：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ） 事务隔离的实现：在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 长事务：系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 事务启动方式 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接 建议总是使用set autocommit=1, 通过显式语句的方式来启动事务。避免长连接导致长事务。 查询长事务1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60; -- 查找持续时间超过60s的事务 深入浅出索引索引常见模型 哈希表 ( 查询效率不高 ) 有序数组 （ 增删效率低，适合静态存储 ） 搜索树 InnoDB 的索引模型索引类型 主键索引 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index） 非主键索引 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index） 12345mysql&gt; create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树 ； 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为500，再到 ID 索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 覆盖索引如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 最左前缀原则只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。 索引下推 （index condition pushdown)1mysql&gt; select * from tuser where name like '张%' and age=10 and ismale=1; InnoDB在(name,age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。在我们的这个例子中，只需要对ID4、ID5这两条记录回表取数据判断，就只需要回表2次","tags":"mysql database 数据库"},{"title":"Notes On Tcpdump and Wireshark","url":"/2019/02/27/notes-on-tcpdump-and-Wireshark/","text":"tcpdump 和 Wireshark这个例子只是执行 ping 指令的一个例子 1tcpdump -nn udp port 53 or host x.x.x.x -w ping.pcap -nn 不解析抓包中的域名（不反向解析）、协议以及端口号 udp port 53 只显示 UDP 协议的端口号（包括源端口和目的端口）为 53 的包 host x.x.x.x 只显示 IP 地址（包括原地址和目的地址）为 x.x.x.x 的包 or 或的关系 HTTP 的一个例子，便于理解 TCP 三次握手和四次挥手 12tcpdump -nn host example.com -w web.pcapcurl example.com 可以看到TCP 三次握手和四次挥手的请求 顺便复习一下流程：","tags":"tcpdump wireshark"},{"title":"Leetcode 206. Reverse Linked List","url":"/2019/02/26/leetcode-206-reverse-linked-list/","text":"题意单链表反转 题目来源：https://leetcode.com/problems/reverse-linked-list/ 标记难度：Easy 提交次数：1/? 代码效率：100% 分析迭代法：将当前节点的后继节点指向前一个节点，移动当前节点 递归法 代码迭代法 1234567891011121314151617181920/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode reverseList(ListNode head) &#123; ListNode newHead = null; while(head != null)&#123; ListNode next = head.next; head.next = newHead; newHead = head; head = next; &#125; return newHead; &#125;&#125; 递归法 12 Nonesense最简单的单链表居然花费了我半天的时间，最后还是参考别人的答案才写出来。。。智商捉急 总结一下问题： 太急躁，要静下心来慢慢梳理过程，整理成代码输出 java变量指针等概念感觉还是不清晰，今天抽空需要补一下","tags":"algorithms leetcode"},{"title":"Leetcode 448 Find All Numbers Disappeared in an Array","url":"/2019/02/24/leetcode-448-find-all-numbers-disappeared-in-an-array/","text":"题意给定一个长度为N整形数组，元素取值 范围从1到N，其中有可能有重复出现两次的元素，找出丢失的元素： 题目来源：https://leetcode.com/problems/find-all-numbers-disappeared-in-an-array/ 标记难度：Easy提交次数：1/N 代码效率： 95.58% Example: 12345Input:[4,3,2,7,8,2,3,1]Output:[5,6] 分析：取负法：不管一个元素出现一次还是两次，只要出现它对应的位置就会被取负。当某个元素不出现的时候，该元素对应的位置始终访问不到，所以还是正值，通过这种方法我们就可以找到哪些元素没有出现 代码123456789101112131415161718class Solution &#123; public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) &#123; List&lt;Integer&gt; list = new ArrayList(); for(int i = 0;i &lt; nums.length;i++)&#123; int val = Math.abs(nums[i]) - 1; if(nums[val] &gt; 0)&#123; nums[val] = -nums[val]; &#125; &#125; for(int j = 0; j&lt;nums.length;j++)&#123; if(nums[j] &gt;0)&#123; list.add(j+1); &#125; &#125; return list; &#125;&#125; 一些废话感觉这个题就是单纯考虑数学技巧，做起来比较吃力，看答案的时候豁然开朗，还是慢慢积累吧。。。","tags":"algorithms leetcode"},{"title":"Leetcode 283 Move Zeroes","url":"/2019/02/23/leetcode-283-move-zeroes/","text":"题意给定一个整形数组，将0都移动到最后，保持其他数组相对位置不变 题目来源：https://leetcode.com/problems/move-zeroes/ 标记难度：Easy 提交次数：1/N 代码效率：100% 12Input: [0,1,0,3,12]Output: [1,3,12,0,0 分析一个快指针，一个慢指针，快指针指向不为0的元素，快慢指针值交换，同时向后移动一位。这样可以保证下面两个条件： 快慢指针之间的元素都是0 慢指针之前的元素都不为0代码 1234567891011121314class Solution &#123; public void moveZeroes(int[] nums) &#123; int j = 0; int tmp =0; for(int i = 0;i &lt; nums.length;i++)&#123; if(nums[i]!=0)&#123; tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; j++; &#125; &#125; &#125;&#125; 一些废话一开始理解错误，以为把0都放到后面之后还是要对前面从大到小进行排序。。。结果想了半天 以后还是要仔细审题，不要怀疑自己，先用自己的想法暴力实现 写代码之前可以举个栗子来一步一步推敲，想好边界和规律再写代码","tags":"algorithms leetcode"},{"title":"Leetcode 136. Single Number","url":"/2019/02/22/leetcode-136-single-number/","text":"题意给定一个非空数组，除了唯一个单独的元素外，每个元素出现两次。找出这个单独的元素。 题目来源：https://leetcode.com/problems/single-number/ 标记难度：Easy 提交次数：1/N 代码效率：100.00% 分析使用异或 ^ 两个相同的数异或后为0 0和一个数异或后为那个数 异或运算满足交换律 代码123456789class Solution &#123; public int singleNumber(int[] nums) &#123; int result = 0; for(int i = 0;i&lt; nums.length;i++)&#123; result^=nums[i]; &#125; return result; &#125;&#125;","tags":"algorithms leetcode"},{"title":"Leetcode 226. Invert Binary Tree","url":"/2019/02/21/leetcode-226-invert-binary-tree/","text":"题意反转二叉树左右子树 题目来源：https://leetcode.com/problems/invert-binary-tree/ 标记难度：Easy提交次数：1/ N 代码效率：100.00% Input: 12345 4 / \\ 2 7 / \\ / \\1 3 6 9 Output: 12345 4 / \\ 7 2 / \\ / \\9 6 3 1 分析左子树和右子树递归互换 代码123456789101112131415161718192021/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; if(root == null)&#123; return null; &#125; TreeNode tmp = root.left; root.left = invertTree(root.right); root.right = invertTree(tmp); return root; &#125; &#125; 题外话对递归还是理解不透彻，总结一下如何处理递归问题： 那该如何理解递归代码呢？如果一个问题A可以分解为若干个子问题B、C、D，你可以假设子问题B、C、D已经解决。而且，你只需要思考问题A与子问题B、C、D两层之间的关系即可，不需要一层层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。","tags":"algorithms leetcode"},{"title":"Leetcode 104. Maximum Depth of Binary Tree","url":"/2019/02/20/leetcode-104-maximum-depth-of-binary-tree/","text":"题意计算二叉树的深度 题目来源：https://leetcode.com/problems/maximum-depth-of-binary-tree/ 标记难度：Easy提交次数：思路很乱，参考 Discuss 的答案 代码效率：100.00% 分析递归左右子树，对深度最大的子树进行递归调用并+1 代码1234567891011121314151617/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public int maxDepth(TreeNode root) &#123; if(root == null)&#123; return 0; &#125; return Math.max(maxDepth(root.left),maxDepth(root.right)) + 1; &#125;&#125;","tags":"algorithms leetcode"},{"title":"Leetcode 617 Merge Two Binary Trees","url":"/2019/02/19/leetcode-617-merge-two-binary-trees/","text":"题意合并两个给定的子二叉树，新的二叉树每个节点是两个二叉树对应节点的和，如果某一个二叉树的节点不存在，则取另外一个二叉树对应节点的值作为新的二叉树对应节点的值。 题目来源：https://leetcode.com/problems/merge-two-binary-trees/ 标记难度：Easy提交次数：1/1 代码效率：98.24% 耗时：25分钟 1234567891011121314Input: Tree 1 Tree 2 1 2 / \\ / \\ 3 2 1 3 / \\ \\ 5 4 7 Output: Merged tree: 3 / \\ 4 5 / \\ \\ 5 4 7 分析主要考察对递归算法的理解。 首先考虑边界，如果两个子二叉树都为空，则新的二叉树必定为空 考虑其中一个子二叉树为空，则新的二叉树直接等于另外一个子二叉树 如果两个子二叉树都不为空，新二叉树节点值为两个子二叉树对应节点的值的和，同时对两个子二叉树的左右子树进行递归调用，仔细想想就明白了 代码1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public TreeNode mergeTrees(TreeNode t1, TreeNode t2) &#123; TreeNode ret; if(t1 == null &amp;&amp; t2 == null)&#123; return null; &#125;else if(t1 != null &amp;&amp; t2 == null)&#123; ret = t1; &#125;else if(t1 == null &amp;&amp; t2 != null)&#123; ret = t2; &#125;else &#123; ret = new TreeNode(t1.val + t2.val); ret.left = mergeTrees(t1.left,t2.left); ret.right = mergeTrees(t1.right,t2.right); &#125; return ret; &#125;&#125; 当然别人思路的总是最好的 o(╥﹏╥)o 12345678public TreeNode mergeTrees(TreeNode t1, TreeNode t2) &#123; if (t1 == null) return t2; if (t2 == null) return t1; TreeNode result = new TreeNode(t1.val + t2.val); result.left = mergeTrees(t1.left, t2.left); result.right = mergeTrees(t1.right, t2.right); return result;&#125; 一些废话学习数据结构的时候，总感觉递归对自己来说是弱项，智商不够用。今天居然一次性直接做出来了。学习数据结构和算法真的能培养思维逻辑和解决问题的能力。fighting !!!","tags":"algorithms leetcode"},{"title":"Leetcode 461 Hamming Distance","url":"/2019/02/18/leetcode-461-hamming-distance/","text":"题意统计两个整数转换成二进制位时位数不同的个数。 题目来源：https://leetcode.com/problems/hamming-distance/ 标记难度：Easy提交次数：1/2 (少写了 return 语句。。) 代码效率：91.77% 分析二进制的每一位的值不是 0 就是 1，就是整数除以 2 取余的结果，判断是否相等。然后再取模（相当于向左移动一位），再取余作比较。 代码1234567891011121314151617class Solution &#123; public int hammingDistance(int x, int y) &#123; int count = 0; int i = 0; int j = 0; while(x != 0 || y != 0)&#123; i = x % 2; j = y % 2; if(i != j)&#123; count++; &#125; x = x / 2; y = y / 2; &#125; return count; &#125;&#125; 参考别人的一行代码实现Orz： 12345public class Solution &#123; public int hammingDistance(int x, int y) &#123; return Integer.bitCount(x ^ y); &#125;&#125;","tags":"algorithms leetcode"},{"title":"Leetcode 771 Jewels And Stones","url":"/2019/02/17/leetcode-771-jewels-and-stones/","text":"题意给定两个字符串 J 和 S，找出 J 中的字母出现在 S 中的次数。 题目来源：https://leetcode.com/problems/jewels-and-stones/ 标记难度：Easy 提交次数：1/4 代码效率：93.10% 分析把 J 和S 转换成字符数组，遍历 J 数组中的字符是否等于 S 中的 字符。 代码123456789101112131415class Solution &#123; public int numJewelsInStones(String J, String S) &#123; char[] charJ = J.toCharArray(); char[] charS = S.toCharArray(); int count = 0; for(char var : charJ)&#123; for(int i = 0;i&lt;charS.length;i++)&#123; if(var == charS[i])&#123; count++; &#125; &#125; &#125; return count; &#125;&#125; 参考别人还有更好的做法： 遍历 J 把字符放入 set 集合 遍历 S 字符是否出现在 set 中 1234567public int numJewelsInStones(String J, String S) &#123; int res = 0; Set setJ = new HashSet(); for (char j: J.toCharArray()) setJ.add(j); for (char s: S.toCharArray()) if (setJ.contains(s)) res++; return res; &#125; 一些废话第一次开始刷 Leetcode ,虽然做的是 easy 的题目，但还是没有参考其他人的答案自己完成了。开始有一点新鲜感和成就感了，希望可以坚持下去。 刚开始刷题使用的是 VS CODE 码代码，在网上看了一些网友的建议，为了应对后续面试可能要求手写编程的情况，所以现在是先用 IDE 把代码写出来，再手写输入 Leetcode 提交答案。 加油！","tags":"algorithms leetcode"},{"title":"Leetcode Tips","url":"/2019/02/15/leetcode-tips/","text":"数据结构和算法是编程中很重要的一部分，学习了这些知识之后，对解题思路有很大的帮助。 数据结构和算法也是其他技术的实现基础，要理解这些技术的实现原理就必须学习数据结构和算法。推荐学习书籍： 数据结构与算法之美 极客时间的一个专栏，内容通俗易懂，适合入门 数据结构与算法分析：Java语言描述 下一步打算看的书籍 经典大作：算法，算法导论 附数据结构与算法之美推荐书单： Leetcode 刷题方法在刚开始刷 Leetcode 时，很多人只有在看完答案才知道要怎么做，如果不看答案的话完全没有思路。这是非常正常的现象，并不表示你的思维能力比别人差。人类最擅长的学习方式是模仿，刚开始刷题的时候不会做看看别人怎么做是很正确的做法，模仿多了自然就会做了。 刷 Leetcode 也有两种流派：龟派和兔派。龟派每道题都要想很久，而且尽可能想出多种解法。兔派是想一会儿就看答案，这样就可以很快地刷题。龟派比较适合思维锻炼，而兔派比较适合短期内快速提高并记忆。如果是为了应对校招的话，比较推荐兔派这种刷题方法，因为校招确实很依赖于短期记忆。选择兔派这种方式的话，就需要反复地进行复习，从而保持记忆并增加理解。但是也不能完全采用兔派这种方法，因为如果习惯于不去思考怎么做的话，会养成惰性的思维方式。 当你刷题到一定程度的时候，最好每天再刷一两题保持题感。可以选你之前做过的题目，因为你再做一遍的话可以很快做出来，这样子就可以让你对刷题这件事保持积极的一种心态。 刷 Leetcode 的收益如下图所示，可以看到刷的越多收益增长的越小。刷 200 题就足够应对大多数互联网公司的校招，但是如果时间不够的话刷 100 题也是有很大的收益，可以刷一下 Top 100 Liked Questions。 排序：大部分要求能手写，并分析时间空间复杂度，以及稳定性 树：红黑树的原理以及在 JDK 的使用；B+ 树以及在数据库索引中的使用 图：拓扑排序；并查集；最短路径；最小生成树 散列表：实现原理，以及在 JDK 中的使用 字符串：KMP；AC 自动机；Trie 树","tags":"algorithms leetcode"},{"title":"Beauty Of Algorithms 20 Summary. Red Black Tree","url":"/2019/02/13/beauty-of-algorithms-20-summary-red-black-tree/","text":"红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树的数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n,所以它是近似平衡， 插入、删除、查找操作的时间复杂度都是O(logn)。红黑树非常复杂，无法永久记忆它的平衡调整策略。 有时间深入了解一下 :)","tags":"algorithms 数据结构与算法 red-black-tree 红黑树"},{"title":"Beauty Of Algorithms 19 Summary. Binarytree","url":"/2019/02/09/beauty-of-algorithms-19-summary-binarytree/","text":"二叉树树 节点 树中的元素称之为节点 高度 节点的高度 节点到叶子节点的最长路径 树的高度 跟节点的高度 深度 根节点到这个节点所经历的边的个数 层 节点的深度+1 二叉树 满二叉树 除了叶子结点外每个节点都有左右两个子节点 完全二叉树 叶子结点都在最低下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大 表示、存储一棵二叉树链式存储法 每个结点有三个字段，其中一个存储数据，另两个是指向左右子节点的指针。 顺序存储法(基于数组) 根节点存储在下标i=1的位置，左子节点存储在下标2i=2的位置，右子节点存储在2i+1=3的位置，以此类推。 如果节点 X 存储在数组中下标为 i 的位置，下标为 2 i 的位置存储的就是左子节点，下标为 2 i + 1 的位置存储的就是右子节点。我们只要知道根节点存储的位置，这样就可以通过下标计算，把整棵树都串起来。 为了方便计算子节点，根节点会存储在下标为 1 的位置 二叉树的遍历 前序遍历 对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。 中序遍历 对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。 后序遍历 对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。 层序遍历 从树的第一层开始从左到右打印节点 实际上，二叉树的前、中、后序遍历就是一个递归的过程。 比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。 二叉树以及二叉树遍历代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139/** * BinaryTree */public class BinaryTree &#123; private Node root; private int data = 0; private int size = 0; public BinaryTree() &#123; root = new Node(data); &#125; public void add(int data) &#123; if (size == 0) &#123; root.data = data; size++; &#125; else &#123; add(root, new Node(data)); &#125; &#125; private void add(Node root, Node newNode) &#123; if (root == null) &#123; return; &#125; if (newNode.data &lt; root.data) &#123; if (root.leftNode == null) &#123; root.leftNode = newNode; size++; &#125; else &#123; add(root.leftNode, newNode); &#125; &#125; else &#123; if (root.rightNode == null) &#123; root.rightNode = newNode; size++; &#125; else &#123; add(root.rightNode, newNode); &#125; &#125; &#125; public int getLow() &#123; Node parent = root; while (parent.leftNode != null) &#123; parent = parent.leftNode; &#125; return parent.data; &#125; public int getHigh() &#123; Node parent = root; while (parent.rightNode != null) &#123; parent = parent.rightNode; &#125; return parent.data; &#125; public void preOrder() &#123; System.out.println(\"前序遍历：\"); pre(root); System.out.println(\" \"); &#125; private void pre(Node node) &#123; if (node != null) &#123; System.out.print(node.data + \" \"); pre(node.leftNode); pre(node.rightNode); &#125; &#125; public void inOrder() &#123; System.out.println(\"中序遍历：\"); in(root); System.out.println(\" \"); &#125; private void in(Node node) &#123; if (node != null) &#123; in(node.leftNode); System.out.print(node.data + \" \"); in(node.rightNode); &#125; &#125; public void postOrder() &#123; System.out.println(\"后序遍历：\"); post(root); System.out.println(\" \"); &#125; private void post(Node node) &#123; if (node != null) &#123; post(node.rightNode); post(node.leftNode); System.out.print(node.data + \" \"); &#125; &#125; private class Node &#123; private int data; private Node leftNode; private Node rightNode; public Node(int data) &#123; this.data = data; this.leftNode = null; this.rightNode = null; &#125; &#125; public static void main(String[] args) &#123; System.out.println(\"*************\"); BinaryTree t = new BinaryTree(); t.add(40); t.add(25); t.add(78); t.add(10); t.add(32); t.add(50); t.add(93); t.add(3); t.add(17); t.add(30); t.add(38); System.out.println(t.getLow()); System.out.println(t.getHigh()); System.out.println(\"Size-\" + t.size); System.out.println(t); t.inOrder(); t.preOrder(); t.postOrder(); &#125;&#125; 二叉查找树 Binary Search Tree二叉查找树的定义二叉查找树又称二叉搜索树。其要求在二叉树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树的节点的值都大于这个节点的值。 二叉查找树的查找操作二叉树类、节点类以及查找方法的代码实现 先取根节点，如果它等于我们要查找的数据，那就返回。 如果要查找的数据比根节点的值小，那就在左子树中递归查找； 如果要查找的数据比根节点的值大，那就在右子树中递归查找。 12345678910111213public Node find(int data) &#123; Node p = tree; while (p != null) &#123; if (data &lt; p.data) &#123; p = p.left; &#125; else if (data &gt; p.data) &#123; p = p.right; &#125; else &#123; return p; &#125; &#125; return null;&#125; 二叉查找树的插入操作 新插入的数据一般都是在叶子节点上，所以我们只需要从根节点开始，依次比较要插入的数据和节点的大小关系。 如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。 同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。 12345678910111213141516171819202122public void insert(int data) &#123; if (tree == null) &#123; tree = new Node(data); return; &#125; Node p = tree; while (p != null) &#123; if (data &lt; p.data) &#123; if (p.left == null) &#123; p.left = new Node(data); return; &#125; p = p.left; &#125; else &#123; if (p.right == null) &#123; p.right = new Node(data); return; &#125; p = p.right; &#125; &#125;&#125; 二叉查找树的删除操作 第一种情况，删除的节点没有子节点直接将其父节点指向置为null。 第二种情况，删除的节点只有一个子节点，将其父节点指向其子节点。 第三种情况，删除的节点有两个子节点，首先找到该节点右子树中最小的的节点把他替换掉要删除的节点 然后再删除这个最小的节点，该节点必定没有子节点，否则就不是最小的节点了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 1. 先找到要删除的节点 * 2. 如果这个节点有两个叶子节点，找到右子树的最小值，替换当前的这个节点值，同时删除这个最小值 * 3.如果这个节点只有一个叶子节点，用叶子节点的值替换当前节点的值 * 4. 如果这个节点没有叶子节点，直接删除 * @param data */public void delete(int data) &#123; Node p = root; Node pp = null; while (p != null &amp;&amp; p.data != data) &#123; pp = p; if (data &lt; p.data) &#123; p = p.left; &#125; else &#123; p = p.right; &#125; &#125; if (p == null) &#123; return; &#125; if (p.left != null &amp;&amp; p.right != null) &#123; Node minP = p; Node minPP = pp; while (minP.left != null) &#123; minPP = minP; minP = minP.left; &#125; p.data = minP.data; p = minP; pp = minpp; &#125; Node child; if (p.left != null) &#123; child = p.left; &#125; else if (p.right != null) &#123; child = p.right; &#125; else &#123; child = null; &#125; if (pp == null) &#123; root = child; &#125; else if (pp.left == p) &#123; pp.left = child; &#125; else &#123; pp.right = child; &#125;&#125; 关于二叉查找树的删除操作，还有个非常简单、取巧的方法，就是单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。 这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。 二叉查找树的其他操作二叉查找树中还可以支持快速地查找最大节点和最小节点、前驱节点和后继节点。 二叉查找树除了支持上面几个操作之外，还有一个重要的特性，就是中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)，非常高效。因此，二叉查找树也叫作二叉排序树。 支持重复数据的二叉查找树前面的二叉查找树的操作，我们默认树中节点存储的都是数字，针对的都是不存在键值相同的情况。 我们可以通过两种办法来构建支持重复数据的二叉查找树。 第一种方法 二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。 第二种方法 每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。 当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。 对于删除操作，我们也需要先查找到每个要删除的节点，然后再按前面讲的删除操作的方法，依次删除。 二叉查找树的时间复杂度分析最坏、最好情况 如果根节点的左右子树极度不平衡，已经退化成了链表，所以查找的时间复杂度就变成了 O(n)。 最理想的情况，二叉查找树是一棵完全二叉树（或满二叉树）。不管操作是插入、删除还是查找，时间复杂度其实都跟树的高度成正比，也就是 O(height)。而完全二叉树的高度小于等于 log2n。 平衡二叉查找树 我们需要构建一种不管怎么删除、插入数据，在任何时候都能保持任意节点左右子树都比较平衡的二叉查找树，这就是一种特殊的二叉查找树，平衡二叉查找树。 平衡二叉查找树的高度接近 logn，所以插入、删除、查找操作的时间复杂度也比较稳定，是O(logn)。 二叉查找树相比散列表的优势散列表中的数据是无序存储的 如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历就可以在 O(n) 的时间复杂度内，输出有序的数据序列。 散列表扩容耗时很多 而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。 散列表存在哈希冲突 尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。 加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。 散列表装载因子不能太大 为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。 综合这几点，平衡二叉查找树在某些方面还是优于散列表的，所以，这两者的存在并不冲突。","tags":"algorithms 数据结构与算法 binarytree 二叉树"},{"title":"Beauty Of Algorithms 18 Summary. Hash","url":"/2019/02/08/beauty-of-algorithms-18-summary-hash/","text":"哈希算法的定义和原理将任意长度的二进制串映射为固定长度的二进制串。 这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制串就是哈希值。 设计一个优秀的哈希算法需要满足： 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法） 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值 MD5哈希算法MD5的哈希值是128位的bit长度，为了方便转换成了16进制编码。 可以看出无论哈希值文本有多长多短，通过MD5哈希之后，得到的哈希值的长度都是一样的， 而且得到的哈希值看起来像一堆随机数完全没有规律。 12MD5(&quot; 今天我来讲哈希算法 &quot;) = bb4767201ad42c74e650c1b6c03d78faMD5(&quot;jiajia&quot;) = cd611a31ea969b908932d44d126d195b 哈希算法的应用安全加密加密算法 最常用于加密的哈希算法是MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和SHA（Secure Hash Algorithm，安全散列算法）。 对用于加密的哈希算法来说，有两点格外重要： 很难根据哈希值反向推导出原始数据 散列冲突的概率要很小 实际上，不管是什么哈希算法，我们只能尽量减少碰撞冲突的概率，理论上是没办法做到完全不冲突的。 鸽巢理论 这里就基于组合数学中一个非常基础的理论，鸽巢原理（也叫抽屉原理）。 这个原理本身很简单，它是说如果有 10 个鸽巢，有 11 只鸽子那肯定有 1 个鸽巢中的鸽子数量多于 1 个。 换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。 我们知道，哈希算法产生的哈希值的长度是固定且有限的。 哈希值是固定的 128 位二进制串，能表示的数据是有限的最多能表示 2^128 个数据。 基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。 唯一标识在图库中搜索图片 如果要在海量的图库中，搜索一张图是否存在，我们不能单纯地用图片的元信息（比如图片名称）来比对。 因为有可能存在名称相同但图片内容不同，或者名称不同图片内容相同的情况。 我们可以给每一个图片取一个唯一标识，或者说信息摘要。 比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节。 然后将这 300 个字节放到一块，通过哈希算法（比如 MD5)得到一个哈希字符串，用它作为图片的唯一标识。 通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量 性能提升如果还想继续提高效率，我们可以把每个图片的唯一标识和相应的图片文件在图库中的路径信息，都存储在散列表中。 当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。 数据校验P2P文件快校验 BT 下载的原理是基于 P2P 协议的。 我们从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成100 块，每块大约 20MB）。 等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。 网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者下载过程中出现了错误，所以下载的文件块可能不是完整的。 解决方法 我们通过哈希算法，对 100 个文件块分别取哈希值并且保存在种子文件中。 当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。 如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。 散列函数散列函数是一种哈希算法 实际上，散列函数也是哈希算法的一种应用。 散列函数是设计一个散列表的关键。 它直接决定了散列冲突的概率和散列表的性能。 不过，相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。 即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。 散列函数追求平均分布 不仅如此，散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。 散列函数中用到的散列算法，更加关注散列后的值是否能平均分布。 也就是一组数据是否能均匀地散列在各个槽中。 除此之外，散列函数执行的快慢，也会影响散列表的性能， 所以，散列函数用的散列算法一般都比较简单，比较追求效率。 负载均衡我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。 最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。 客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。这种方法简单直观，但也有几个弊端： 如果客户端很多，映射表可能会很大，比较浪费内存空间 客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大 如果借助哈希算法，这些问题都可以非常完美地解决。 我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。 数据分片统计“搜索关键词”出现的次数 假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词， 我们想要快速统计出每个关键词被搜索的次数。 我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。 为了提高处理的速度，我们用 n 台机器并行处理。 我们从搜索记录的日志文件中，依次读出每个搜索关键词， 并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。 这样，哈希值相同的搜索关键词就被分配到了同一个机器上。 也就是说，同一个搜索关键词会被分配到同一个机器上。 每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。 快速判断图片是否在图库中 假设现在我们的图库中有 1 亿张图片，在单台机器上构建散列表是行不通的。 我们同样可以对数据进行分片，然后采用多机处理。 我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。 我们每次从图库中读取一个图片，计算唯一标识， 然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号， 然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。 当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法， 计算这个图片的唯一标识，然后与机器个数 n 求余取模。 假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。 分布式存储我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。 我们需要将数据分布在多台机器上通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号 如果数据增多，原来的 10 个机器已经无法承受，我们需要扩容，假如扩到 11 个机器。 原来的数据是通过与 10 来取模的，比如 13 这个数据，存储在编号为 3 这台机器上。 新加了一台机器后，我们对数据按照 11 取模，原来 13 这个数据被分配到了 2 号这台机器上。 因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。 所有的数据请求都会穿透缓存，直接去请求数据库，可能会发生雪崩效应，压垮数据库。 我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。 这时候，一致性哈希算法就要登场了。 一致性哈希算法 参考 假设我们有 k 个机器，数据的哈希值的范围是 [0, MAX]。 我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。 当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。 这样既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。","tags":"algorithms 数据结构与算法 hash 哈希算法"},{"title":"Beauty Of Algorithms 17 Summary. HashTable","url":"/2019/02/07/beauty-of-algorithms-17-summary-hash-table/","text":"散列表Hash Table来源于数组，它借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性。 需要存储在散列表中的数据我们称为键key，将键转化为数组下标的方法hash(key)称为散列函数，散列函数的计算结果称为散列值。 将数据存储在散列值对应的数组下标位置。 设计散列函数设计散列函数的基本要求 散列函数计算得到的散列值是一个非负整数。 若key1=key2，则hash(key1)=hash(key2)。 若key≠key2，则hash(key1)≠hash(key2)。 当空闲位置越来越少，散列值冲突的概率越来越大，也就无法满足第三条。 散列冲突的解决方法开放寻址法 线性探测 开放寻址法会导致占用删除元素的位置，这样会导致原来的算法失效。 所以线性探测法的删除操作是将要删除的元素标记为deleted，当要插入数据时遇到这种位置就继续向下探测。 二次探测 线性探测法每次探测的步长为1，即在数组中一个一个探测，比如hash(key)+1,hash(key)+2… 而二次探测的步长变为原来的平方hash(key)+1^2,hash(key)+2^2… 双重散列 使用一组散列函数，先使用第一个，如果有冲突就换下一个，直到找到空闲位置为止。 性能描述 我们使用装载因子来表示空位多少： 1散列表的装载因子 = 填入表中的元素个数 / 散列表的长度 装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。 链表法 插入数据 当插入的时候，我们需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，所以插入的时间复杂度为O(1) 查找或删除数据 对于散列比较均匀的散列函数，链表的节点个数k=n/m，其中n表示散列表中数据的个数，m表示散列表中槽的个数。当查找、删除一个元素时，通过散列函数计算对应的槽，然后遍历链表查找或删除，两操作与链表长度k成正比，即时间复杂度为O(k)。 思考假设我们有10万条URL访问日志，如何按照访问次数给URL排序 遍历 10 万条日志，将 URL 做为 KEY ，声明一个访问次数 count 作为散列表值，存入散列表，每次遇到重复的 count++ ,然后对散列表值进行桶排序或者快速排序。 有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中相同的字符串 将其中一个数组以字符串为 KEY， 默认值 value 为 0 存入散列表。然后用第二个数组的元素为 KEY 遍历这个散列表，如果找到相同的KEY ，那么 value +1 ，最后统计 value&gt;0 的所有 KEY. 散列表碰撞攻击在极端情况下，有些恶意的攻击者，还有可能通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。 如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。 散列函数的设计 散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能 散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况 实际工作中，我们还需要综合考虑各种因素。这些因素有关键字的长度、特点、分布、还有散列表的大小等。 散列函数的设计方法有很多：数据分析法、直接寻址法、平方取中法、折叠法、随机数等等 装载因子 装载因子越大，散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。 插入数据的过程要多次寻址或者拉很长的链，查找的过程也会变得很慢。 动态散列表的数据集合是频繁变动的，我们事先无法预估数据个数，无法事先申请一个足够大的散列表。 数据慢慢加入，装载因子就会慢慢变大，当装载因子大到一定程度之后，散列冲突变得不可接受。 当装载因子过大时，我们可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。 假设每次扩容我们都申请一个原来散列表大小两倍的空间。如果原来散列表的装载因子是 0.8，扩容之后新散列表的装载因子就下降为原来的一半变成了 0.4。 避免低效地扩容 当装载因子已经到达阈值，需要先进行扩容，再插入数据。这个时候，插入数据就会变得很慢，甚至会无法接受。 举一个极端的例子，如果散列表当前大小为 1GB，要想扩容为原来的两倍大小，那就需要对1GB 的数据重新计算哈希值，并且从原来的散列表搬移到新的散列表。 为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。 当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。 每次插入一个数据到散列表，我们都重复上面的过程。 经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。 对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。 散列冲突解决方法开放寻址法 优点 散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。 种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易 缺点 在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高 使用开放寻址法解决冲突的散列表，装载因子的上限不能太大 这种方法比链表法更浪费内存空间 当数据量比较小、装载因子小的时候，适合采用开放寻址法。 这也是 Java 中的 ThreadLocalMap 使用开放寻址法解决散列冲突的原因。 链表法 优点 链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。实际上，这一点也是我们前面讲过的链表优于数组的地方。 链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多 缺点 链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍 而且，因为链表中的结点是零散分布在内存中的，不是连续的。所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响 当如果我们存储的是大对象，即存储的对象的大小远远大于一个指针的大小。那么链表中指针的内存消耗在大对象面前就可以忽略了。 链表法比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。 工业级散列表举例分析初始大小 HashMap 默认的初始大小是 16，这个默认值是可以设置的。可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。 装载因子和动态扩容 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。 散列冲突解决方法 HashMap 底层采用链表法来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。 于是，在 JDK1.8 版本中，为了对 HashMap 做进一步优化，我们引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。 散列函数 1234int hash(Object key) &#123; int h = key.hashCode()； return (h ^ (h &gt;&gt;&gt; 16)) &amp; (capitity -1); //capicity 表示散列表的大小&#125; hashCode() 返回的是 Java 对象的 hash code。 比如 String 类型的对象的 hashCode() 就是下面这样： 1234567891011public int hashCode() &#123; int var1 = this.hash; if(var1 == 0 &amp;&amp; this.value.length &gt; 0) &#123; char[] var2 = this.value; for(int var3 = 0; var3 &lt; this.value.length; ++var3) &#123; var1 = 31 * var1 + var2[var3]; &#125; this.hash = var1; &#125; return var1;&#125; 如何设计的一个工业级的散列函数？ 如果这是一道面试题或者是摆在你面前的实际开发问题，从哪几个方面思考呢 结合已经学习过的散列知识，我觉得应该有这样几点要求： 支持快速的查询、插入、删除操作 内存占用合理，不能浪费过多的内存空间 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况 如何实现这样一个散列表呢？根据前面讲到的知识从这三个方面来考虑设计思路 设计一个合适的散列函数 定义装载因子阈值，并且设计动态扩容策略 选择合适的散列冲突解决方法 散列表和链表组合使用LRU缓存淘汰算法借助散列表，我们可以把LRU缓存淘汰算法的时间复杂度降为O(1)。 一个缓冲cache系统主要包含以下操作 往缓存中添加一个数据 从缓存中删除一个数据 在缓存中查找一个数据 单纯采用链表，时间复杂度只能是O(n)。 将散列表和双向链表结合，就可以降为O(1)，其结构如下图所示： 其中，我们使用双向链表存储数据，data存储数据，prev前驱指针，next后继指针。 此外，新增加了hnext指针，这个指针就是链表法散列表中的拉链的后继指针。 如何做到O(1) 查找 因为是散列表所以查找一个数据的操作时间复杂度就接近于O(1) 删除 删除一个数据，我们借助散列表再O(1)的时间复杂度里找到该结点，而双向链表有前驱指针，可以直接删除该节点，时间复杂度为O(1) 添加 添加一个数据比较复杂，首先要看其是否已经在缓存中，如果在就将其移动到双向链表的尾部，如果不在就检查缓存满了没，满了就删除双向链表的头结点，再将数据放到双向链表的尾部，如果没有满就直接将数据放大双向链表的尾部 以上操作中，设计查找的操作是散列表完成的，删除节点、插入节点是双向链表完成的，所以时间复杂度是O(1)。 Redis有序集合在有序集合中，每个成员对象有两个重要的属性，键key和分值score。 我们不仅需要key来查找数据，还会需要用score查找数据。 细化一下Redis有序集合的操作： 添加一个成员对象 按照键值来删除一个成员对象 按照键值来查找一个成员对象 按照分值区间查找数据，比如查找积分在[100, 356] 之间的成员对象 按照分值从小到大排序成员变量 如果只按照分支将成员对象组织成跳表的结构，那么按照键值删除、查询对象就会很慢。 我们可以按照键值构建一个散列表，这样按照key来删除、查找一个对象的时间复杂度就都变成了O(1)。 Java中的LinkedHashMapJava 中的LinkedHashMap中的Linked并不是链表法表示散列表的意思，而是双向链表和散列表结合。 LinkedHashMap本身就是一个支持LRU缓存淘汰策略的缓存系统，其数据的存取移动删除规则和LRU一样。 思考今天讲的几个散列表和链表结合使用的例子里，我们用的都是双向链表。如果把双向链表改成单链表，还能否正常工作呢？为什么呢？ 不能，影响查询性能 假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。 假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作： 根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息 ID 为 KEY，散列表可以实现快速查询，链表法可以实现删除更新。 查找积分在某个区间的猎头 ID 列表 遍历散列表查询积分对应的 ID 列表 查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 … 遍历散列表","tags":"algorithms 数据结构与算法 hashtable 哈希表 散列表"},{"title":"Beauty Of Algorithms 16 Summary. Skiplist","url":"/2019/02/06/beauty-of-algorithms-16-summary-skiplist/","text":"跳表的概念对链表建立n级索引，例如每两个结点提取一个节点到上一层，称之为索引层。图中的down表示down指针，指向下一级结点 跳表的时间复杂度跳表的高度 跳表的高度是log2n 跳表的时间复杂度 跳表中查询某个数据的时间复杂度是O(logn) 跳表的空间复杂度及优化跳表的空间复杂度 跳表的空间复杂度为O(n) 优化时间复杂度 如果链表有n个节点，每3或5个节点抽取抽出一个节点作为上一级索引的节点， 虽然跳表的空间复杂度仍然是O(n)，但和每2个节点抽取一次相比占用的内存空间少了很多。 高效的动态插入和删除时间复杂度 跳表本质上就是链表，所以仅插作，插入和删除操时间复杂度就为O(1)， 但在实际情况中，要插入或删除某个节点，需要先查找到指定位置，而这个查找操作比较费时。 在跳表中查找操作的时间复杂度是O(logn)，因此跳表的插入和删除操作的是时间复杂度也是O(logn)。 跳表索引动态更新 当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中， 可以通过随机函数来决定将这个节点插入到哪几级索引中，比如随机函数生成了值K，那就可以把这个节点添加到第1级到第K级索引中。 跳表代码实现参考","tags":"algorithms 数据结构与算法 skiplist 跳表"},{"title":"Beauty Of Algorithms 15 Summary. BinarySearch","url":"/2019/02/05/beauty-of-algorithms-15-summary-binary-search/","text":"二分查找针对的是一个有序的数据集合，每次通过跟区间中间的元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间缩小为0。 时间复杂度是O(logn) 二分查找实现123456789101112131415161718192021222324252627282930public class BinarySearch &#123; private int[] array; private BinarySearch(int[] array) &#123; this.array = array; &#125; private int binarySearch(int value) throws Exception &#123; int lo = 0; int hi = array.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (array[mid] == value) &#123; return mid; &#125; else if (array[mid] &gt; value) &#123; hi = mid - 1; &#125; else &#123; lo = mid + 1; &#125; &#125; return -1; &#125; public static void main(String[] args) throws Exception &#123; int[] array = &#123; 1, 3, 6, 8, 9 &#125;; BinarySearch binarySearch = new BinarySearch(array); System.out.println(binarySearch.binarySearch(9)); &#125;&#125; 注意事项 循环退出条件是：start&lt;=end，而不是start&lt;end。 mid的取值可以优化，如使用mid=start + (end - start) / 2，而不用mid=(start + end)/2，因为如果start和end比较大的话，求和可能会发生int类型的值超出最大范围。 为了把性能优化到极致，可以将除以2转换成位运算，即start + ((end - start) &gt;&gt; 1)，相比除法运算来说，计算机处理位运算要快得多。 start和end的更新：start = mid - 1，end = mid + 1，若直接写成start = mid，end=mid，就可能会发生死循环。 使用条件 二分查找依赖的是顺序表结构，即数组 二分查找针对的是有序数据，因此只能用在插入、删除操作不频繁，一次排序多次查找的场景中 数据量太小不适合二分查找，与直接遍历相比效率提升不明显。但有一个例外，就是数据之间的比较操作非常费时，比如数组中存储的都是长度超过300的字符串，那这是还是尽量减少比较操作使用二分查找吧 数据量太大也不是适合用二分查找，因为数组需要连续的空间，若数据量太大，往往找不到存储如此大规模数据的连续内存空间 四种常见的二分查找变形问题查找第一个值等于给定值的元素 12345678910111213141516171819202122/* * 查找第一个值等于给定值的元素 */public int binarySearch(int value)&#123; int lo = 0; int hi = array.length -1; while (lo &lt;= hi)&#123; int mid = lo + (hi - lo)/2; if (array[mid] &gt; value)&#123; hi = mid -1; &#125;else if (array[mid]&lt;value)&#123; lo = mid +1; &#125;else &#123; if (mid == 0 || array[mid -1]!= value)&#123; return mid; &#125;else &#123; hi = mid -1; &#125; &#125; &#125; return -1;&#125; 查找最后一个值等于给定值的元素 12345678910111213141516171819202122/* * 查找最后一个值等于给定值的元素 */public int binarySearch3(int value) &#123; int lo = 0; int hi = array.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (array[mid] &gt; value) &#123; hi = mid - 1; &#125; else if (array[mid] &lt; value) &#123; lo = mid + 1; &#125; else &#123; if (mid == array.length - 1 || array[mid + 1] != value) &#123; return mid; &#125; else &#123; lo = mid + 1; &#125; &#125; &#125; return -1;&#125; 查找第一个大于等于给定值的元素 1234567891011121314151617181920/* * 查找第一个大于等于给定值的元素 */public int binarySearch(int value) &#123; int lo = 0; int hi = array.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (array[mid] &gt;= value) &#123; if (mid == 0 || array[mid - 1] &lt; value) &#123; return mid; &#125; else &#123; hi = mid - 1; &#125; &#125; else &#123; lo = mid + 1; &#125; &#125; return -1;&#125; 查找最后一个小于等于给定值的元素 12345678910111213141516171819/* * 查找最后一个小于等于给定值的元素 */public int binarySearch5(int value) &#123; int lo = 0; int hi = array.length - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; if (array[mid] &lt;= value) &#123; if (mid == (array.length - 1) || array[mid + 1] &gt; value) &#123; return mid; &#125; else &#123; lo = mid + 1; &#125; &#125; else &#123; hi = mid - 1; &#125; &#125; 适用性分析凡是能用二分查找解决的，绝大部分我们更倾向于用散列表或者二叉查找树， 即便二分查找在内存上更节省，但是毕竟内存如此紧缺的情况并不多。 求“值等于给定值”的二分查找确实不怎么用到，二分查找更适合用在”近似“查找问题上。比如上面讲几种变体。","tags":"algorithms 数据结构与算法 binarysearch 二分查找"},{"title":"Beauty Of Algorithms 14 Summary. Sorting Enhancement","url":"/2019/02/04/beauty-of-algorithms-14-summary-sorting-enhancement/","text":"排序算法的选择与优化 选择排序算法的原则 线性排序时间复杂度很低但使用场景特殊，如果要写一个通用排序函数，不能选择线性排序 为了兼顾任意规模数据的排序，一般会首选时间复杂度为O(nlogn)的排序算法来实现排序函数 同为O(nlogn)的快排和归并排序相比，归并排序不是原地排序算法，所以最优的选择是快排 优化快速排序导致快排时间复杂度降为O(n^2)的原因是分区点选择不合理，最理想的分区点是： 被分区点分开的两个分区中，数据的数量差不多。 优化分区点有2种常用方法： 三数取中法 从区间的首、中、尾分别取一个数，然后比较大小，取中间值作为分区点 如果要排序的数组比较大，那三数取中可能就不够用了，可能要五数取中或者十数取中 随机法 每次从要排序的区间中，随机选择一个元素作为分区点 递归发生堆栈溢出的解决方法 限制递归深度，一旦递归超过了设置的阈值就停止递归 在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈过程，这样就没有系统栈大小的限制 通用排序函数实现技巧 数据量不大时，可以采取用空间换时间的思路 数据量大时，优化快排分区点的选择 防止堆栈溢出，可以选择在堆上手动模拟调用栈解决 在排序区间中，当元素个数小于某个常数是，可以考虑使用O(n^2)级别的插入排序 用哨兵简化代码，每次排序都减少一次判断，尽可能把性能优化到极致","tags":"algorithms 数据结构与算法"},{"title":"Beauty Of Algorithms 13 Summary. Linear Sorting","url":"/2019/02/03/beauty-of-algorithms-13-summary-linear-sorting/","text":"线性排序的概念 线性排序算法包括桶排序、计数排序、基数排序。 线性排序算法的时间复杂度为O(n)。线性排序的特点 此3种排序算法都不涉及元素之间的比较操作，是非基于比较的排序算法。 对排序数据的要求很苛刻，重点掌握此3种排序算法的适用场景。 桶排序算法原理 将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行快速排序 桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了 使用条件 要排序的数据需要很容易就能划分成m个桶，并且桶与桶之间有着天然的大小顺序 数据在各个桶之间分布是均匀的 代码实现 1234567891011121314151617181920212223242526272829303132333435363738/** * 桶排序 * BucketSort */public class BucketSort &#123; private int[] buckets; private int[] array; //声明成绩在1-10范围的10个桶 public BucketSort(int range,int[] array)&#123; this.buckets = new int[range]; this.array = array; &#125; public void sort()&#123; if(array!=null &amp;&amp; array.length &gt;0)&#123; for (int i = 0; i &lt; array.length; i++) &#123; buckets[array[i]]++; &#125; &#125; &#125; public void sortOut()&#123; for (int i = 0; i &lt; buckets.length; i++) &#123; for (int j = 0; j &lt; buckets[i]; j++) &#123; System.out.print(i +\" \\t\"); &#125; &#125; &#125; public static void main(String[] args) &#123; int[] array = &#123;5,7,3,5,4,8,6,4,1,2&#125;; BucketSort bucketSort = new BucketSort(10, array); bucketSort.sort() bucketSort.sortOut(); &#125;&#125; 适用场景 桶排序比较适合用在外部排序中 外部排序就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存中 应用案例 需求描述 有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序，但内存有限，仅几百MB 解决思路 扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶 第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推 每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99） 将100个小文件依次放入内存并用快排排序 所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可 若单个文件无法全部载入内存，则针对该文件继续细分数据过多的部分，按照前面的思路进行处理 计数排序算法原理 计数其实就是桶排序的一种特殊情况 当要排序的n个数据所处范围并不大时，比如最大值为k，则分成k个桶 每个桶内的数据值都是相同的，就省掉了桶内排序的时间 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041// 计数排序，a 是数组，n 是数组大小。假设数组中存储的都是非负整数。public void countingSort(int[] a, int n) &#123; if (n &lt;= 1) return; // 查找数组中数据的范围 int max = a[0]; for (int i = 1; i &lt; n; ++i) &#123; if (max &lt; a[i]) &#123; max = a[i]; &#125; &#125; int[] c = new int[max + 1]; // 申请一个计数数组 c，下标大小 [0,max] for (int i = 0; i &lt;= max; ++i) &#123; c[i] = 0; &#125; // 计算每个元素的个数，放入 c 中 for (int i = 0; i &lt; n; ++i) &#123; c[a[i]]++; &#125; // 依次累加 for (int i = 1; i &lt;= max; ++i) &#123; c[i] = c[i-1] + c[i]; &#125; // 临时数组 r，存储排序之后的结果 int[] r = new int[n]; // 计算排序的关键步骤，有点难理解 for (int i = n - 1; i &gt;= 0; --i) &#123; int index = c[a[i]]-1; r[index] = a[i]; c[a[i]]--; &#125; // 将结果拷贝给 a 数组 for (int i = 0; i &lt; n; ++i) &#123; a[i] = r[i]; &#125;&#125; 案例分析 假设只有8个考生分数在0-5分之间，成绩存于数组A[8] = [2，5，3，0，2，3，0，3]。 使用大小为6的数组C[6]表示桶，下标对应分数，即0，1，2，3，4，5。 C[6]存储的是考生人数，只需遍历一边考生分数，就可以得到C[6] = [2，0，2，3，0，1]。 对C[6]数组顺序求和则C[6]=[2，2，4，7，7，8]，c[k]存储的是小于等于分数k的考生个数。 数组R[8] = [0，0，2，2，3，3，3，5]存储考生名次。那么如何得到R[8]的呢？ 从后到前依次扫描数组A，比如扫描到3时，可以从数组C中取出下标为3的值7，也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R的第7个元素（也就是数组R中下标为6的位置）。 当3放入数组R后，小于等于3的元素就剩下6个了，相应的C[3]要减1变成6。 以此类推，当扫描到第二个分数为3的考生时，就会把它放入数组R中第6个元素的位置（也就是下标为5的位置）。当扫描完数组A后，数组R内的数据就是按照分数从小到大排列的了。 使用条件 只能用在数据范围不大的场景中，若数据范围k比要排序的数据n大很多，就不适合用计数排序 计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数 比如如果考试成绩精确到小数后一位，就需要将所有分数乘以10，转换为整数 基数排序算法原理 以排序10万个手机号为例来说明 比较两个手机号码a，b的大小，如果在前面几位中a已经比b大了，那后面几位就不用看了借助稳定排序算法的思想，可以先按照最后一位来排序手机号码，然后再按照倒数第二位来重新排序，以此类推，最后按照第一个位重新排序 经过11次排序后，手机号码就变为有序的了 每次排序有序数据范围较小，可以使用桶排序或计数排序来完成 使用条件 要求数据可以分割独立的“位”来比较 位之间由递进关系，如果a数据的高位比b数据大，那么剩下的地位就不用比较了 每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到O(n)","tags":"algorithms 数据结构与算法 linearsorting 线性排序"},{"title":"Beauty Of Algorithms 12 Summary. Sorting 2","url":"/2019/02/02/beauty-of-algorithms-12-summary-sorting-2/","text":"分治思想分治，顾明思意就是分而治之，将一个大问题分解成小的子问题来解决，小的子问题解决了，大问题也就解决了。 分治与递归的区别 分治算法一般都用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。 归并排序算法原理归并的思想 先把数组从中间分成前后两部分，然后对前后两部分分别进行排序，再将排序好的两部分合并到一起，这样整个数组就有序了。 这就是归并排序的核心思想。如何用递归实现归并排序呢？ 写递归代码的技巧就是分写得出递推公式，然后找到终止条件，最后将递推公式翻译成递归代码。 递推公式 merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r)) 终止条件 p = r 不用再继续分解 代码实现使用哨兵可以简化代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.Arrays;public class MergeSort &#123; public static void merge(int[] a, int begin, int end) &#123; if (begin == end) &#123; return; &#125; if (begin &lt; end) &#123; int mid = (begin + end) / 2; merge(a, begin, mid); merge(a, mid + 1, end); mergeAndSort(a, begin, mid, end); &#125; &#125; public static void mergeAndSort(int[] a, int begin, int mid, int end) &#123; int[] left = new int[mid - begin + 2]; int[] right = new int[end - mid + 1]; for (int i = begin; i &lt;= end; i++) &#123; if (i &lt;= mid) &#123; left[i - begin] = a[i]; &#125; else &#123; right[i - mid - 1] = a[i]; &#125; &#125; left[mid - begin + 1] = Integer.MAX_VALUE; right[end - mid] = Integer.MAX_VALUE; int i = 0; int j = 0; int index = begin; while (index &lt;= end) &#123; a[index++] = left[i] &lt; right[j] ? left[i++] : right[j++]; &#125; &#125; public static void main(String[] args) &#123; int[] a = &#123;1, 9, 5, 7, 4, 6, 3, 8, 11, 24&#125;; merge(a, 0, a.length - 1); System.out.println(Arrays.toString(a)); //打印结果为：[1, 3, 4, 5, 6, 7, 8, 9, 11, 24] &#125;&#125; 性能分析算法稳定性 归并排序是一种稳定排序算法。 时间复杂度 归并排序的时间复杂度是O(nlogn)。 空间复杂度 归并排序算法不是原地排序算法，空间复杂度是O(n) 因为归并排序的合并函数，在合并两个数组为一个有序数组时，需要借助额外的存储空间 快速排序一般情况下，快速排序被认为是最快的排序算法（人如其名啊），因此可以说是最常用的排序算法，并受大多数公司的青睐，是一定要熟练掌握的。 算法原理快排的思想 如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点）。然后遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将povit放到中间。 经过这一步之后，数组p到r之间的数据就分成了3部分，前面p到q-1之间都是小于povit的，中间是povit，后面的q+1到r之间是大于povit的。 根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。 递推公式 quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r) 终止条件 p &gt;= r 代码实现左右两个指针分别向左向右移动，取最后一位做临界值，左边遇到比这个值大的，就交换，换反方向指针比较，遇到比这个值小的，再次交换。 参考这里 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.Arrays;public class QuickSort &#123; public static void quickSort(int[] a, int begin, int end) &#123; if (end &lt;= begin) &#123; return; &#125; int i = begin; int j = end; int tmp = a[end]; boolean tag = true; while (i != j) &#123; if (tag) &#123; if (a[i] &lt;= tmp) &#123; i++; continue; &#125; else &#123; a[j] = a[i]; j--; tag = false; &#125; &#125; else &#123; if (a[j] &gt;= tmp) &#123; j--; continue; &#125; else &#123; a[i] = a[j]; i++; tag = true; &#125; &#125; &#125; a[i] = tmp; quickSort(a, begin, i - 1); quickSort(a, i + 1, end); &#125; public static void main(String[] args) &#123; int[] a = &#123;5, 7, 8, 2, 6, 125, 6, 41, 341, 34, 63, 28, 97&#125;; quickSort(a, 0, a.length - 1); System.out.println(Arrays.toString(a)); &#125;&#125; 性能分析算法稳定性 快速排序是不稳定的排序算法。 时间复杂度 如果每次分区操作都能正好把数组分成大小接近相等的两个小区间， 那快排的时间复杂度递推求解公式跟归并的相同。快排的时间复杂度也是O(nlogn)。 如果数组中的元素原来已经有序了，快排的时间复杂度就是O(n^2)。 前面两种情况，一个是分区及其均衡，一个是分区极不均衡， 它们分别对应了快排的最好情况时间复杂度和最坏情况时间复杂度。 T(n)大部分情况下是O(nlogn)，只有在极端情况下才是退化到O(n^2)。 空间复杂度 快排是一种原地排序算法，空间复杂度是O(1) 归并排序与快速排序的区别归并排序 先递归调用，再进行合并，合并的时候进行数据的交换。所以它是自下而上的排序方式。 何为自下而上？就是先解决子问题，再解决父问题。 快速排序 先分区，在递归调用，分区的时候进行数据的交换。所以它是自上而下的排序方式。 何为自上而下？就是先解决父问题，再解决子问题。","tags":"algorithms 数据结构与算法 mergesorting 归并排序"},{"title":"Beauty Of Algorithms 11 Summary. Sorting 1","url":"/2019/02/01/beauty-of-algorithms-11-summary-sorting-1/","text":"排序方法冒泡排序、插入排序、选择排序、快速排序、归并排序、计数排序、基数排序、桶排序。 复杂度归类冒泡排序、插入排序、选择排序 O(n^2) 快速排序、归并排序 O(nlogn) 计数排序、基数排序、桶排序 O(n) 算法的执行效率 最好、最坏、平均情况时间复杂度 时间复杂度的系数、常数和低阶 比较次数，交换（或移动）次数 排序算法的稳定性稳定性概念 如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 稳定性重要性 可针对对象的多种属性进行有优先级的排序。 排序算法的内存损耗 原地排序算法：特指空间复杂度是O(1)的排序算法。 冒泡排序冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求，如果不满足就让它俩互换。 稳定性 冒泡排序是稳定的排序算法。 空间复杂度 冒泡排序是原地排序算法。 时间复杂度 最好情况：O(n)。 最坏情况：O(n^2)。 平均情况：平均时间复杂度为O(n^2)。 12345678910111213public void sort(T[] num) &#123; int N = num.length; boolean isSorted = false; for (int i = N - 1; i &gt; 0 &amp;&amp; !isSorted; i--) &#123; isSorted=true; for (int j = 0; j &lt;i ; j++) &#123; if (less(num[j+1],num[j]))&#123; isSorted=false; swap(num,j,j+1); &#125; &#125; &#125;&#125; 插入排序插入排序将数组数据分成已排序区间和未排序区间。初始已排序区间只有一个元素，即数组第一个元素。 在未排序区间取出一个元素插入到已排序区间的合适位置，直到未排序区间为空。 稳定性 插入排序是稳定的排序算法。 空间复杂度 插入排序是原地排序算法。 时间复杂度 \\1. 最好情况：O(n)。 \\2. 最坏情况：O(n^2)。 \\3. 平均情况：O(n^2)。 12345678public void sort(T[] num) &#123; int N = num.length; for (int i = 1; i &lt; N; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(num[j], num[j - 1]); j--) &#123; swap(num, j, j - 1); &#125; &#125;&#125; 选择排序选择排序将数组分成已排序区间和未排序区间。初始已排序区间为空。 每次从未排序区间中选出最小的元素插入已排序区间的末尾，直到未排序区间为空。 稳定性 选择排序不是稳定的排序算法。 空间复杂度 选择排序是原地排序算法。 时间复杂度 都是O(n^2)） 1234567891011public void sort(T[] a) &#123; for (int i = 0; i &lt; a.length; i++) &#123; int min = i; for (int j = i + 1; j &lt; a.length; j++) &#123; if (less(a[j], a[min])) &#123; min = j; &#125; &#125; swap(a, i, min); &#125;&#125; 思考冒泡排序和插入排序的时间复杂度相同都是O(n^2)，为什么插入排序比冒泡排序更受欢迎？ 参考这里 对于部分有序的小区间 N，冒泡排序需要排序 N次，而插入排序效率更高 对于冒泡排序可以改进（参考代码），如果循环完没有做任何交换，说明已经是有序的 如果数据存储在链表中，三种排序方法的时间复杂会变成怎样？ 假定只能改变节点位置 冒泡排序，比较次数不变，因为指针，交换数据更加复杂。 插入排序，比较次数不变，但可以直接插入数据，不需要一个个地后移数据。 选择排序，比较次数不变，因为指针，交换数据更加复杂。","tags":"algorithms 数据结构与算法 sorting 排序"},{"title":"Beauty Of Algorithms 10 Summary. Recursion","url":"/2019/01/31/beauty-of-algorithms-10-summary-recursion/","text":"递归的概念递归是一种非常高效、简洁的编码技巧，一种应用非常广泛的算法。 比如DFS深度优先搜索、前中后序二叉树遍历等都是使用递归。 方法或函数调用自身的方式称为递归调用，调用称为递，返回称为归。 基本上，所有的递归问题都可以用递推公式来表示，比如 123f(n) = f(n-1) + 1;f(n) = f(n-1) + f(n-2);f(n)=n*f(n-1); 递归需要满足三个条件 一个问题的解可以分解为几个子问题的解。 问题与分解后的子问题除了数据规模不同，求解思路完全相同。 存在递归终止条件。 递归的优缺点 优点 代码的表达力很强，写起来简洁。 缺点 空间复杂度高、有堆栈溢出风险、存在重复计算、过多的函数调用会耗时较多等问题。 实现递归递归代码的编写写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。 递归代码理解对于递归代码，若试图想清楚整个递和归的过程，实际上是进入了一个思维误区。 那该如何理解递归代码呢？如果一个问题A可以分解为若干个子问题B、C、D，你可以假设子问题B、C、D已经解决。而且，你只需要思考问题A与子问题B、C、D两层之间的关系即可，不需要一层层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。 因此，理解递归代码，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。 递归的常见问题及解决方案 警惕堆栈溢出，可以声明一个全局变量来控制递归的深度，从而避免堆栈溢出。 警惕重复计算通过某种数据结构来保存已经求解过的值，从而避免重复计算。 递归改写为非递归代码笼统的讲，所有的递归代码都可以改写为迭代循环的非递归写法。 抽象出递推公式、初始值和边界条件，然后用迭代循环实现。","tags":"algorithms 数据结构与算法 recursion 递归"},{"title":"Beauty Of Algorithms 9 Summary. Queue","url":"/2019/01/30/beauty-of-algorithms-9-summary-queue/","text":"队列的概念 先进者先出 支持两个操作：入队 enqueue()，放一个数据到队尾；出队 dequeue()，从队头取一个元素。 队列也是一种操作受限的线性表 数组实现 ( 顺序队列 ) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ArrayQueue &#123; private String[] items; private int n = 0; private int head = 0; private int tail = 0; public ArrayQueue(int n) &#123; items = new String[n]; this.n = n; &#125; public void enqueue(String item) throws Exception &#123; if (tail == n) &#123; throw new Exception(\"queue is full , cant enter any more !\"); &#125; items[tail] = item; tail++; &#125; public String dequeue() throws Exception &#123; if (head == tail) &#123; throw new Exception(\"queue is empty !\"); &#125; String ret = items[head]; head++; return ret; &#125; public void printQueue() &#123; for (int i = head; i &lt; tail; i++) &#123; System.out.print(items[i] + \" \"); &#125; &#125; public static void main(String[] args) throws Exception &#123; ArrayQueue arrayQueue = new ArrayQueue(10); arrayQueue.enqueue(\"1\"); arrayQueue.enqueue(\"2\"); arrayQueue.enqueue(\"3\"); arrayQueue.enqueue(\"4\"); arrayQueue.enqueue(\"4\"); arrayQueue.printQueue(); System.out.println(\" \"); System.out.println(\"***************************\"); System.out.println(arrayQueue.dequeue()); System.out.println(\"***************************\"); arrayQueue.printQueue(); &#125;&#125; 假溢出以上代码中的出队入队会造成假溢出现象，即随着不断的出队，head在增加，head前面的数组空间是被空着的。 修改入队方法 1234567891011121314public void enqueue2(String item) throws Exception &#123; if (tail == n) &#123; if (head == 0) &#123; throw new Exception(\"queue is full , cant enter any more !\"); &#125; for (int i = head; i &lt; tail; i++) &#123; items[i - head] = items[i]; &#125; tail -= head; head = 0; &#125; items[tail] = item; tail++;&#125; 链表实现 链表无需考虑溢出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class SingleLinkQueue&lt;T&gt; &#123; private class Node&lt;T&gt; &#123; private T data; private Node&lt;T&gt; next; public Node(T data, Node&lt;T&gt; next) &#123; this.data = data; this.next = next; &#125; &#125; private Node&lt;T&gt; tail; private Node&lt;T&gt; head; private int size; public SingleLinkQueue() &#123; head = tail = null; &#125; public void enqueue(T item) &#123; Node&lt;T&gt; node = new Node&lt;T&gt;(item, null); if (head == null) &#123; head = node; tail = node; &#125; tail.next = node; tail = node; size++; &#125; public T dequeue() throws Exception &#123; if (head == null) &#123; throw new Exception(\"Queue is empty, no element to dequeue !\"); &#125; T ret = head.data; head = head.next; size--; return ret; &#125; public void printQueue()&#123; Node&lt;T&gt; tem = head; while (tem!= null)&#123; System.out.print(tem.data + \" \"); tem = tem.next; &#125; &#125; public static void main(String[] args) throws Exception &#123; SingleLinkQueue&lt;String&gt; singleLinkQueue = new SingleLinkQueue&lt;&gt;(); singleLinkQueue.enqueue(\"1\"); singleLinkQueue.enqueue(\"2\"); singleLinkQueue.enqueue(\"3\"); singleLinkQueue.enqueue(\"4\"); singleLinkQueue.printQueue(); System.out.println(\"\\n***************************\"); System.out.println(singleLinkQueue.dequeue()); System.out.println(\"***************************\"); singleLinkQueue.printQueue(); &#125;&#125; 循环队列 ( 基于数组 ) 循环队列可以实现不进行数据搬移而解决假溢出现象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class CircularQueue &#123; private String[] items; int n = 0; int head = 0; int tail = 0; public CircularQueue(int n) &#123; this.n = n; items = new String[n]; &#125; public void enqueue(String item) throws Exception &#123; if ((tail + 1) % n == head) &#123; throw new Exception(\"queue is full ,cant enqueue any more items !\"); &#125; items[tail] = item; tail = (tail + 1) % n; &#125; public String dequeue() throws Exception &#123; if (tail == head) &#123; throw new Exception(\"queue is empty !\"); &#125; String ret = items[head]; head = (head + 1) % n; return ret; &#125; public void printQueue() &#123; for (int i = head; i % n != tail; i++) &#123; System.out.print(items[i] + \" \"); &#125; &#125; public static void main(String[] args) throws Exception &#123; CircularQueue circularQueue = new CircularQueue(10); circularQueue.enqueue(\"1\"); circularQueue.enqueue(\"2\"); circularQueue.enqueue(\"3\"); circularQueue.enqueue(\"4\"); circularQueue.enqueue(\"4\"); circularQueue.printQueue(); System.out.println(\" \"); System.out.println(\"***************************\"); System.out.println(circularQueue.dequeue()); System.out.println(\"***************************\"); circularQueue.printQueue(); &#125;&#125; 队列的常见应用阻塞队列 在队列的基础上增加阻塞操作，就成了阻塞队列。 阻塞队列就是在队列为空的时候，从队头取数据会被阻塞，因为此时还没有数据可取，直到队列中有了数据才能返回； 如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后在返回。 从上面的定义可以看出这就是一个“生产者-消费者模型”。 这种基于阻塞队列实现的“生产者-消费者模型”可以有效地协调生产和消费的速度。 当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了， 这时生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续生产。 不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据处理效率， 比如配置几个消费者，来应对一个生产者。 并发队列 在多线程的情况下，会有多个线程同时操作队列，这时就会存在线程安全问题。能够有效解决线程安全问题的队列就称为并发队列。 并发队列简单的实现就是在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或取操作 实际上，基于数组的循环队列利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 线程池资源枯竭时的处理在资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。 思考如何实现无锁的并发队列？","tags":"algorithms 数据结构与算法 queue 队列"},{"title":"Beauty Of Algorithms 8 Summary. Stack","url":"/2019/01/29/beauty-of-algorithms-8-summary-stack/","text":"什么是栈 后进者先出，先进者后出，这就是典型的 ”栈“ 结构 从栈的操作特性来看，是一种“操作受限”的线性表，只允许在端插入和删除数据 为什么需要栈 栈是一种操作受限的数据结构，其操作特性用数组和链表均可实现。 但任何数据结构都是对特定应用场景的抽象，数组和链表虽然使用起来更加灵活，但却暴露了几乎所有的操作，难免会引发错误操作的风险。 所以，当某个数据集合只涉及在某端插入和删除数据，且满足后进者先出，先进者后出的操作特定时，我们应该首选栈这种数据结构。 如何实现栈数组实现使用数组实现固定容量的栈 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ArrayStack &#123; private String[] data; private int count; private int maxSize; public ArrayStack(int maxSize) &#123; data = new String[maxSize]; this.maxSize = maxSize; count = 0; &#125; public void push(String item) throws Exception &#123; if (count == maxSize - 1) &#123; throw new Exception(\"stack is full ,cant push anymore !\"); &#125; data[count] = item; count++; &#125; public String pop() throws Exception &#123; if (count == 0) &#123; throw new Exception(\"Stack is empty, no element to pop !\"); &#125; String top = data[count-1]; count--; return top; &#125; public void printStack() &#123; for (int i = this.count-1; i &gt;=0; i--) &#123; System.out.println(this.data[i]); &#125; &#125; public static void main(String[] args) throws Exception &#123; ArrayStack arrayStack = new ArrayStack(5); arrayStack.push(\"1\"); arrayStack.push(\"2\"); arrayStack.push(\"3\"); arrayStack.printStack(); System.out.println(\"***************************\"); System.out.println(arrayStack.pop()); System.out.println(\"***************************\"); arrayStack.printStack(); &#125;&#125; 数组实现自动扩容 改进代码： 12345678910111213//入栈方法 public void push(String item) throws Exception &#123; if (count == maxSize) &#123; maxSize = count * 2; String[] tmp = data; data = new String[maxSize]; for (int i = 0; i &lt;count ; i++) &#123; data[i] = tmp[i]; &#125; &#125; data[count] = item; count++; &#125; 链表实现单链表栈： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class SingleLinkedStack&lt;T&gt; &#123; private class Node&lt;T&gt; &#123; private T data; private Node&lt;T&gt; next; public Node(T data, Node&lt;T&gt; next) &#123; this.data = data; this.next = next; &#125; &#125; private Node&lt;T&gt; top; public SingleLinkedStack() &#123; top = null; &#125; public void push(T t)&#123; Node node = new Node(t,top); top = node; &#125; public T pop() throws Exception &#123; if (top == null)&#123; throw new Exception(\"Stack is empty, no element to pop !\"); &#125; Node&lt;T&gt; node = top; top = top.next; return node.data; &#125; public void printStack(Node&lt;T&gt; top)&#123; while (top != null)&#123; System.out.println(top.data); top = top.next; &#125; &#125; public static void main(String[] args) throws Exception &#123; SingleLinkedStack&lt;String&gt; singleLinkedStack = new SingleLinkedStack&lt;&gt;(); singleLinkedStack.push(\"1\"); singleLinkedStack.push(\"2\"); singleLinkedStack.push(\"3\"); singleLinkedStack.printStack(singleLinkedStack.top); System.out.println(\"***************************\"); System.out.println(singleLinkedStack.pop()); System.out.println(\"***************************\"); singleLinkedStack.printStack(singleLinkedStack.top); &#125;&#125; 栈的应用栈在函数调用中的应用操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成 “栈” 这种结构，用来存储函数调用时的临时变量。 每进入一个函数，就会将其中的临时变量作为栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。 栈在表达式求值中的应用利用两个栈，其中一个用来保存操作数，另一个用来保存运算符。从左向右遍历表达式，当遇到数字，就直接压入操作数栈。当遇到运算符，就与运算符栈的栈顶元素进行比较，若比运算符栈顶元素优先级高，就将当前运算符压入栈。若比运算符栈顶元素的优先级低或者相同，从运算符栈中取出栈顶运算符，从操作数栈顶取出2个操作数，然后进行计算，把计算完的结果压入操作数栈，继续比较。 站在括号匹配中的应用用栈保存为匹配的左括号，从左到右一次扫描字符串，当扫描到左括号时候，则将其压入栈 当扫描到右括号时，从栈顶取出一个左括号，如果能匹配上，则继续扫描剩下的字符串。 如果扫描过程中，遇到不能配对的右括号，或者占中没有数据，则说明为非法格式。 当所有的括号都扫描完成后，如果栈为空，则说明字符串为合法格式；否则，说明未匹配的左括号为非法格式。 实现浏览器的前进和后退功能我们使用两个栈 X 和 Y，我们把首次浏览的页面依次压入栈 X，Y。 当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入 Y 栈。 当点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。 当栈 X 中没有数据时，说明没有页面可以继续后退浏览了。 当 Y 栈没有数据，那就说明没有页面可以点击前进浏览了。","tags":"algorithms 数据结构与算法 stack 栈"},{"title":"Beauty Of Algorithms 7 Summary. Array Or List","url":"/2019/01/28/beauty-of-algorithms-7-summary-array-or-list/","text":"数组和链表的总结和比较 选择数组还是链表插入、删除和随机访问的时间复杂度 数组的缺点 若申请内存空间很大，比如 100 M ,但若内存空间没有 100 M 的连续空间是，则会申请失败，尽管内存可用空间超过 100 M 。 大小固定，若空间存储不足，需要进行扩容，一旦扩容就要进行数据复杂，而这是非常费时的。 链表的缺点 内存空间消耗更大，因为需要额外的空间存储指针信息。 对链表进行频繁的插入和删除操作，会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，还可能会造成频繁的 GC (自动辣鸡回收器) 操作。 如何选择链表和数组 数组简单易用，在实现上使用连续的内存空间，可以借助 CPU 的缓冲机制预读数组中的数据，所以访问效率更高。 而链表在内存中并不是连续存储的，所以为 CPU 缓存不友好，没办法预读。 如果代码对内存的使用非常苛刻，那数组就更适合。","tags":"algorithms 数据结构与算法 array 数组 链表 list"},{"title":"Beauty Of Algorithms 6 Summary. Linked List","url":"/2019/01/27/beauty-of-algorithms-6-summary-linked-list/","text":"什么是链表和数组一样，链表也是一种线性表 从内存结构来看，链表的内存结构是不连续的内存空间，是将一组零散的内存块串联起来，从而进行数据存储的数据结构 链表中的每一个内存块被称为节点 Node 。节点除了存储数据外，还需要记录链上下一个节点的地址，即后继指针 next。 链表的特点插入、删除数据效率高，时间复杂度为 O(1)，只需要更改指针指向即可。 随机访问效率低，时间复杂度为 O(n)，需要从链头至链尾进行遍历。 和数组相比，链表的内存空间消耗更大，因为每个存储数据的节点都需要额外的空间存储后继指针。 常见的链表结构单链表 每个节点只包含一个指针，即后继指针。 单链表有两个特殊的节点，即首节点和尾节点。 用首节点地址表示整条链表，尾节点的后继指针指向空地址 null 。 性能特点，插入和删除节点的时间复杂度为O(1)，查找的时间复杂度为O(n)。 循环链表 除了尾节点的后继指针指向首节点的地址外均与单链表一致。 适用于存储有循环特点的数据，比如约瑟夫问题。 双向链表 节点除了存储数据外，还有两个指针分别指向前一个节点地址（前驱指针 prev ）和下一个节点地址（后继指针 next ）。 首节点的前驱指针 prev 和尾节点的后继指针 next均指向空地址。 性能特点，和单链表相比，存储相同的数据，需要消耗更多的存储空间。 插入、删除操作比单链表效率更高，时间复杂度为 O(1) 。以删除操作为例，删除操作分为两种情况 给定数据值删除对应节点 单链表和双向链表都需要从头到尾进行遍历从而找到对应节点进行删除，时间复杂度为 O(n) 。 给定节点地址删除节点 要进行删除操作必须找到前驱节点，单链表需要从头到尾进行遍历知道 p-&gt;next = q，时间复杂度为 O(n) ,而双向链表可以直接找到前驱节点，时间复杂度为 O(1) 。 和单链表相比的优势 对于一个有序链表，双向链表的按值查询效率要比单链表高一些。因为我们可以记录上次超找的位置 p ，每一次查询是，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 双向循环链表 首节点的前驱指针指向尾节点，为节点的后继指针指向首节点。 常见的链表操作 单链表反转 123456789101112131415161718private static Node reverseNode(Node head) &#123; if (head == null || head.getNext() == null) &#123; return head; &#125; Node pre = null; Node cur = head; Node next = head.getNext(); while (next != null) &#123; cur.setNext(pre); pre = cur; cur = next; next = next.getNext(); &#125; cur.setNext(pre); return cur;&#125; 链表中环的检测 123456789101112131415161718public static boolean isCircleNodeList(Node head) &#123; if (head == null) &#123; return false; &#125; Node slow = head; Node fast = head; while (fast != null &amp;&amp; fast.getNext() != null) &#123; slow = slow.getNext(); fast = fast.getNext().getNext(); if (fast == null) &#123; return false; &#125; else if (slow == fast) &#123; return true; &#125; &#125; return false;&#125; 两个有序链表合并 1234567891011121314151617181920212223242526public static Node mergeNode(Node head1, Node head2) &#123; Node guard = new Node(0); Node cur = guard; while (head1 != null &amp;&amp; head2 != null) &#123; if (head1.val &lt;= head2.val) &#123; while (head1 != null &amp;&amp; head1.val &lt;= head2.val) &#123; cur.next = head1; head1 = head1.next; cur = cur.next; &#125; &#125; else &#123; while (head2 != null &amp;&amp; head2.val &lt; head1.val) &#123; cur.next = head2; head2 = head2.next; cur = cur.next; &#125; &#125; &#125; if (head1 != null) &#123; cur.next = head1; &#125; if (head2 != null) &#123; cur.next = head2; &#125; return guard.next;&#125; 删除链表倒数第 n 个节点 1234567891011121314151617181920public static Node deleteLastK(Node head, int K) &#123; if (K &lt; 1 || head == null) &#123; return head; &#125; Node guard = new Node(0); guard.next=head; Node slow = guard; Node fast = guard; for (int i = 0; i &lt; K; i++) &#123; if (fast!= null)&#123; fast=fast.next; &#125; &#125; while (fast != null &amp;&amp; fast.next!= null)&#123; slow = slow.next; fast = fast.next; &#125; slow.next = slow.next.next; return guard.next;&#125; 求链表的中间节点 123456789101112public static Node findMiddle(Node head) &#123; Node slow = head; Node fast = head; if (head == null || head.next == null) &#123; return head; &#125; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow;&#125;","tags":"algorithms 数据结构与算法 linked-list 链表"},{"title":"Beauty Of Algorithms 5 Summary. Array","url":"/2019/01/26/beauty-of-algorithms-5-summary-array/","text":"什么是数组数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。线性表 线性表就是数据排成像一条线一样的结构。 常见的线性表结构：数组、链表、队列、栈等。 非线性表有：二叉树、图、堆等。连续的内存空间和相同类型的数据 优点：两个限制使得具有随机访问的特性 缺点：删除，插入数据效率低 数组如何根据下标随机访问通过寻址公式，计算出该元素存储的内存地址： a[i]_address = base_address + i * data_type_size 为何数组插入和删除低效插入 若有一个元素想往 int[n] 的第 K 个位置插入数据，需要 n-k 的位置往后移 最好情况时间复杂度 O(1)，最坏情况复杂度是 O(n) ,平均时间复杂度为 O(n) 如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第 K 个位置上的数据移到最后，然后将插入的数据直接放在第 K 个位置上，这样时间复杂度就将为 O(1) 了 删除 与插入类似，为了保持内存的连续性 最好情况时间复杂度 O(1)，最坏情况复杂度是 O(n) ,平均时间复杂度为 O(n) 提高删除效率的方法 讲多次删除操作集中在一起执行，可以先记录已经删除的数据，但是不进行数据迁移，而仅仅是记录。当发现没有更多空间存储时，在执行真正的删除操作。这也是 JVM 标记清理垃圾回收算法的核心思想 数组访问越界问题 C 语言中的数据越界是一种未决行为，一般比较难发现的逻辑错误。相比之下，Java 会有越界检查。 用数组还是容器二者的特点 数组现指定了空间大小 容器如 ArrayList 可以动态扩容 使用数组的情形 希望存储基本类型数据，可以用数组 事先知道数组的大小，并且操作简单，可以用数组 直观表示多维，可以用数组 业务开发，使用容器足够，开发框架，追求性能，首选数组。 为什么数组要从 0 开始编号由于数组是通过寻址公式，计算出该元素存储的内存地址： a[i]_address = base_address + i * data_type_size 如果数组是从 1 开始计数，那么就会变成： a[i]_address = base_address + （i-1）* data_type_size 对于 CPU 来说，多了一次执行减法的指令 当然，还有一定的历史原因。C 语言从最开始就约定使用 0 开始编号。","tags":"algorithms 数据结构与算法 array 数组"},{"title":"Beauty Of Algorithms 1~4 Summary. Introduction","url":"/2019/01/25/beauty-of-algorithms-1-4-summary-introduction/","text":"前言数据结构和算法很重要！数据结构和算法很重要！数据结构和算法很重要！ 学习数据结构和算法的目的是建立时间复杂度、空间复杂度意识，写出高质量的代码，能够设计基础框架，提升编程技能，训练逻辑思维。算法，是一种解决问题的思路和方法，有机会应用到生活和事业的其他方面。长期看来，大脑思考能力是个人最重要的核心竞争力，算法是为数不多的能够有效训练大脑思考能力的途径之一。 知识总览 复杂度分析什么是复杂度分析 数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”。 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。 为什么要进行复杂度分析 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。 如何进行复杂度分析 大O表示法 算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示 其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模。 特点 以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势， 所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。 复杂度分析法则 单段代码看高频：比如循环 多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 嵌套代码求乘积：比如递归、多重循环等 多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。 常用的复杂度级别 多项式阶 随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括 O(1)（常数阶） O(logn)（对数阶） O(n)（线性阶） O(nlogn)（线性对数阶） O(n^2)（平方阶） O(n^3)（立方阶） 非多项式阶 随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差（不常用）。包括， O(2^n)（指数阶 O(n!)（阶乘阶） 如何掌握好复杂度分析方法复杂度分析关键在于多练，所谓孰能生巧。 复杂度分析的 4 个概念 最坏情况时间复杂度 代码在最坏情况下执行的时间复杂度 最好情况时间复杂度 代码在最理想情况下执行的时间复杂度 平均时间复杂度 用代码在所有情况下执行的次数的加权平均值表示 均摊时间复杂度 在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系式，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度 为什么要引入复杂度分析的 4 个概念同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入了这 4 个概念。 代码复杂度在不同情况下出现量级差别是才需要区分这四种复杂度。大多数情况下，是不需要区分分析他们的。 如何分析平均、均摊时间复杂度平均时间复杂度 代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示 均摊时间复杂度 两个条件满足时使用： 代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度 低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度","tags":"algorithms 数据结构与算法"},{"title":"OS Summary 8 - 页面置换算法","url":"/2018/12/29/os-lecture-8-summary/","text":"功能：当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面 目标 尽可能减少页面的调入调出次数 把未来不再访问或短期内不访问的页面调出 最优页面置换算法 ( OPT , optimal )置换在未来最长时间不访问的页面，理想情况 先进先出算法（First-In First-Out, FIFO）基本思路：选择在内存驻留时间最长的页面进行置换 算法实现 维护一个记录所有位于内存中的逻辑页面链表 链表元素按驻留内存的时间排序，链首最长，链尾最短 出现缺页时，选择链首页面进行置换，新页面加到链尾 算法特征 实现简单 性能较差，调出的页面可能是经常访问的 进程分配物理页面数增加时，缺页并不一定减少( Belady 现象) 很少单独使用 最近最久未使用算法(Least Recently Used, LRU)基本思路 选择最长时间没有被引用的页面进行置换 如某些页面长时间未被访问，则它们在将来还可能会长时间不会访问 算法实现 缺页时，计算内存中每个逻辑页面的上一次访问时间 选择上一次使用到当前时间最长的页面 算法特征 最优置换算法的一种近似 LRU算法的可能实现方法 页面链表 系统维护一个按最近一次访问时间排序的页面链表 链表首节点是最近刚刚使用过的页面 链表尾节点是最久未使用的页面 访问内存时，找到相应页面，并把它移到链表之首 缺页时，置换链表尾节点的页面 活动页面栈 访问页面时，将此页号压入栈顶，并栈内相同的页号抽出 缺页时，置换栈底的页面 特征 开销比较大 时钟置换算法（Clock）基本思路 仅对页面的访问情况进行大致统计 时钟算法是LRU和FIFO的折中 最不常用算法（Least Frequently Used, LFU）基本思路 缺页时，置换访问次数最少的页面 算法实现 每个页面设置一个访问计数（多位计数） 访问页面时，访问计数加1 缺页时，置换计数最小的页面 算法特征 算法开销大 开始时频繁使用，但以后不使用的页面很难置换 解决方法 计数定期右移、衰减 LRU和LFU的区别 LRU关注多久未访问,时间越短越好 LFU关注访问次数，次数越多越好 LRU、FIFO和Clock的比较 LRU算法和FIFO本质上都是先进先出的思路 LRU依据页面的最近访问时间排序 LRU需要动态地调整顺序 FIFO依据页面进入内存的时间排序 LRU可退化成FIFO 如页面进入内存后没有被访问，最近访问时间与进入内存的时间相同 LRU算法性能较好，但系统开销较大 FIFO算法系统开销较小，会发生Belady现象 Clock算法是它们的折衷 页面访问时，不动态调整页面在链表中的顺序，仅做标记 缺页时，再把它移动到链表末尾 对于未被访问的页面，Clock和LRU算法的表现一样好 对于被访问过的页面，Clock算法不能记录准确访问顺序，而LRU算法可以","tags":"os"},{"title":"OS Summary 7 - 虚拟内存","url":"/2018/12/23/os-lecture-7-summary/","text":"背景虚拟内存是非连续内存分配的一个延续，非连续内存分配在存储空间内可以连续也可以不连续。虚拟内存是在非连续内存分配基础上，可以把一部分内容放到外存中去，让应用程序有更大的空间使用。 需求背景：增长迅速的存储需求，程序规模的增长速度远远大于存储器容量的增长速度。 解决办法 覆盖 ( overlay ) 应用程序手动把需要的指令和数据保存在内存中 交换 ( swapping ) 操作系统自动把暂时不能执行的程序保存到外存中 虚拟存储 在有限容量的内存中，以页为单位自动装入更多更大的程序 覆盖技术目标 ：在较小的可用内存中运行较大的程序 方法 ：依据程序逻辑结构，将程序划分为若干功能相对独立的模块，将不会同时执行的模块共享同一块内存区域 必要部分（常用功能）的代码和数据常驻内存 可选部分（不常用功能）放在其他程序模块中,只在需要用到时装入内存 不存在调用关系的模块可相互覆盖，共用同一块内存区域 注：不存在相互调用关系可以分成一个覆盖区 不足 ： 增加编程困难 需程序员划分功能模块，并确定模块间的覆盖关系 增加了编程的复杂度 增加执行时间 从外存装入覆盖模块 时间换空间 交换技术目标：增加正在运行或需要运行的程序的内存 实现方法： 可将暂时不能运行的程序放到外存 换入换出的基本单位是整个进程的地址空间 换出（swap out）：把一个进程的整个地址空间保存到外存； 换入（swap in）：将外存中某进程的地址空间读入到内存； 交换技术面临的问题 交换时机 只当内存空间不够或有不够的可能时换出 交换区大小 存放所有用户进程的所有内存映像的拷贝 程序换入时的重定位 采用动态地址映射的方法 覆盖和交换的对比 覆盖 只能发生在没有调用关系的模块间 程序员须给出模块间的逻辑覆盖结构 发生在运行程序的内部模块间 交换 以进程为单位 以进程为单位 发生在内存进程间 虚拟内存技术目标 只把部分程序放到内存中，从而运行比物理内存大的程序 由操作系统自动完成，无需程序员的干涉 实现进程在内存与外存之间的交换，从而获得更多的空闲内存空间 在内存和外存之间只交换进程的部分内容 局部性原理程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域 时间局部性 一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内 空间局部性 当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内 分支局部性 一条跳转指令的两次执行，很可能跳到相同的内存位置 局部性原理的意义从理论上来说，虚拟存储技术是能够实现的，而且可取得满意的效果 虚拟存储概念将不常用的部分内存块暂存到外存 原理 装载程序时只将当前指令执行需要的部分页面或段装入内存 指令执行中需要的指令或数据不在内存（称为缺页或缺段）时，处理器通知操作系统将相应的页面或段调入内存 操作系统将内存中暂时不用的页面或段保存到外存 实现方式 虚拟页式存储 在页式存储管理的基础上，增加请求调页和页面置换 当用户程序要装载到内存运行时，只装入部分页面，就启动程序运行 进程在运行中发现有需要的代码或数据不在内存时，则向系统发出缺页异常请求 操作系统在处理缺页异常时，将外存中相应的页面调入内存，使得进程能继续运行 虚拟段式存储 缺页异常 在内存中有空闲物理页面时，分配一物理页帧 f，转第 5 步 依据页面置换算法选择将被替换的物理页帧 f，对应逻辑页 q 如 q 被修改过，则把它写回外存 修改 q 的页表项中驻留位置为0 将需要访问的页 p 装入到物理页面 f 修改p的页表项驻留位为 1 ,物理页帧号为 f 重新执行产生缺页的指令 虚拟页式存储中的外存管理在何处保存未被映射的页 应能方便地找到在外存中的页面内容 交换空间（磁盘或者文件） 采用特殊格式存储未被映射的页面 注：可以用一个文件来存这些未被映射的页 虚拟页式存储中的外存选择 代码段：可执行二进制文件（代码指向相应的可执行文件） 动态加载的共享库程序段：动态调用的库文件（共享库也有相应的目标文件，所以上两项不改） 其它段：交换空间（数据段，堆栈）","tags":"os"},{"title":"OS Summary 6 - 物理内存管理:非连续内存分配","url":"/2018/12/18/os-lecture-6-summary/","text":"内容概述 背景 段机制 页机制 普通页表 快表 多级页表 页寄存器 反置页表 段页式存储管理 背景 非连续内存分配的需求背景 必须分配连续的会带来很多麻烦 不连续？找到的几率更高，但会带来新问题。比如基本块有多大。 段式：分块大 页式：分块小 设计目标 连续分配的缺点： 物理内存必须连续 存在外碎片和内碎片 内存分配的动态修改困难 内存利用率较低 非连续分配的设计目标： 提高内存利用效率和管理灵活性 允许一个程序使用非连续的物理地址空间 允许共享代码与数据 支持动态加载和动态链接 实现 非连续分配需要解决的问题： 如何实现虚拟地址和物理地址的转换：不同的逻辑地址可能位于不连续的物理区域中 软件实现（灵活，开销大） 硬件实现（够用，开销小) 非连续分配的硬件辅助机制 如何选择非连续分配中的内存分块大小？内碎片、外碎片问题？ 段式存储管理（segmentation）：块大 页式存储管理（paging）：块小 段机制段式存储管理 进程的段地址空间由多个段组成： 主代码段 子模块代码段 公用库代码段 堆栈段（stack） 堆数据（heap） 初始化数据段 符号表等 段式存储管理的目的： 更细粒度和灵活的分离域共享 段式地址空间的不连续二维结构： 虽然在逻辑地址空间中，是按这一顺序排列的，但在物理地址空间中可以不是这样的。 段访问机制 概念： 段表示访问方式和存储数据等属性相同的一段地址空间 对应一个连续的内存“块” 若干个段组成进程逻辑地址空间 段访问：逻辑地址由二元组（s，addr）表示 s——段号 addr——段内偏移 从单地址转换成“段基址+段内偏移” 段访问的硬件实现 1234• 首先从逻辑地址中得到段号和偏移量• 在段表中查找段号，得到段基址和段长度• 由MMU来判断偏移量是否合法（偏移量是否大于段长度）• 得到物理地址，在物理内存中查找相应内容 页机制页式存储管理 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） 把物理地址空间划分为大小相同的基本分配单位 2的n次方，如512,4096,8192，4k是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） 把逻辑地址空间也划分为相同大小的基本分配单位 帧和页的大小必须是相同的 页面到页帧之间的转换： 逻辑地址到物理地址的转换 页表 MMU/TLB 帧（Frame） 物理内存被划分成大小相等的帧 此时内存的物理地址可以表示成二元组（f，o），其中f是帧号，o是帧内的偏移量 物理地址的前F位可以换成帧号，后S位可以换成偏移量 F：帧号，F位，共有2^F个帧 o：帧内偏移，S位，每帧有2^S字节 物理地址=f*2^S + o 基于页帧的物理地址计算实例 假定： 地址空间为16位 页帧大小为9位（512字节） 页（Page） 进程逻辑地址空间被划分为大小相等的页 页内偏移=帧内偏移 然而页号大小≠帧号大小，因为逻辑地址是连续的，但物理地址不一定是连续的 进程逻辑地址的表示：二元组（p，o） p：页号（P位，2P个页） o：页内偏移（S位，每页有2^S字节） 页式存储中的地址映射 如何将页映射到帧？ 逻辑地址中的页号 物理地址中的帧号是不连续的 不是所有的页都有对应的帧 页表 页表保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系。 CPU从逻辑地址中得到页号和偏移量 在页表中以页号作为下标查找帧号 用帧号和偏移量组成物理地址 普通页表页表概述 页表结构 每个进程都有一个页表 每个页面对应一个页表项 随进程运行状态而动态变化（可以动态调整内存空间大小） 页表基址寄存器：PTBR，Page Table Base Register 页表项的组成： 帧号：f 页表项标志： 存在位（resident bit）：逻辑页面是否存在与之对应的物理帧 修改位（dirty bit）：对应的页面中的内容是否被修改了 引用位（clock/reference bit）：在过去一段时间内是否访问过页中的某一个存储单元 页表地址转换实例有了存在位之后，就会发现，有些逻辑页没有对应的物理帧 页式存储管理机制的性能问题 内存访问性能问题： 访问一个内存单元需要2次内存访问 第一次访问：获取页表项 第二次访问：获取数据 页表大小问题： 页表可能非常大 64位机器如果每页1024字节，那么一个页表的大小会是多少？（2^54个页面*8个多字节） 如何处理？ 缓存（Caching） 间接（Indirection）访问：切段，多级页表 快表快表和多级页表 快表（Translation Look-aside Buffer，TLB） 目标：缓存近期访问的页表项 TLB使用关联存储（associated ），具备快速访问性能 关联存储器：有一组key，可以并行地查找所有表项，得到匹配项 因为快表位于CPU中，所以它的速度快、成本高、功耗大 如果TLB命中，物理页号可以很快被获取 如果TLB未命中，对应的表项被更新到TLB中 多级页表多级页表 通过间接引用将页号分成k级 可以有效减少每级页表的长度，但是如果所有的页表项都存在，则多级页表并没有减少存储量 不过大部分进程并不会用到所有的逻辑地址空间 在x86架构中，CR3寄存器用于存储PTBR（页表基址） 页寄存器反置页表 减少页表占用的空间的一种做法 大地址空间问题 对于大地址空间（64-bits）系统，多级页表变得繁琐。 比如：5级页表 逻辑（虚拟）地址空间增长速度快于物理地址空间 页寄存器和反置页面的思路： 不让页表与逻辑地址空间的大小相对应 让页表与物理地址空间的大小相对应 页寄存器（Page Registers） 每个帧与一个页寄存器（Page Register）关联，寄存器内容包括： 使用位（Residence bit）：此帧是否被进程占用 占用页号（Occupier）：对应的页号p 保护位（Protection bits）：约定这一页的访问方式，可读，可写…… 页寄存器示例 物理内存大小：40964096=4K4KB=16MB 页面大小：4096bytes=4KB 页帧数：4096=4K 页寄存器使用的空间：8*4096=32Kbytes（假定每个页寄存器占8字节） 页寄存器带来的额外开销：32K/16M=0.2%（大约） 虚拟内存的大小：任意 页寄存器方案的特征 优点 页表大小相对于物理内存而言很小 页表大小与逻辑地址空间大小无关 缺点 页表信息对调后，需要根据帧号可找页号 在页寄存器中搜索逻辑地址中的页号 页寄存器中的地址转换 CPU生成的逻辑地址如何找对应的物理地址？ 对逻辑地址进行Hash映射，以减少搜索范围 需要解决可能的冲突 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行Hash变换 在快表中查找对应页表项 有冲突时遍历冲突项列表 查找失败时，产生异常 快表的限制 快表的容量限制 快表的功耗限制（StrongARM上快表功耗占27%） 反置页表反置页表 基于Hash映射值查找对应页表项中的帧号 进程标识与页号的Hash值可能有冲突 页表项中包括保护位、修改位、访问位和存在位等标识 查找过程： 从逻辑地址中得到页号 根据页号和PID计算出Hash值 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号 反置页表的Hash冲突 例子：在页表项中加入next项，指出全部冲突项的列表 段页式存储管理段页式存储管理段页式存储管理的需求段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势段式存储和页式存储能否结合？ 段页式存储管理在段式存储管理基础上，给每个段加一级页表逻辑地址：段号+若干个页号+页内偏移物理地址：帧号+页内偏移 123• 从逻辑地址中得到段号s和页号p，以及偏移o• 通过段基址（STBR）和s得到对应的段表项• 访问段表项对应的页表，得到对应的帧号 段页式存储管理中的内存共享通过指向相同的页表基址，实现进程间的段共享 共享段指向同一个页表 小结段式、页式、段页式内存分配总结 共同点 可以不连续 区别 块的大小 问题 加入页表或段表 页表大小问题 快表 多级页表 反置页表 实现细节 练习选择填空题描述段管理机制正确的是() 段的大小可以不一致 段可以有重叠 段可以有特权级 段与段之间是可以不连续的 都对。段的大小显然可以不一致（段描述符中给出的大小不同）。段之间可以重叠（没说不能重叠，而且完全扁平模型就是全都映射到全部物理内存。）段可以有特权级（段描述符中的DPL，访问段的最低特权级）。段之间当然也是可以不连续的。 描述页管理机制正确的是() 页表在内存中 页可以是只读的 页可以有特权级 上述说法都不对 前三个都对。当然有的地方不太准确。在80386系统中，一级页表一定在内存中，但二级页表不一定在内存中。PDE和PTE都可以规定访问权限，不过只有U/S（用户/OS权限）和R/W（只读/可读可写）位。 页表项标志位包括() 存在位(resident bit) 修改位(dirty bit) 引用位(clock/reference bit) 只读位(read only OR read/write bit) 简答题为什么要设计非连续内存分配机制？ 提高分配的灵活性 提高内存的利用效率 方便共享、充分利用内存空间 允许一个程序使用非连续的物理地址空间 允许共享代码与数据 支持动态加载和动态链接 非连续内存分配中内存分块大小有哪些可能的选择？大小与大小是否可变? 大块好管理，小块更灵活。段式存储下，大小是可变的，且块比较大。页式存储下，大小是固定的，且块比较小。 为什么在大块时要设计大小可变，而在小块时要设计成固定大小？小块时的固定大小可以提供多种选择吗？ 固定大小好管理，多种大小比一种大小灵活。可变大小更灵活，通常可变大小也会通过对齐来减少管理难度。小块时如果大小可变，则提供的灵活性没有那么多。 什么是段、段基址和段内偏移？ 段表示访问方式和存储数据的类型等属性相同的一段地址空间。段基址是段的起始地址（线性地址）。段内偏移是地址在段内的偏移量。 段式存储管理机制的地址转换流程是什么？为什么在段式存储管理中，各段的存储位置可以不连续？这种做法有什么好处和麻烦？ 段式存储管理中，地址转换是段基址（段号）加段内偏移。 段反映了程序的存储逻辑结构（数据段和代码段是分开的），程序不会从一个段的基址去访问另一个段，于是不同的段可以不连续。 好处是可以不连续，方便内存管理；麻烦是地址转换稍微复杂了一些。 什么是页（page）、帧（frame）、页表（page table）、存储管理单元（MMU）、快表（TLB, Translation Lookaside Buffer）和高速缓存（cache）？ 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） 把物理地址空间划分为大小相同的基本分配单位 大小一般为2的n次方，如512、4096、8192字节，4KB是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） 把逻辑地址空间也划分为相同大小的基本分配单位 帧和页的大小必须是相同的 页表：保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系 MMU：一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制，在较为简单的计算机体系结构中，负责总线的仲裁以及存储体切换 TLB：为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度 Cache：访问速度比一般随机存取内存（RAM）快的一种RAM，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术 页式存储管理机制的地址转换流程是什么？为什么在页式存储管理中，各页的存储位置可以不连续？这种做法有什么好处和麻烦？ 页式存储管理中，地址转换流程是页号-&gt;物理页帧号加页内偏移。 CPU使用连续的逻辑地址，存储访问时，逻辑地址先分成逻辑页号和页内偏移，然后通过页表定义的对应关系，把逻辑页面转换成物理页号，最后再把物理页号加页内偏移得到物理地址；于是不同的页可以不连续。 好处是可以不连续，方便内存管理中的存储分配和回收；麻烦是地址转换比较复杂（页表项访问开销和页表存储开销），并且频繁进行（每次存储访问会变成两次或更多）。 页表大小受哪些因素影响？ 页大小、地址空间大小、进程数目、页表级数 快表（TLB）与高速缓存（cache）有什么不同？ TLB中缓存的是线性地址物理地址的映射关系，由硬件管理，对软件是透明的。 Cache中缓存的是具体的内存内容，也由硬件管理，对软件是透明的。 为什么快表中查找物理地址的速度非常快？它是如何实现的？为什么它的的容量很小？ 因为它是在多个表项中同步查找有没有对应的线性地址项，所以很快。TLB的硬件是怎么实现的……大概瞎写吧。容量小是因为用电路换时间了（多路并行查找），成本和耗电量比较高。 什么是多级页表？多级页表中的地址转换流程是什么？多级页表有什么好处和麻烦？ 就是套了很多层的页表。地址转换流程就是不断根据每一级的页号和页表基址查找下一级的页表基址（或者查到页表项）。 好处是减小了页表占据的空间（因为程序一般不会用完自己的虚拟地址空间，所以大部分次级页表不需要生成）；麻烦是地址转换变得更加复杂和缓慢了。 页寄存器机制的地址转换流程是什么？ 对CPU访问的逻辑地址进行hash，然后查相应页寄存器。 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行Hash变换 在快表中查找对应页表项 有冲突时遍历冲突项列表 查找失败时，产生异常 反置页表机制的地址转换流程是什么？ 逻辑地址和进程号共同进行hash，然后查相应页寄存器。 查找过程： 从逻辑地址中得到页号 根据页号和PID计算出Hash值 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号；处理hash冲突 反置页表项有些什么内容？ PID、逻辑页号、标志位（可能还应该有指向下一个hash相同的页表项的指针） 段页式存储管理机制的地址转换流程是什么？这种做法有什么好处和麻烦？ 首先从逻辑地址翻译成线性地址（段机制），再从线性地址翻译成物理地址（页机制）。 好处是……。。。 麻烦是，地址访问过程甚至变得更加复杂和耗时了。 如何实现基于段式存储管理的内存共享？ ……就把需要重用的内存映射到不同的段里…… 如何实现基于页式存储管理的内存共享？ 不同的页表项指向相同的物理页…… 请简要分析64bit CPU体系结构下的分页机制是如何实现的 说明64bit CPU架构的分页机制的大致特点和页表执行过程 正确描述了64bit CPU支持的物理内存大小限制（1分） 正确描述了64bit CPU下的多级页表的级数和多级页表的结构或反置页表的结构（2分） 除上述两点外，进一步描述了在多级页表或反置页表下的虚拟地址–&gt;物理地址的映射过程（3分） 64位的寻址空间能够寻址16EB 的内存大小，对于目前的硬件来说太大了。在X64体系结构下，只实现了48位的虚拟地址。不同于x86体系结构，每级页表寻址长度变成9位，由于在x64体系结构中，普通页大小仍为4KB，然而数据却表示64位长，因此一个4KB页在x64体系结构下只能包含512项内容，所以为了保证页对齐和以页为单位的页表内容换入换出，在x64下每级页表寻址部分长度定位9位。 为了正确翻译x64的线性地址，其页表也从x86的2级变成了4级。翻译过程可参考Intel手册或者以下链接 http://www.cnblogs.com/lanrenxinxin/p/4735027.html 某系统使用请求分页存储管理，若页在内存中，满足一个内存请求需要150ns (10^-9s)。若缺页率是10%，为使有效访问时间达到0.5us(10^-6s),求不在内存的页面的平均访问时间。请给出计算步骤。 500=0.9150+0.1x （2）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持32KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : VALID | PFN6 … PFN0PDE格式（8 bit） : VALID | PT6 … PT0其 VALID==1表示，表示映射存在；VALID==0表示，表示映射不存在。PFN6..0:页帧号PT6..0:页表的物理基址&gt;&gt;5在物理内存模拟数据文件中，给出了4KB物理内存空间的值，请回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents。 Virtual Address 6c74Virtual Address 6b22 Virtual Address 03dfVirtual Address 69dc Virtual Address 317aVirtual Address 4546 Virtual Address 2c03Virtual Address 7fd7 Virtual Address 390eVirtual Address 748b比如答案可以如下表示： (注意：下面的结果是错的，你需要关注的是如何表示) Virtual Address 7570:–&gt; pde index:0x1d pde contents:(valid 1, pfn 0x33)–&gt; pte index:0xb pte contents:(valid 0, pfn 0x7f)–&gt; Fault (page table entry not valid) Virtual Address 21e1:–&gt; pde index:0x8 pde contents:(valid 0, pfn 0x7f)–&gt; Fault (page directory entry not valid) Virtual Address 7268:–&gt; pde index:0x1c pde contents:(valid 1, pfn 0x5e)–&gt; pte index:0x13 pte contents:(valid 1, pfn 0x65)–&gt; Translates to Physical Address 0xca8 –&gt; Value: 16链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，请说明原因。 （3）请基于你对原理课二级页表的理解，并参考Lab2建页表的过程，设计一个应用程序（可基于python、ruby、C、C++、LISP、JavaScript等）可模拟实现(2)题中描述的抽象OS，可正确完成二级页表转换。 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，提交你的实现，并说明区别。 （4）假设你有一台支持反置页表的机器，请问你如何设计操作系统支持这种类型计算机？请给出设计方案。 (5)X86的页面结构扩展思考题阅读64bit IBM Powerpc CPU架构是如何实现反置页表，给出分析报告。 interactive understand VMVirtual Memory with 256 Bytes of RAM：这是一个只有256字节内存的一个极小计算机系统。按作者的[[https://github.com/RobertElderSoftware/recc#what-can-this-project-do|特征描述]]，它具备如下的功能。CPU的实现代码不多于500行；支持14条指令、进程切换、虚拟存储和中断；用C实现了一个小的操作系统微内核可以在这个CPU上正常运行；实现了一个ANSI C89编译器，可生成在该CPU上运行代码；该编译器支持链接功能；用C89, Python, Java, Javascript这4种语言实现了该CPU的模拟器；支持交叉编译；所有这些只依赖标准C库。 针对op-cpu的特征描述，请同学们通过代码阅读和执行对自己有兴趣的部分进行分析，给出你的分析结果和评价。","tags":"os"},{"title":"OS Summary 5 - 物理内存管理:连续内存分配","url":"/2018/12/13/os-lecture-5-summary/","text":"内容概述 计算机体系结构和内存层次 地址空间和地址生成 连续内存分配 三种不同的分类策略 碎片整理 伙伴系统 uCore 中的连续内存管理实现框架 计算机体系结构和内存层次 计算机体系结构由 CPU、内存、I/O 设备、总线组成。 CPU 中包括： ALU、控制逻辑 寄存器 高速缓存：加快读写速度 存储管理单元 (MMU) 内存的特点： 最小访问单位是字节 (8 bit ) 一次可以读 / 写 4 字节 (32 位)，有地址对其问题 内存可以分为如下层次： CPU 中： L1 缓存 L2 缓存 这些缓存都是由硬件 (MMU) 来控制的，软件看不到 高速缓存未命中：( 这之下由操作系统软件来控制) 内存 缺页 外存 ( 虚拟内存 ) 操作系统的内存管理OS 内存管理的特点： 每个字节有自己的物理地址 分为内存和外存 每个进程有自己用的内存片，它们自己的地址之间是可以重叠的 MMU：将逻辑 ( 虚拟 ) 地址空间转换为物理地址空间 OS 内存管理的目标： 抽象：逻辑地址空间 保护：独立地址空间 共享：访问相同内存 虚拟化：更大的地址空间 操作系统采用的内存管理方式： 重定位 (relocation)：段地址 + 偏移 分段 (segmentation)：程序的逻辑结构不需要连成一片，而是分成代码、数据、堆栈 3 块，每一块的空间就减少了；但每段的内容是连续的 分页 (paging)：把内存分成最基本的单位 虚拟存储 (virtual memory)：目前多数系统 ( 如 Linux ) 采用的是按需页式虚拟存储 内存管理方式的实现是高度依赖硬件的： 与计算机存储架构紧密耦合 MMU (内存管理单元)：处理 CPU 存储访问请求的硬件 静态地址重定位：即在程序装入内存的过程中完成，是指在程序开始运行前，程序中的各个地址有关的项均已完成重定位，地址变换通常是在装入时一次完成的，以后不再改变，故成为静态重定位。优点：无需硬件支持缺点：1）程序重定位之后就不能在内存中搬动了；2）要求程序的存储空间是连续的，不能把程序放在若干个不连续的区域中。动态地址重定位：不是在程序执行之前而是在程序执行过程中进行地址重定位。更确切的说，是在每次访问内存单元前才进行地址变换。动态重定位可使装配模块不加任何修改而装入内存，但是它需要硬件一定位寄存器的支持。优点：1）目标模块装入内存时无需任何修改，因而装入之后再搬迁也不会影响其正确执行，这对于存储器紧缩、解决碎片问题是极其有利的；2）一个程序由若干个相对独立的目标模块组成时，每个目标模块各装入一个存储区域，这些存储区域可以不是顺序相邻的，只要各个模块有自己对应的定位寄存器就行。缺点：需要硬件支持。 地址空间和地址生成一般来说，地址空间至少有 3 种： 物理地址空间：硬件支持的地址空间 起始地址 0 到 MAXsys 线性地址空间：CPU 看到的地址 起始地址 0 大小取决于地址线的宽度 逻辑地址空间：在 CPU 中运行的进程看到的地址 起始地址 0 到 MAXprog 也就是用户程序可见的地址 逻辑地址的生成需要经过如下几个过程： 高级语言程序：写出函数 编译：对源代码进行编译，称为汇编源代码，此时仍然用符号来指代函数 汇编：汇编成二进制代码，用具体地址来替代符号了，但是有一些函数还没有找到 链接：加入函数库，找到库函数的地址 重定位：程序加载时进行，视程序实际位置改变符号地址 一般来说，生成地址有几个时机： 编译时（优点：简单） 假设起始地址已知 但如果起始地址改变，就必须重新编译 功能手机一般会有这种情况 加载时 如果加载时起始位置未知，编译器需生成可重定位的代码 ( relocation code ) 加载时，生成绝对地址 执行时（优点：灵活） 执行时代码可移动 需地址转换（映射）硬件支持（一般是虚拟存储） 连续内存分配一般分配给一个进程的地址空间是连续的，因此需要进行有效的内存分配。需求是，给进程分配一块不小于制定大小的连续的物理内存区域。定义碎片是过小的不能被利用的空闲内存，分为 2 类： 外部碎片：分配单元之间的未被使用内存 内部碎片：分配单元内部的未被使用内存（一般是否有内碎片取决于分配单元大小是否要取整） 我们在 uCore 中进行的是动态内存分配，需要满足如下要求： 当程序被加载执行时，分配一个进程指定大小可变的分区（块） 分区的地址是连续的 一般来说，操作系统需要维护至少 2 个数据结构，里面存储的内容是： 所有进程的已分配分区 空闲分区 ( Empty-blocks ) 常见的几种连续内存分配策略包括： 最先匹配 (First-fit) 最佳匹配 (Best-fit) 最差匹配 (worst-fit) 总的来说，这些匹配方式各有优劣，至于到底是什么优劣，与使用场景关系很大。 三种不同的分类策略最先匹配 (First Fit Allocation) 策略 思路：需要分配 n 个字节时，使用第一个可用的空间比 n 打的空闲块 原理和实现： 空闲分区列表按地址顺序排序 分配时搜索第一个合适的分区 释放分区时，检查是否可与邻近的空闲分区合并 优点： 简单 在搞地质空间有大块的空闲分区 缺点 容易产生外部碎片 分配大块时较慢 最佳匹配 (Best Fit Allocation) 策略 思路：分配 n 字节内存时，查找并使用不小于 n 的最小空闲分区 原理和实现： 空闲分区列表按照大小排序 分配时，查找一个合适的分区 释放时，查找并合并邻近的空闲分区（如果找到） 优点： 大部分分配的尺寸较小时，效果很好 可避免大的空闲分区被拆分 可减少外部碎片的大小 相对简单 缺点： 外部碎片较多 释放分区较慢 容易产生很多无用的小碎片 最差匹配 (Worst Fit Allocation) 策略 思路：分配 n 字节时，使用尺寸不小于 n 的最大空闲分区 原理和实现： 空闲分区列表由大到小排序 分配时，选最大的分区 释放时检查是否可与邻近的空闲分区合并，进行可能的合并，并调整空闲分区列表顺序 优点： 中等大小的分配较多时，效果最好 避免出现太多的小碎片 缺点： 释放分区较慢 外部碎片较多 容易破坏打的空闲分区，因此难以分配大的分区 碎片整理上述方法都会产生外碎片。（但是不会产生内碎片，因为是按需分配的）如果碎片太多，就有可能出现，即使空余内存总数足够大，也无法分配出一块连续内存的情况。为此就需要进行碎片整理。碎片整理的定义是通过调整进程占用的分区位置来减少或避免分区碎片。一般有两种碎片整理的方法 紧凑（compaction）通过移动分配给进程的内存分区，以合并外部碎片 进行碎片紧凑的条件：所有的应用程序可动态重定位 需要在应用程序等待时进行移动 需要考虑开销 分区对换（Swapping in/out）：通过抢占并回收处于等待状态进程的分区，以增大可用内存空间 这就让更多进程能够在内存里交替运行 需要解决的问题：交换哪个（些）进程？ swap分区在linux中是耳熟能详的，在早期很有用，但代价很大，因为外存的速度远远慢于内存 有了虚拟页式存储之后，纯粹的分区对换的意义就不大了 伙伴系统伙伴系统（Buddy System）是一种连续存储分配的办法，它解决了分配位置和碎片的问题。 假定整个可分配的分区大小为2u，伙伴系统的分配和释放过程如下： 分配过程： 需要的分区大小为2u−1&lt;s≤2u时，把整个块分配给该进程 若s≤2i−1−1，则将大小为2i的当前空闲分区划分成两个大小为2i−1−1的空闲分区 重复划分过程，直到2i−1&lt;s≤2i，并把一个空闲分区分配给该进程 释放过程： 将进程占用的块释放 查看它能否与相邻的空闲块合并（注意边界条件） 如果能合并，则不断合并到不能再合并为止 由分析可知，内碎片的大小最多是2i−1−1，没有外碎片。 伙伴系统的具体实现数据结构： 空闲块按大小和起始地址组织成二维数组（或者说一维数组+一维链表） 第一维：大小；第二维：地址 初始状态：只有一个大小为2u的空闲块 分配过程： 由小到大 在空闲块数组中找最小的可用空闲块（只要有合适的空闲块，就不切分大块，这是隐含的一个原则吧） 如果块太大，则对可用空闲块进行二等分，直到得到合适大小的块 释放过程： 把释放的块放入空闲块数组 合并满足合并条件的空闲块，合并条件是： 大小相同，均为2i 地址相邻 相邻两块的低地址必须是2^(i+1)的倍数 练习选择填空题操作系统中可采用的内存管理方式包括() 重定位(relocation) 分段(segmentation 分页(paging) 段页式（segmentation+paging） 都有。虽然我还是很难想象重定位是内存管理方式，这难道不是进程的管理方式么，虽然能够把进程在内存中搬移大概是上述几种分配策略的前提…… 在启动页机制的情况下，在CPU运行的用户进程访问的地址空间是() 物理地址空间 逻辑地址空间 外设地址空间 都不是 用户进程访问的内存地址是虚拟地址。虚拟地址加上对应的段选择子构成逻辑地址。逻辑地址经过分段翻译成线性地址。线性地址经过分页翻译成物理地址。（但是，即使没有启动页机制，用户进程访问的地址空间也应该是逻辑地址空间吧） 连续内存分配的算法中，会产生外碎片的是() 最先匹配算法 最差匹配算法 最佳匹配算法 都不会 三种算法都会有外碎片，而没有内碎片。相比之下，分页不会有外碎片，只会有内碎片。伙伴系统是可能会产生外碎片的，当然也有内碎片。 在使能分页机制的情况下，更合适的外碎片整理方法是() 紧凑(compaction) 分区对换(Swapping in/out) 都不是 分页方式不会有外碎片。虽然很对，但这道题完全毫无意义。 描述伙伴系统(Buddy System)特征正确的是() 多个小空闲空间可合并为大的空闲空间 会产生外碎片 会产生内碎片 都不对 小空闲空间在满足一定条件时可以合并。因为是一个不断二分的过程，所以外碎片是可能会产生的。因为是分配2的幂大小的内存，所以内碎片也是有的。 简答题操作系统中存储管理的目标是什么？ 抽象 保护 共享 虚拟化 描述编译、汇编、链接和加载的过程是什么？ 编译：将程序源代码转换为汇编代码 汇编：将汇编代码转为二进制的机器码 链接：将多个二进制的机器码结合成一个可执行环境 加载：将程序从外存中加载到内存中 什么是内碎片、外碎片？ 内碎片是指分配给任务的内存大小比任务所要求的大小所多出来的内存。外碎片指分配给任务的内存之间无法利用的内存。当然，一块内存是否为外碎片取决于需要分配的内存的大小。 最先匹配会越用越慢吗？请说明理由（可来源于猜想或具体的实验）？ 最先匹配总是先找低地址空间的内存，到后期低地址空间都是大量小的不连续的内存空间，每次都要扫描低地址空间后到达高地质空间才能得到可用的内存。所以大概是会越用越慢的。 最差匹配的外碎片会比最优适配算法少吗？请说明理由（可来源于猜想或具体的实验） 应该会的。因为每次都找到最大的内存块进行分割，因此分割剩下的内存块也很大，往往还可以再装下一个程序。 理解0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm算法中分区释放后的合并处理过程？ (optional) 它们的处理方式都是查看边上是否也有空闲块，如果有，则合并空闲块，然后将空闲块管理数据插入链表中。如果能进行合并，都需要连续合并。当然，伙伴系统的合并过程需要判断是否满足条件。 对换和紧凑都是碎片整理技术，它们的主要区别是什么？为什么在早期的操作系统中采用对换技术？ 区别是，紧凑是在内存中搬动进程占用的内存位置，以合并出大块的空闲块；对换是把内存中的进程搬到外存中，以空出更多的内存空闲块。采用对换的原因是，处理简单。不过代价也比较高，因为外存比较慢。 伙伴系统的空闲块如何组织？ 按照内存的大小由一系列链表组织。类似于哈希表，将相同大小的内存区域首地址连接起来。（因为一般来说，内存要按首地址大小排列，链表的插入删除比较简单啊） 伙伴系统的内存分配流程？ 当向内核请求分配(2i−1，2i]数目的页块时，按照2i大小的块来请求处理。如果对应的块链表中没有空闲页块，则在更大的页块链表中找空闲块，并将大块进行切分，直到得到满足要求的块。如果切出了多余的块，伙伴系统会将这些块插入到对应的空闲页块链表中。 伙伴系统的内存回收流程？ 当释放多页的块时，内核首先计算出该内存块的伙伴的地址。内核将满足以下条件的三个块称为伙伴： 两个块具有相同的大小，记作b。 它们的物理地址是连续的。 第一块的第一个页的物理地址是2∗(2b)的倍数。 如果找到了该内存块的伙伴，确保该伙伴的所有页都是空闲的，以便进行合并。内存继续检查合并后页块的“伙伴”并检查是否可以合并，依次类推。 （所以才叫伙伴系统，了解了）","tags":"os"},{"title":"OS Summary 4 - 实验:系统软件启动过程","url":"/2018/12/08/os-lecture-4-summary/","text":"内容概述主要介绍了一些和 Lab1 相关的内容。（对 C++ 一窍不通。。羞耻，只是大致了解一下，有时间和精力要对照试验内容认真补一下。。。 系统启动过程 BIOS BootLoader 段机制 操作系统的加载 C 语言的一些相关的只是 函数调用过得实现（略） GCC 内联汇编（略） x86 架构下的中断处理过程 系统启动过程 BIOS BIOS 的工作过程已经在第三讲中详细说过了，在此不再重复。唯一值得注意的是，虽然实模式下的寻址方式是 Base (16 位寄存器 CS)*16+Offset (16位寄存器IP) = 线性地址( 20 位)，但这并不是段机制。 bootloader BIOS 将控制权转交给bootloader。它的工作内容主要包括： 使能保护模式 ( protection mode ) 和段机制 (segment level protection)，切换回 32 位 4G 的寻址空间，对段机制进行初始化 从硬盘上读取 ELF 格式的 ucore kernel (位于 MBR 后面的扇区) 并放到内存中固定的位置。 跳转到 ucore OS 的入口点 (entry point)，将控制权转交给 ucore OS 使能保护模式 将系统寄存器 CR0 的第 0 个 bit 置为 1，说明进入保护模式。当然，在此之前要开 A20，并准备好 GDT 表，将基址加载到 GDT 基址寄存器中。 段机制 保护模式下必须开启段机制。 总的来说，段机制其实是一种映射关系。一个段指向的是线性地址空间中一段连续的内存，有基址和 limit 。短与段之间是可以重叠的。 设置段机制的方法是，建立一个数组来存储段描述符表，称为全局描述符表 GDT (也称为段表，在 ucore 中是由 bootloader 建立的，因为开启保护模式之前就需要设置好 GDT )，其中包括描述符表的位置、大小等信息。这样 CPU 就可以找到段表了 (用 GDTR 寄存器保存表信息)。除了设置 GDT 之外，还要为 CS、DS 等段寄存器设置好对应的 index，使他们能够指向全局描述符表 GDT 对应的项，这可以在切换到保护模式之后进行。 硬件提供了一些段寄存器。这些段寄存器指向段描述符，比较重要的几个段寄存器包括： CS : 代码段寄存器 DS : 数据段寄存器 SS : 堆栈段寄存器 段寄存器的结构是这样的： 高 13 位：GDT index 1 位：TI，一般设置为0，因为没有用到 LDT (本地描述符表) 2位：RP，表明段优先级，有 4 个特权级，一般应用程序放在 3 , 操作系统放在 0 每个段寄存器指向一个 GDT 或者 LDT 中的段描述符。段描述符描述了一个段的起始地址和它的大小。(一个段描述符的大小是 8 字节，具体内容比较复杂。。。忽略) uCore 中采用过的应该是 Intel 手册中提到的扁平保护模型。 在设置完所需的表和寄存器之后，段机制就可以完成从逻辑地址到线性地址（在页机制没有开启的时候，线性地址 = 物理地址）的翻译了。 通过逻辑地址中的段选择子查找段描述符表项 从表项中读出段基址和段的大小 检查逻辑地址中的 offset 是否合法 安全性检查 段基址 (Base Address) + 段内偏移量 (offset) = 线性地址 (linear address) 代码实现过程（略。。。） x86 架构下的中断处理过程此处的 “中断” 包括两类： 中断 (Interrupts) 外部中断 (External (hardware generated) interrupts)：串口、硬盘、网卡、时钟 软件产生的中断 (Software generated interrupts)：INT n指令，通常用于系统调用 异常 (Exceptions) 程序错误 软件产生的异常 (Software generated excetpion)：INTO, INT 3 和 BOUND 机器检查出的异常 通过中断号确定中断服务例程 ( ISR )（略。。。）","tags":"os"},{"title":"OS Summary 3 - 启动、中断、异常和系统调用","url":"/2018/12/02/os-lecture-3-summary/","text":"内容概述 系统启动过程 BIOS 的原理 BIOS 的一些具体工作 系统启动规范 中断，异常和系统调用 中断 系统调用 系统启动过程 BIOS 的基本功能 计算机刚刚启动时的内存布局如图： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM 1MB ~ (4GB - 64KB) 空闲空间 640KB ~ 1MB 视频内存，BIOS启动固件（映射） 0 ~ 640KB 空闲空间 （这是一个非常简略的示意图，具体请见Memory Map (x86))） 这一复杂的映射机制是为了保证向后兼容而设计的。在8086时代，内存只有1MB大小，此时，BIOS的代码固化在EPROM中，且EPROM被编址在1MB内存地址空间的最高64KB中。PC加电后，CS寄存器初始化为0xF000，IP寄存器初始化为0xFFF0，所以CPU要执行的第一条指令的地址为CS:IP=0xF000:0XFFF0（ Segment:Offset表示） =0xFFFF0（ Linear表示） 。这个地址位于被固化的EPROM中，该地址存储了一条指令，它是一个长跳转指令JMP F000:E05B。这样就开启了BIOS的执行过程。 到了32位的80386 CPU时代，内存空间扩大到了4G，多了段机制和页机制。如果仍然把BIOS启动固件编址在0xF0000起始的64KB内存地址空间内，就会把整个物理内存地址空间隔离成不连续的两段，一段是0xF0000以前的地址，一段是1MB以后的地址，这很不协调。为此，intel采用了一个折中的方案：默认将执行BIOS ROM编址在32位内存地址空间的最高端，即位于4GB地址的最后一个64KB内。在PC系统开机复位时，CPU进入实模式，并将CS寄存器设置成0xF000，将它的shadow register的Base值初始化设置为0xFFFF0000，EIP寄存器初始化设置为0x0000FFF0。所以机器执行的第一条指令的物理地址是0xFFFFFFF0。80386的BIOS代码也要和以前8086的BIOS代码兼容，故地址0xFFFFFFF0处的指令还是一条长跳转指令jmp F000:E05B。注意，这个长跳转指令会更新CS寄存器和它的shadowregister，即执行jmp F000:E05B后，CS将被更新成0xF000。表面上看CS其实没有变化，但CS的shadow register被更新为另外一个值了，它的Base域被更新成0x000F0000，此时形成的物理地址为Base+EIP=0x000FE05B，这就是CPU执行的第二条指令的地址。此时这条指令的地址已经是1M以内了，且此地址不再位于BIOS ROM中，而是位于RAM空间中。由于Intel设计了一种映射机制，将内存高端的BIOS ROM映射到1MB以内的RAM空间里，并且可以使这一段被映射的RAM空间具有与ROM类似的只读属性。所以PC机启动时将开启这种映射机制，让4GB地址空间的最高一个64KB的内容等同于1MB地址空间的最高一个64K的内容，从而使得执行了长跳转指令后，其实是回到了早期的8086 CPU初始化控制流，保证了向下兼容。 上述说明指出，在 CPU 启动之后，它一直处于实模式之下，执行的第一条指令是 jmp F000:E05B ，跳转到 BIOS 程序中。此时，PC = 16 * CS + IP，系统地址空间只有 20 位（1MB）。 20 位地址空间：1MB 这之后 BIOS 会进入以下工作： 在实模式下提供基本输入输出方法 通过中断调用实现 只能在实模式下使用，操作系统无法使用 运行自检程序 用户选择引导设备（从什么介质启动） 将 BootLoader 从磁盘的引导扇区加载到内存中 0x7c00 开始的位置 跳转到 BootLoader的位置：CS:IP=0000:7C00 系统设置信息 开机后自检程序 系统自启动程序等 这之后，控制权就交给 BootLoader： 切换到保护模式 将操作系统的代码和数据从硬盘加载到内存中（因为 BIOS 无法处理硬件的文件系统） 跳转到操作系统的起始地址 加载之后的内存布局如下表： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM ? ~ (4GB - 64KB) 空闲空间 1MB ~ ? 操作系统 640KB ~ 1MB 视频内存，BIOS启动固件（映射） ? ~ 640KB 空闲空间 0x7c00 ~ ? bootloader 0 ~ 0x7c00 BIOS数据 最后，bootloader把控制权转交给操作系统。 BIOS 的一些具体工作BISO 本身的初始化内容 硬件自检 POST 检测系统中内存和显卡等关键部件的存在和工作状态 查找并执行显卡等接口卡 BIOS，进行设备初始化 执行系统 BIOS，进行系统检测：检测和配置系统中安装的即插即用设备 更新 CMOS 中的扩展系统配置数据 ESCD 按指定启动顺序从硬盘、软盘等设备启动 BIOS 如何读取 BootLoader Wiki上是这么说的： 系统开机或者重启。 BIOS加电（台湾用语：开机）自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示”NO ROM BASIC”然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 标准MBR的结构如下： 地址（十进制） 描述 长度（字节） 0 代码区 440（最大446） 440 选用磁盘标志 4 444 一般为空值; 0x0000 2 446 标准MBR分区表规划（四个16 byte的主分区表入口） 64 510 MBR有效标志：0x55AA 2 系统启动规范课程中还讲到了BIOS-MBR、BIOS-GPT、PXE和UEFI等系统启动规范，其中UEFI似乎还更重要一点。这似乎是通用的现代BIOS标准。 中断、异常和系统调用定义： 系统调用（System Call)：应用程序主动向操作系统发出的服务请求 异常（Exception)：非法指令或其他原因导致当前指令执行失败（如：内存出错）后的处理请求 中单（Hardware Interrupt）：来自硬件设备的处理请求 它们的相同之处是，采用的处理方式大致相同。无论发生异常、中断、还是系统调用，都需要由硬件保存现场和中断号，转到内核态，进入中断向量表，查找对应的设备驱动程序地址（异常）、异常服务例程地址（异常），或找到系统调用表，并在其中查找对应的系统调用实现的起始地址。处理完毕之后，在进行现场切换，会到用户态继续执行程序（如果可能继续的话）。它们的区别如下表： 源头 响应方式 处理机制 中断 外设 异步 持续，对用户应用程序是透明的 异常 应用程序或内核意想不到的行为 同步 杀死或重新执行意想不到的应用程序指令 系统调用 应用程序请求操作提供服务 异步或同步 等待和持续 这三者的处理有时可以嵌套，有时不可以。 相比于用户态的函数调用，中断和异常的开销是比较大的，因为他们需要进行： 特权级的切换 建立内核堆栈 验证参数的合法性（防止对内核的恶意攻击） 内核态需要映射到用户态的地址空间（因为需要访问用户程序的一些内容），因此㤇更新页面映射权限 内核态也拥有独立的地址空间，因此 TLB 会失效 中断的具体处理机制 中断处理的过程需要软件和硬件的配合（虽然系统调用和异常也是。。。） 硬件处理内容包括： 在 CPU 初始化时设置中断使能表示 依据内部或者外部事件设置中断标志 依据中断向量调用对应的中断服务例程 软件处理内容包括： 现场保存（编译器） 终端服务处理（服务例程） 清楚中断标记（服务例程）（系统调用只占用一个中断向量，另有系统调用表） 现场恢复（编译器） 系统调用 特点 系统调用时操作系统服务的编程接口 通常由高级语言编写（ C 或 C ++） 程序访问系统调用通常是高层次的 API 接口（比如封装到标准 C 库一）而不是直接进行系统调用 3中最常用的应用程序编程接口（API): Win32 API：Windows POSIX API：UNIX、LINUX、Mac OS X Java API：用于JAVA虚拟机（JVM），是对实际系统调用的进一步抽象 系统调用的实现 每个系统调用对应一个系统调用号 系统调用接口根据系统调用号来维护表的索引 系统调用接口调用内核态中的系统调用功能实现，并返回系统调用的状态和结果 用户不需要系统调用的实现 需要设置调用参数和获取返回结果 操作系统接口的细节大部分都隐藏在应用编程接口后 通过运行程序支持的库来管理 注意，系统调用时，堆栈需要切换（内核和用户程序使用的是不同的堆栈），特权级需要进行切换 习题简答题BIOS从磁盘读入的第一个扇区是是什么内容？为什么没有直接读入操作系统内核映像？ BIOS完成硬件初始化和自检后，会根据CMOS中设置的启动顺序启动相应的设备，这里假定按顺序系统要启动硬盘。但此时，文件系统并没有建立，BIOS也不知道硬盘里存放的是什么，所以BIOS是无法直接启动操作系统。另外一个硬盘可以有多个分区，每个分区都有可能包括一个不同的操作系统，BIOS也无从判断应该从哪个分区启动，所以对待硬盘，所有的BIOS都是读取硬盘的0磁头、0柱面、1扇区的内容，然后把控制权交给这里面的MBR (Main Boot Record）。 我认为上述答案并不十分确切。比如，在uCore中，虽然BIOS没有建立文件系统，bootloader也没有建立文件系统啊。但是，加载操作系统是个很复杂的过程：就比如uCore，我们需要完成对ELF文件格式的解析和文件本身的读入。BIOS工作在实模式，本身访存范围只有1MB（能使用的数据只有0 ~ 0x7c00的范围），而且代码长度被限制在64KB。为了将OS读入到高地址的内存中，需要BIOS进行模式的切换。但是，如果BIOS进行了实模式到保护模式的切换，就不能实现向后兼容了。而且不同的OS的文件格式和处理方法也有差异，这会导致BIOS十分复杂。因此，让OS提供自己的启动程序是最好的选择。 比较UEFI和BIOS的区别。 统一可扩展固件接口 (Unified Extensible Firmware Interface, UEFI) 是一种个人电脑系统规格，用来定义操作系统与系统固件之间的软件界面，作为BIOS的替代方案。 UEFI启动对比BIOS启动的优势有三点： 安全性更强：UEFI启动需要一个独立的分区，它将系统启动文件和操作系统本身隔离，可以更好的保护系统的启动； 启动配置更灵活：EFI启动和GRUB启动类似，在启动的时候可以调用EFIShell，在此可以加载指定硬件驱动，选择启动文件。比如默认启动失败，在EFIShell加载U盘上的启动文件继续启动系统； 支持容量更大：传统的BIOS启动由于MBR的限制，默认是无法引导超过2TB以上的硬盘的。随着硬盘价格的不断走低，2TB以上的硬盘会逐渐普及，因此UEFI启动也是今后主流的启动方式。 分区引导扇区的结束标志是什么？ 0X55AA。当然，上面也说到了，BIOS除此之外还会检查别的内容。 在UEFI中的可信启动有什么作用？ 通过启动前的数字签名检查来保证启动介质的安全性。 什么是中断、异常和系统调用？ 中断：外部意外的响应； 异常：指令执行意外的响应； 系统调用：系统调用指令的响应。 这个回答真是十分简洁明了。 中断、异常和系统调用的处理流程有什么异同？ 相同点：都会进入异常服务例程，切换为内核态。 不同点： 源头不同，中断源是外部设备，异常和系统调用源是应用程序； 响应方式不同，中断是异步的，异常是同步的，系统调用异步和同步都可以。 处理机制不同，中断对用户程序是透明的，异常会重新执行用户指令或杀死用户进程，系统调用一般是用户程序调用的 系统调用与函数调用的区别是什么？ 汇编指令的区别 系统调用：使用INT和IRET指令 函数调用：使用CALL和RET指令 安全性的区别 系统调用有堆栈和特权级的转换过程，函数调用没有这样的过程，系统调用相对更为安全 性能的区别 时间角度：系统调用比函数调用要做更多和特权级切换的工作，所以需要更多的时间开销 空间角度：在一些情况下，如果函数调用采用静态编译，往往需要大量的空间开销，此时系统调用更具有优势","tags":"os"},{"title":"OS Summary 2 - 操作系统实验环境","url":"/2018/11/27/os-lecture-2-summary/","text":"内容概述 实验内容的详细介绍 X86-32硬件的介绍 uCore 的部分编程技巧和数据结构 如何使用工具编写和调试实验 实验主要是使用 C 语言实现的，目前还没有认真动手操作，只是大概了解一下思路。 实验具体内容略。。。 X86-32硬件简单介绍 运行模式 80386 共有四中运行模式，我们只用到了其中两种 实模式：加电后的默认模式，在BootLoader中就会切换为保护模式 保护模式：一般的模式 寻址方法 逻辑地址：由16位的段选择子和32位的偏移量组成，是应用程序直接使用的地址空间（大概就是程序运行时访问的地址） 线性地址：由逻辑地址的偏移量 + 段基址得到，是虚存管理下每个运行的应用程序能访问的地址空间 物理地址：处理器提交到总线上用于访问计算机系统中内存和外设的最终地址。如果未开启页机制，则物理地址 = 线性地址；否则通过页表和线性地址可得到物理地址 寄存器 通用寄存器 EAX : 累加器 EBX : 基址寄存器 ECX : 计数器 EDX : 数据寄存器 ESI : 原地址指针寄存器 EDI : 目的地址指针寄存器 EBP : 基址指针寄存器 ESP : 堆栈指针寄存器 段寄存器 CS : 代码段 ( Code Segment) DS : 数据段（Data Segment） ES : 附加数据段（Extra Segment） SS : 堆栈段（Stack Segment FS : 附加段 GS : 附加段 指令寄存器 EIP : 指令的段内偏移地址 标志寄存器 EFLAGS : TF : 开启单步调试 IF : 开启硬件中断 IOPL : I/O特权级，CPL &lt;= IOPL 时才能进行 I/O 操作 选择题略。。。 简答题你理解的对于类似ucore这样需要进程/虚存/文件系统的操作系统，在硬件设计上至少需要有哪些直接的支持？至少应该提供哪些功能的特权指令？ 进程的切换需要硬件支持时钟中断；虚存管理需要地址映射机制，从而需要MMU等硬件；对于文件系统，需要硬件有稳定的存储介质来保证操作系统的持久性。对应的，应当提供中断使能，触发软中断等中断相关的，设置内存寻址模式，设置页表等内存管理相关的，执行 I/O 操作等文件系统相关的特权指令。 对于现代操作系统（每个进程占一个时间片）时钟中断是非常重要的。存储介质当然也是非常重要的。当然，事实上，MMU 没有也行，可以用用户态函数库来实现地址转换，但这样可能就保证不了安全性了。 Intel 手册第 3 卷 2.8 j节 “System Instruction Summary” 中给出了一个系统指令列表。 “系统指令完成的是系统级的功能，包括加载系统寄存器、管理 Cache、管理终端和设置调试寄存器。其中的大部分指令都必须由操作系统或特权级为 0 的进程执行；另一部分可以由任何特权级的进程执行。” 你理解的x86的实模式和保护模式有什么区别？物理地址、线性地址、逻辑地址的含义分别是什么？ 保护模式和实模式的根本区别是进程内存是否受保护。（作者的意见是，实模式既是一个历史包袱，又有一定的实际用途。在实模式下，BIOS 自检和加载 BootLoader 的程序可以尽可能简单，因为不需要建立复杂的段映射。但是段机制必须开启这一点也是历史包袱。总之，BootLoader 一开始就开了 A20 ，设置了GDT然后长跳转切换到保护模式了。）实模式将整个内存看成分段的区域，程序代码和数据位于不同的区域，系统程序和用户程序没有区别对待，而且没一个指针都是指向“实在”的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并改变了值，那么对于这个别修改的系统程序或用户程序，其后果可能是灾难性的。为了克服这种低劣的内存管理模式，处理器厂商开发出保护模式。这样，物理内存不能直接被程序访问，程序内部的地址（虚拟地址）要由操作系统转化为物理地址去访问，程序对此一无所知。 物理地址：是处理器提交到总线上用于访问计算机系统中的内存和外设的最终地址。 逻辑地址：在有地址变换功能的计算机中，访问指令给出的地址叫逻辑地址。（一般的定义是段选择子+段内偏移量是逻辑地址。大概） 线性地址：线性地址是逻辑地址和物理地址变换之间的中间层，是处理器通过段（Segment）机制控制下形成的地址空间 虚拟地址：对这个名称的定义总是模糊不清。在这门课中，似乎虚拟地址就是程序内存的地址。","tags":"os"},{"title":"OS Summary 1 - 操作系统概述","url":"/2018/11/21/os-lecture-1-summary/","text":"内容概述 什么是操作系统 操作系统的演变 操作系统结果的分类 什么是操作系统操作系统可以是： 一个控制程序 一个资源管理器 一套标准库 操作系统通常有内核、命令行和 GUI 组成。我们研究的主要是内核。可以分成以下4个层次 ： 应用程序 命令行程序、编译器、解释器、系统库 内核 内核向上提供系统调用接口 同时调用下层提供的硬件抽象 硬件设备 操作系统内核的特征： 并发：OS 需要管理和调度多个同时运行的程序 共享：对资源的互斥共享 虚拟：对 CUP 和内存资源的虚拟化 异步：程序的运行时时常会停止的，OS 需要保证程序展厅之后状态不变 操作系统的演变 单用户系统：1945 - 1955 OS = 装载器 + 通用子程序库 存在的问题：任务完全为穿行执行，由于读卡时间过长，执行时间比例降低 批处理系统：1955 - 1965 每个任务在每个组件中串行执行，总体看来是并行执行的 解决了利用率的问题 多道程序系统：1965 - 1980 将多个程序储存在内存中，复用 CPU 在程序进行 I/O 操作室将其阻塞，切换到别的程序 分时系统：1970 - 定义中断当前程序，实现对CPU的复用 个人电脑操作系统 分布式操作系统 …… 操作系统结构的分类操作系统的结构可以分为以下几种： 简单结构：没有拆分为模块，没有很好的分离接口和功能 应用程序可以直接访问最底层的服务，也可以使用操作系统的服务 例： MS-DOS 分层结构：将操作系统分为几层，每层建立在底层之上 优点：可移植性强 缺点：层次过多会导致效率降低 例：UNIX 微内核结构：将一些内核服务移动到用户态，内核只保留进程通信和硬件支持功能 优点：灵活，安全 缺点：性能差 例：目前的系统结构是微内核结构和分层结构的混合体 外核结构：内核只起到资源的保护和隔离功能，操作系统原有功能由用户态操作系统库支持 虚拟机结构：操作系统和虚拟机管理器交互，虚拟机管理器负责和硬件交互 习题选择填空题 当前常见的操作系统主要用C，C++，ASM编程语言编写。 “Operating system”这个单词起源于Operator。 指的是原来的系统操作员。 在计算机系统中，控制和管理各种资源、有效地组织多道程序运行的系统软件称作操作系统。 对操作系统定义的考察。当然我觉得这个答案并不全面，加上“提供了一套标准库”（也就是系统调用）会更好。 允许多用户将若干个作业提交给计算机系统集中处理的操作系统称为批处理操作系统。 这说明单用户系统是每个任务手动提交上去的。 你了解的当前世界上使用最多的32bit CPU是ARM，其上运行最多的操作系统是Android。 答案如此，没有找到信源。不过知道这个也没什么意义。 应用程序通过系统调用接口获得操作系统的服务。 系统调用是非常重要的。这是应用程序主动进入内核态的方式。 现代操作系统的特征包括并发性，共享性，虚拟性，异步性，持久性。 特征到底应该包括哪些也是见仁见智。OSTEP中总结出的三点是虚拟，并发和持久性。异步性和共享性大概可以归入并发性。同时我也觉得持久性未必是操作系统的特点，而是存储设备的特点。当然这也可能是我的理解不够。 UPD：操作系统本身也是需要从持久性存储设备中读入的。文件系统也是OS的重要组成成分。所以我想得可能太片面了。 操作系统内核的架构包括宏内核，微内核，外核。 这个答案和上面讲的并不相符。那么，当然应该填简单结构、分层结构、微内核结构、外核结构和虚拟机结构了。 简答题请总结你认为操作系统应该具有的特征有什么？并对其特征进行简要阐述。 操作系统应该具有的特征有：虚拟性、并发性、异步性、共享性和持久性。 虚拟性：虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备。 并发性：并发是指两个或多个事件在同一时间间隔内发生，在多道程序环境下，一段时间内宏观上有多个程序在同时执行，而在同一时刻，单处理器环境下实际上只有一个程序在执行，故微观上这些程序还是在分时的交替进行。操作系统的并发是通过分时得以实现的。操作系统的并发性是指计算机系统中同时存在多个运行着的程序，因此它具有处理和调度多个程序同时执行的能力。 异步性：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。异步性使得操作系统运行在一种随机的环境下，可能导致进程产生于时间有关的错误。但是只要运行环境相同，操作系统必须保证多次运行进程，都获得相同的结果。 共享性：系统中的资源可供内存中多个并发执行的进程共同使用。（事实上，只能做到互斥共享，或者说同时。） 持久性：通过实现文件系统，操作系统可以将程序以及数据存储在磁盘等存储介质中。 详细解释可以参考操作系统的特征。 为什么现在的操作系统基本上用C语言来实现？为什么没有人用python，java来实现操作系统？ C语言是编译型语言，有良好的性能，能够直接嵌入汇编，可以方便地操作硬件；Python，Java无法保证性能，不能直接操作硬件。 不过，仍然是有人用这些语言来编写操作系统的，比如： 用Java实现的操作系统：JavaOS 用Python实现的操作系统：pycorn，pythonix 用Rust实现的操作系统：Redox 参考： https://github.com/chyyuu/os_course_info https://zhanghuimeng.github.io/ http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240243X+sp/about","tags":"os"},{"title":"扫一扫下面的二维码图案，加我微信","url":"/about/wechat-id.html","text":"","tags":""},{"title":"About Me","url":"/about/index.html","text":"Hello, my name is Shinhwa Wang, an engineer at AsiaInfo living in Kualua Lumpur, Malaysia. Current Focus Algorithms Operating Systems Network Database Java English I’m interested in all kinds of technical stuff, I also like hiphop music and dance.If you’d like to know more about me, check out my Resume and GitHub. My Biggest Influences and fav 💕 blogsCS-Notes: The blog made me realize how much more I need to learn. Contact Me ​ For general communication, contact shinhwawang2015@gmail.com ​ My Wechat id wshpop","tags":""},{"title":"404","url":"/404.html","text":"* { -webkit-box-sizing: border-box; box-sizing: border-box; -webkit-user-select: none; /* Safari 3.1+ */ -moz-user-select: none; /* Firefox 2+ */ -ms-user-select: none; /* IE 10+ */ user-select: none; /* Standard syntax */ } body { padding: 0; margin: 0; } #notfound { position: relative; height: 90%; width: 100%; } #notfound .notfound { position: absolute; left: 50%; top: 50%; -webkit-transform: translate(-50%, -50%); -ms-transform: translate(-50%, -50%); transform: translate(-50%, -50%); } .notfound { max-width: 550px; width: 100%; line-height: 1.4; text-align: center; } .notfound .notfound-404 { position: relative; height: 200px; margin: 0px auto 20px; z-index: -1; } .notfound .notfound-404 h1 { font-family: 'Palatino', serif; font-size: 236px; font-weight: 200; margin: 0px; color: #211b19; text-transform: uppercase; position: absolute; left: 50%; top: 50%; -webkit-transform: translate(-50%, -50%); -ms-transform: translate(-50%, -50%); transform: translate(-50%, -50%); } .notfound .notfound-404 h2 { font-family: 'Palatino', serif; font-size: 36px; font-weight: 400; text-transform: uppercase; color: #211b19; background: #fff; padding-top: 20px; padding-bottom: 10px; margin: auto; display: inline-block; position: absolute; width: 120%; left: 50%; top: 50%; -webkit-transform: translate(-50%, -80%); -ms-transform: translate(-50%, -80%); transform: translate(-50%, -80%); } .notfound a { font-family: 'Palatino', serif; text-decoration: none; text-transform: uppercase; padding: 13px 23px; font-size: 18px; -webkit-transition: 0.2s all; transition: 0.2s all; display: inline-block; margin: 0 4px; padding: 4px 12px; background-color: #fff; border-bottom: 4px solid #b21c1c; border-radius: 4px; font-size: 14px; color: #fff; background-color: #e20b0b; text-align: center; cursor: pointer; } .notfound a:hover { background-color: #f21a1a; } @media only screen and (max-width: 600px) { .notfound .notfound-404 h1 { font-size: 120px; } .notfound .notfound-404 h2 { font-size: 18px; padding-top: 10px; padding-bottom: 5px; } } 404 - Page not found 404 🙃 Page is not found. Take me home!","tags":""},{"title":"","url":"/search/index.html","text":"","tags":""}]}