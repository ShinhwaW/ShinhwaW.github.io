{"pages":[{"title":"OS Summary 8 - 页面置换算法","url":"/2018/12/29/os-lecture-8-summary/","text":"功能：当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面 目标 尽可能减少页面的调入调出次数 把未来不再访问或短期内不访问的页面调出 最优页面置换算法 ( OPT , optimal )置换在未来最长时间不访问的页面，理想情况 先进先出算法（First-In First-Out, FIFO）基本思路：选择在内存驻留时间最长的页面进行置换 算法实现 维护一个记录所有位于内存中的逻辑页面链表 链表元素按驻留内存的时间排序，链首最长，链尾最短 出现缺页时，选择链首页面进行置换，新页面加到链尾 算法特征 实现简单 性能较差，调出的页面可能是经常访问的 进程分配物理页面数增加时，缺页并不一定减少( Belady 现象) 很少单独使用 最近最久未使用算法(Least Recently Used, LRU)基本思路 选择最长时间没有被引用的页面进行置换 如某些页面长时间未被访问，则它们在将来还可能会长时间不会访问 算法实现 缺页时，计算内存中每个逻辑页面的上一次访问时间 选择上一次使用到当前时间最长的页面 算法特征 最优置换算法的一种近似 LRU算法的可能实现方法 页面链表 系统维护一个按最近一次访问时间排序的页面链表 链表首节点是最近刚刚使用过的页面 链表尾节点是最久未使用的页面 访问内存时，找到相应页面，并把它移到链表之首 缺页时，置换链表尾节点的页面 活动页面栈 访问页面时，将此页号压入栈顶，并栈内相同的页号抽出 缺页时，置换栈底的页面 特征 开销比较大 时钟置换算法（Clock）基本思路 仅对页面的访问情况进行大致统计 时钟算法是LRU和FIFO的折中 最不常用算法（Least Frequently Used, LFU）基本思路 缺页时，置换访问次数最少的页面 算法实现 每个页面设置一个访问计数（多位计数） 访问页面时，访问计数加1 缺页时，置换计数最小的页面 算法特征 算法开销大 开始时频繁使用，但以后不使用的页面很难置换 解决方法 计数定期右移、衰减 LRU和LFU的区别 LRU关注多久未访问,时间越短越好 LFU关注访问次数，次数越多越好 LRU、FIFO和Clock的比较 LRU算法和FIFO本质上都是先进先出的思路 LRU依据页面的最近访问时间排序 LRU需要动态地调整顺序 FIFO依据页面进入内存的时间排序 LRU可退化成FIFO 如页面进入内存后没有被访问，最近访问时间与进入内存的时间相同 LRU算法性能较好，但系统开销较大 FIFO算法系统开销较小，会发生Belady现象 Clock算法是它们的折衷 页面访问时，不动态调整页面在链表中的顺序，仅做标记 缺页时，再把它移动到链表末尾 对于未被访问的页面，Clock和LRU算法的表现一样好 对于被访问过的页面，Clock算法不能记录准确访问顺序，而LRU算法可以","tags":"os"},{"title":"OS Summary 7 - 虚拟内存","url":"/2018/12/23/os-lecture-7-summary/","text":"背景虚拟内存是非连续内存分配的一个延续，非连续内存分配在存储空间内可以连续也可以不连续。虚拟内存是在非连续内存分配基础上，可以把一部分内容放到外存中去，让应用程序有更大的空间使用。 需求背景：增长迅速的存储需求，程序规模的增长速度远远大于存储器容量的增长速度。 解决办法 覆盖 ( overlay ) 应用程序手动把需要的指令和数据保存在内存中 交换 ( swapping ) 操作系统自动把暂时不能执行的程序保存到外存中 虚拟存储 在有限容量的内存中，以页为单位自动装入更多更大的程序 覆盖技术目标 ：在较小的可用内存中运行较大的程序 方法 ：依据程序逻辑结构，将程序划分为若干功能相对独立的模块，将不会同时执行的模块共享同一块内存区域 必要部分（常用功能）的代码和数据常驻内存 可选部分（不常用功能）放在其他程序模块中,只在需要用到时装入内存 不存在调用关系的模块可相互覆盖，共用同一块内存区域 注：不存在相互调用关系可以分成一个覆盖区 不足 ： 增加编程困难 需程序员划分功能模块，并确定模块间的覆盖关系 增加了编程的复杂度 增加执行时间 从外存装入覆盖模块 时间换空间 交换技术目标：增加正在运行或需要运行的程序的内存 实现方法： 可将暂时不能运行的程序放到外存 换入换出的基本单位是整个进程的地址空间 换出（swap out）：把一个进程的整个地址空间保存到外存； 换入（swap in）：将外存中某进程的地址空间读入到内存； 交换技术面临的问题 交换时机 只当内存空间不够或有不够的可能时换出 交换区大小 存放所有用户进程的所有内存映像的拷贝 程序换入时的重定位 采用动态地址映射的方法 覆盖和交换的对比 覆盖 只能发生在没有调用关系的模块间 程序员须给出模块间的逻辑覆盖结构 发生在运行程序的内部模块间 交换 以进程为单位 以进程为单位 发生在内存进程间 虚拟内存技术目标 只把部分程序放到内存中，从而运行比物理内存大的程序 由操作系统自动完成，无需程序员的干涉 实现进程在内存与外存之间的交换，从而获得更多的空闲内存空间 在内存和外存之间只交换进程的部分内容 局部性原理程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域 时间局部性 一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内 空间局部性 当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内 分支局部性 一条跳转指令的两次执行，很可能跳到相同的内存位置 局部性原理的意义从理论上来说，虚拟存储技术是能够实现的，而且可取得满意的效果 虚拟存储概念将不常用的部分内存块暂存到外存 原理 装载程序时只将当前指令执行需要的部分页面或段装入内存 指令执行中需要的指令或数据不在内存（称为缺页或缺段）时，处理器通知操作系统将相应的页面或段调入内存 操作系统将内存中暂时不用的页面或段保存到外存 实现方式 虚拟页式存储 在页式存储管理的基础上，增加请求调页和页面置换 当用户程序要装载到内存运行时，只装入部分页面，就启动程序运行 进程在运行中发现有需要的代码或数据不在内存时，则向系统发出缺页异常请求 操作系统在处理缺页异常时，将外存中相应的页面调入内存，使得进程能继续运行 虚拟段式存储 缺页异常 在内存中有空闲物理页面时，分配一物理页帧 f，转第 5 步 依据页面置换算法选择将被替换的物理页帧 f，对应逻辑页 q 如 q 被修改过，则把它写回外存 修改 q 的页表项中驻留位置为0 将需要访问的页 p 装入到物理页面 f 修改p的页表项驻留位为 1 ,物理页帧号为 f 重新执行产生缺页的指令 虚拟页式存储中的外存管理在何处保存未被映射的页 应能方便地找到在外存中的页面内容 交换空间（磁盘或者文件） 采用特殊格式存储未被映射的页面 注：可以用一个文件来存这些未被映射的页 虚拟页式存储中的外存选择 代码段：可执行二进制文件（代码指向相应的可执行文件） 动态加载的共享库程序段：动态调用的库文件（共享库也有相应的目标文件，所以上两项不改） 其它段：交换空间（数据段，堆栈）","tags":"os"},{"title":"OS Summary 6 - 物理内存管理:非连续内存分配","url":"/2018/12/18/os-lecture-6-summary/","text":"内容概述 背景 段机制 页机制 普通页表 快表 多级页表 页寄存器 反置页表 段页式存储管理 背景 非连续内存分配的需求背景 必须分配连续的会带来很多麻烦 不连续？找到的几率更高，但会带来新问题。比如基本块有多大。 段式：分块大 页式：分块小 设计目标 连续分配的缺点： 物理内存必须连续 存在外碎片和内碎片 内存分配的动态修改困难 内存利用率较低 非连续分配的设计目标： 提高内存利用效率和管理灵活性 允许一个程序使用非连续的物理地址空间 允许共享代码与数据 支持动态加载和动态链接 实现 非连续分配需要解决的问题： 如何实现虚拟地址和物理地址的转换：不同的逻辑地址可能位于不连续的物理区域中 软件实现（灵活，开销大） 硬件实现（够用，开销小) 非连续分配的硬件辅助机制 如何选择非连续分配中的内存分块大小？内碎片、外碎片问题？ 段式存储管理（segmentation）：块大 页式存储管理（paging）：块小 段机制段式存储管理 进程的段地址空间由多个段组成： 主代码段 子模块代码段 公用库代码段 堆栈段（stack） 堆数据（heap） 初始化数据段 符号表等 段式存储管理的目的： 更细粒度和灵活的分离域共享 段式地址空间的不连续二维结构： 虽然在逻辑地址空间中，是按这一顺序排列的，但在物理地址空间中可以不是这样的。 段访问机制 概念： 段表示访问方式和存储数据等属性相同的一段地址空间 对应一个连续的内存“块” 若干个段组成进程逻辑地址空间 段访问：逻辑地址由二元组（s，addr）表示 s——段号 addr——段内偏移 从单地址转换成“段基址+段内偏移” 段访问的硬件实现 1234• 首先从逻辑地址中得到段号和偏移量• 在段表中查找段号，得到段基址和段长度• 由MMU来判断偏移量是否合法（偏移量是否大于段长度）• 得到物理地址，在物理内存中查找相应内容 页机制页式存储管理 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） 把物理地址空间划分为大小相同的基本分配单位 2的n次方，如512,4096,8192，4k是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） 把逻辑地址空间也划分为相同大小的基本分配单位 帧和页的大小必须是相同的 页面到页帧之间的转换： 逻辑地址到物理地址的转换 页表 MMU/TLB 帧（Frame） 物理内存被划分成大小相等的帧 此时内存的物理地址可以表示成二元组（f，o），其中f是帧号，o是帧内的偏移量 物理地址的前F位可以换成帧号，后S位可以换成偏移量 F：帧号，F位，共有2^F个帧 o：帧内偏移，S位，每帧有2^S字节 物理地址=f*2^S + o 基于页帧的物理地址计算实例 假定： 地址空间为16位 页帧大小为9位（512字节） 页（Page） 进程逻辑地址空间被划分为大小相等的页 页内偏移=帧内偏移 然而页号大小≠帧号大小，因为逻辑地址是连续的，但物理地址不一定是连续的 进程逻辑地址的表示：二元组（p，o） p：页号（P位，2P个页） o：页内偏移（S位，每页有2^S字节） 页式存储中的地址映射 如何将页映射到帧？ 逻辑地址中的页号 物理地址中的帧号是不连续的 不是所有的页都有对应的帧 页表 页表保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系。 CPU从逻辑地址中得到页号和偏移量 在页表中以页号作为下标查找帧号 用帧号和偏移量组成物理地址 普通页表页表概述 页表结构 每个进程都有一个页表 每个页面对应一个页表项 随进程运行状态而动态变化（可以动态调整内存空间大小） 页表基址寄存器：PTBR，Page Table Base Register 页表项的组成： 帧号：f 页表项标志： 存在位（resident bit）：逻辑页面是否存在与之对应的物理帧 修改位（dirty bit）：对应的页面中的内容是否被修改了 引用位（clock/reference bit）：在过去一段时间内是否访问过页中的某一个存储单元 页表地址转换实例有了存在位之后，就会发现，有些逻辑页没有对应的物理帧 页式存储管理机制的性能问题 内存访问性能问题： 访问一个内存单元需要2次内存访问 第一次访问：获取页表项 第二次访问：获取数据 页表大小问题： 页表可能非常大 64位机器如果每页1024字节，那么一个页表的大小会是多少？（2^54个页面*8个多字节） 如何处理？ 缓存（Caching） 间接（Indirection）访问：切段，多级页表 快表快表和多级页表 快表（Translation Look-aside Buffer，TLB） 目标：缓存近期访问的页表项 TLB使用关联存储（associated ），具备快速访问性能 关联存储器：有一组key，可以并行地查找所有表项，得到匹配项 因为快表位于CPU中，所以它的速度快、成本高、功耗大 如果TLB命中，物理页号可以很快被获取 如果TLB未命中，对应的表项被更新到TLB中 多级页表多级页表 通过间接引用将页号分成k级 可以有效减少每级页表的长度，但是如果所有的页表项都存在，则多级页表并没有减少存储量 不过大部分进程并不会用到所有的逻辑地址空间 在x86架构中，CR3寄存器用于存储PTBR（页表基址） 页寄存器反置页表 减少页表占用的空间的一种做法 大地址空间问题 对于大地址空间（64-bits）系统，多级页表变得繁琐。 比如：5级页表 逻辑（虚拟）地址空间增长速度快于物理地址空间 页寄存器和反置页面的思路： 不让页表与逻辑地址空间的大小相对应 让页表与物理地址空间的大小相对应 页寄存器（Page Registers） 每个帧与一个页寄存器（Page Register）关联，寄存器内容包括： 使用位（Residence bit）：此帧是否被进程占用 占用页号（Occupier）：对应的页号p 保护位（Protection bits）：约定这一页的访问方式，可读，可写…… 页寄存器示例 物理内存大小：40964096=4K4KB=16MB 页面大小：4096bytes=4KB 页帧数：4096=4K 页寄存器使用的空间：8*4096=32Kbytes（假定每个页寄存器占8字节） 页寄存器带来的额外开销：32K/16M=0.2%（大约） 虚拟内存的大小：任意 页寄存器方案的特征 优点 页表大小相对于物理内存而言很小 页表大小与逻辑地址空间大小无关 缺点 页表信息对调后，需要根据帧号可找页号 在页寄存器中搜索逻辑地址中的页号 页寄存器中的地址转换 CPU生成的逻辑地址如何找对应的物理地址？ 对逻辑地址进行Hash映射，以减少搜索范围 需要解决可能的冲突 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行Hash变换 在快表中查找对应页表项 有冲突时遍历冲突项列表 查找失败时，产生异常 快表的限制 快表的容量限制 快表的功耗限制（StrongARM上快表功耗占27%） 反置页表反置页表 基于Hash映射值查找对应页表项中的帧号 进程标识与页号的Hash值可能有冲突 页表项中包括保护位、修改位、访问位和存在位等标识 查找过程： 从逻辑地址中得到页号 根据页号和PID计算出Hash值 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号 反置页表的Hash冲突 例子：在页表项中加入next项，指出全部冲突项的列表 段页式存储管理段页式存储管理段页式存储管理的需求段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势段式存储和页式存储能否结合？ 段页式存储管理在段式存储管理基础上，给每个段加一级页表逻辑地址：段号+若干个页号+页内偏移物理地址：帧号+页内偏移 123• 从逻辑地址中得到段号s和页号p，以及偏移o• 通过段基址（STBR）和s得到对应的段表项• 访问段表项对应的页表，得到对应的帧号 段页式存储管理中的内存共享通过指向相同的页表基址，实现进程间的段共享 共享段指向同一个页表 小结段式、页式、段页式内存分配总结 共同点 可以不连续 区别 块的大小 问题 加入页表或段表 页表大小问题 快表 多级页表 反置页表 实现细节 练习选择填空题描述段管理机制正确的是() 段的大小可以不一致 段可以有重叠 段可以有特权级 段与段之间是可以不连续的 都对。段的大小显然可以不一致（段描述符中给出的大小不同）。段之间可以重叠（没说不能重叠，而且完全扁平模型就是全都映射到全部物理内存。）段可以有特权级（段描述符中的DPL，访问段的最低特权级）。段之间当然也是可以不连续的。 描述页管理机制正确的是() 页表在内存中 页可以是只读的 页可以有特权级 上述说法都不对 前三个都对。当然有的地方不太准确。在80386系统中，一级页表一定在内存中，但二级页表不一定在内存中。PDE和PTE都可以规定访问权限，不过只有U/S（用户/OS权限）和R/W（只读/可读可写）位。 页表项标志位包括() 存在位(resident bit) 修改位(dirty bit) 引用位(clock/reference bit) 只读位(read only OR read/write bit) 简答题为什么要设计非连续内存分配机制？ 提高分配的灵活性 提高内存的利用效率 方便共享、充分利用内存空间 允许一个程序使用非连续的物理地址空间 允许共享代码与数据 支持动态加载和动态链接 非连续内存分配中内存分块大小有哪些可能的选择？大小与大小是否可变? 大块好管理，小块更灵活。段式存储下，大小是可变的，且块比较大。页式存储下，大小是固定的，且块比较小。 为什么在大块时要设计大小可变，而在小块时要设计成固定大小？小块时的固定大小可以提供多种选择吗？ 固定大小好管理，多种大小比一种大小灵活。可变大小更灵活，通常可变大小也会通过对齐来减少管理难度。小块时如果大小可变，则提供的灵活性没有那么多。 什么是段、段基址和段内偏移？ 段表示访问方式和存储数据的类型等属性相同的一段地址空间。段基址是段的起始地址（线性地址）。段内偏移是地址在段内的偏移量。 段式存储管理机制的地址转换流程是什么？为什么在段式存储管理中，各段的存储位置可以不连续？这种做法有什么好处和麻烦？ 段式存储管理中，地址转换是段基址（段号）加段内偏移。 段反映了程序的存储逻辑结构（数据段和代码段是分开的），程序不会从一个段的基址去访问另一个段，于是不同的段可以不连续。 好处是可以不连续，方便内存管理；麻烦是地址转换稍微复杂了一些。 什么是页（page）、帧（frame）、页表（page table）、存储管理单元（MMU）、快表（TLB, Translation Lookaside Buffer）和高速缓存（cache）？ 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） 把物理地址空间划分为大小相同的基本分配单位 大小一般为2的n次方，如512、4096、8192字节，4KB是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） 把逻辑地址空间也划分为相同大小的基本分配单位 帧和页的大小必须是相同的 页表：保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系 MMU：一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制，在较为简单的计算机体系结构中，负责总线的仲裁以及存储体切换 TLB：为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度 Cache：访问速度比一般随机存取内存（RAM）快的一种RAM，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术 页式存储管理机制的地址转换流程是什么？为什么在页式存储管理中，各页的存储位置可以不连续？这种做法有什么好处和麻烦？ 页式存储管理中，地址转换流程是页号-&gt;物理页帧号加页内偏移。 CPU使用连续的逻辑地址，存储访问时，逻辑地址先分成逻辑页号和页内偏移，然后通过页表定义的对应关系，把逻辑页面转换成物理页号，最后再把物理页号加页内偏移得到物理地址；于是不同的页可以不连续。 好处是可以不连续，方便内存管理中的存储分配和回收；麻烦是地址转换比较复杂（页表项访问开销和页表存储开销），并且频繁进行（每次存储访问会变成两次或更多）。 页表大小受哪些因素影响？ 页大小、地址空间大小、进程数目、页表级数 快表（TLB）与高速缓存（cache）有什么不同？ TLB中缓存的是线性地址物理地址的映射关系，由硬件管理，对软件是透明的。 Cache中缓存的是具体的内存内容，也由硬件管理，对软件是透明的。 为什么快表中查找物理地址的速度非常快？它是如何实现的？为什么它的的容量很小？ 因为它是在多个表项中同步查找有没有对应的线性地址项，所以很快。TLB的硬件是怎么实现的……大概瞎写吧。容量小是因为用电路换时间了（多路并行查找），成本和耗电量比较高。 什么是多级页表？多级页表中的地址转换流程是什么？多级页表有什么好处和麻烦？ 就是套了很多层的页表。地址转换流程就是不断根据每一级的页号和页表基址查找下一级的页表基址（或者查到页表项）。 好处是减小了页表占据的空间（因为程序一般不会用完自己的虚拟地址空间，所以大部分次级页表不需要生成）；麻烦是地址转换变得更加复杂和缓慢了。 页寄存器机制的地址转换流程是什么？ 对CPU访问的逻辑地址进行hash，然后查相应页寄存器。 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行Hash变换 在快表中查找对应页表项 有冲突时遍历冲突项列表 查找失败时，产生异常 反置页表机制的地址转换流程是什么？ 逻辑地址和进程号共同进行hash，然后查相应页寄存器。 查找过程： 从逻辑地址中得到页号 根据页号和PID计算出Hash值 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号；处理hash冲突 反置页表项有些什么内容？ PID、逻辑页号、标志位（可能还应该有指向下一个hash相同的页表项的指针） 段页式存储管理机制的地址转换流程是什么？这种做法有什么好处和麻烦？ 首先从逻辑地址翻译成线性地址（段机制），再从线性地址翻译成物理地址（页机制）。 好处是……。。。 麻烦是，地址访问过程甚至变得更加复杂和耗时了。 如何实现基于段式存储管理的内存共享？ ……就把需要重用的内存映射到不同的段里…… 如何实现基于页式存储管理的内存共享？ 不同的页表项指向相同的物理页…… 请简要分析64bit CPU体系结构下的分页机制是如何实现的 说明64bit CPU架构的分页机制的大致特点和页表执行过程 正确描述了64bit CPU支持的物理内存大小限制（1分） 正确描述了64bit CPU下的多级页表的级数和多级页表的结构或反置页表的结构（2分） 除上述两点外，进一步描述了在多级页表或反置页表下的虚拟地址–&gt;物理地址的映射过程（3分） 64位的寻址空间能够寻址16EB 的内存大小，对于目前的硬件来说太大了。在X64体系结构下，只实现了48位的虚拟地址。不同于x86体系结构，每级页表寻址长度变成9位，由于在x64体系结构中，普通页大小仍为4KB，然而数据却表示64位长，因此一个4KB页在x64体系结构下只能包含512项内容，所以为了保证页对齐和以页为单位的页表内容换入换出，在x64下每级页表寻址部分长度定位9位。 为了正确翻译x64的线性地址，其页表也从x86的2级变成了4级。翻译过程可参考Intel手册或者以下链接 http://www.cnblogs.com/lanrenxinxin/p/4735027.html 某系统使用请求分页存储管理，若页在内存中，满足一个内存请求需要150ns (10^-9s)。若缺页率是10%，为使有效访问时间达到0.5us(10^-6s),求不在内存的页面的平均访问时间。请给出计算步骤。 500=0.9150+0.1x （2）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持32KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : VALID | PFN6 … PFN0PDE格式（8 bit） : VALID | PT6 … PT0其 VALID==1表示，表示映射存在；VALID==0表示，表示映射不存在。PFN6..0:页帧号PT6..0:页表的物理基址&gt;&gt;5在物理内存模拟数据文件中，给出了4KB物理内存空间的值，请回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents。 Virtual Address 6c74Virtual Address 6b22 Virtual Address 03dfVirtual Address 69dc Virtual Address 317aVirtual Address 4546 Virtual Address 2c03Virtual Address 7fd7 Virtual Address 390eVirtual Address 748b比如答案可以如下表示： (注意：下面的结果是错的，你需要关注的是如何表示) Virtual Address 7570:–&gt; pde index:0x1d pde contents:(valid 1, pfn 0x33)–&gt; pte index:0xb pte contents:(valid 0, pfn 0x7f)–&gt; Fault (page table entry not valid) Virtual Address 21e1:–&gt; pde index:0x8 pde contents:(valid 0, pfn 0x7f)–&gt; Fault (page directory entry not valid) Virtual Address 7268:–&gt; pde index:0x1c pde contents:(valid 1, pfn 0x5e)–&gt; pte index:0x13 pte contents:(valid 1, pfn 0x65)–&gt; Translates to Physical Address 0xca8 –&gt; Value: 16链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，请说明原因。 （3）请基于你对原理课二级页表的理解，并参考Lab2建页表的过程，设计一个应用程序（可基于python、ruby、C、C++、LISP、JavaScript等）可模拟实现(2)题中描述的抽象OS，可正确完成二级页表转换。 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，提交你的实现，并说明区别。 （4）假设你有一台支持反置页表的机器，请问你如何设计操作系统支持这种类型计算机？请给出设计方案。 (5)X86的页面结构扩展思考题阅读64bit IBM Powerpc CPU架构是如何实现反置页表，给出分析报告。 interactive understand VMVirtual Memory with 256 Bytes of RAM：这是一个只有256字节内存的一个极小计算机系统。按作者的[[https://github.com/RobertElderSoftware/recc#what-can-this-project-do|特征描述]]，它具备如下的功能。CPU的实现代码不多于500行；支持14条指令、进程切换、虚拟存储和中断；用C实现了一个小的操作系统微内核可以在这个CPU上正常运行；实现了一个ANSI C89编译器，可生成在该CPU上运行代码；该编译器支持链接功能；用C89, Python, Java, Javascript这4种语言实现了该CPU的模拟器；支持交叉编译；所有这些只依赖标准C库。 针对op-cpu的特征描述，请同学们通过代码阅读和执行对自己有兴趣的部分进行分析，给出你的分析结果和评价。","tags":"os"},{"title":"OS Summary 5 - 物理内存管理:连续内存分配","url":"/2018/12/13/os-lecture-5-summary/","text":"内容概述 计算机体系结构和内存层次 地址空间和地址生成 连续内存分配 三种不同的分类策略 碎片整理 伙伴系统 uCore 中的连续内存管理实现框架 计算机体系结构和内存层次 计算机体系结构由 CPU、内存、I/O 设备、总线组成。 CPU 中包括： ALU、控制逻辑 寄存器 高速缓存：加快读写速度 存储管理单元 (MMU) 内存的特点： 最小访问单位是字节 (8 bit ) 一次可以读 / 写 4 字节 (32 位)，有地址对其问题 内存可以分为如下层次： CPU 中： L1 缓存 L2 缓存 这些缓存都是由硬件 (MMU) 来控制的，软件看不到 高速缓存未命中：( 这之下由操作系统软件来控制) 内存 缺页 外存 ( 虚拟内存 ) 操作系统的内存管理OS 内存管理的特点： 每个字节有自己的物理地址 分为内存和外存 每个进程有自己用的内存片，它们自己的地址之间是可以重叠的 MMU：将逻辑 ( 虚拟 ) 地址空间转换为物理地址空间 OS 内存管理的目标： 抽象：逻辑地址空间 保护：独立地址空间 共享：访问相同内存 虚拟化：更大的地址空间 操作系统采用的内存管理方式： 重定位 (relocation)：段地址 + 偏移 分段 (segmentation)：程序的逻辑结构不需要连成一片，而是分成代码、数据、堆栈 3 块，每一块的空间就减少了；但每段的内容是连续的 分页 (paging)：把内存分成最基本的单位 虚拟存储 (virtual memory)：目前多数系统 ( 如 Linux ) 采用的是按需页式虚拟存储 内存管理方式的实现是高度依赖硬件的： 与计算机存储架构紧密耦合 MMU (内存管理单元)：处理 CPU 存储访问请求的硬件 静态地址重定位：即在程序装入内存的过程中完成，是指在程序开始运行前，程序中的各个地址有关的项均已完成重定位，地址变换通常是在装入时一次完成的，以后不再改变，故成为静态重定位。优点：无需硬件支持缺点：1）程序重定位之后就不能在内存中搬动了；2）要求程序的存储空间是连续的，不能把程序放在若干个不连续的区域中。动态地址重定位：不是在程序执行之前而是在程序执行过程中进行地址重定位。更确切的说，是在每次访问内存单元前才进行地址变换。动态重定位可使装配模块不加任何修改而装入内存，但是它需要硬件一定位寄存器的支持。优点：1）目标模块装入内存时无需任何修改，因而装入之后再搬迁也不会影响其正确执行，这对于存储器紧缩、解决碎片问题是极其有利的；2）一个程序由若干个相对独立的目标模块组成时，每个目标模块各装入一个存储区域，这些存储区域可以不是顺序相邻的，只要各个模块有自己对应的定位寄存器就行。缺点：需要硬件支持。 地址空间和地址生成一般来说，地址空间至少有 3 种： 物理地址空间：硬件支持的地址空间 起始地址 0 到 MAXsys 线性地址空间：CPU 看到的地址 起始地址 0 大小取决于地址线的宽度 逻辑地址空间：在 CPU 中运行的进程看到的地址 起始地址 0 到 MAXprog 也就是用户程序可见的地址 逻辑地址的生成需要经过如下几个过程： 高级语言程序：写出函数 编译：对源代码进行编译，称为汇编源代码，此时仍然用符号来指代函数 汇编：汇编成二进制代码，用具体地址来替代符号了，但是有一些函数还没有找到 链接：加入函数库，找到库函数的地址 重定位：程序加载时进行，视程序实际位置改变符号地址 一般来说，生成地址有几个时机： 编译时（优点：简单） 假设起始地址已知 但如果起始地址改变，就必须重新编译 功能手机一般会有这种情况 加载时 如果加载时起始位置未知，编译器需生成可重定位的代码 ( relocation code ) 加载时，生成绝对地址 执行时（优点：灵活） 执行时代码可移动 需地址转换（映射）硬件支持（一般是虚拟存储） 连续内存分配一般分配给一个进程的地址空间是连续的，因此需要进行有效的内存分配。需求是，给进程分配一块不小于制定大小的连续的物理内存区域。定义碎片是过小的不能被利用的空闲内存，分为 2 类： 外部碎片：分配单元之间的未被使用内存 内部碎片：分配单元内部的未被使用内存（一般是否有内碎片取决于分配单元大小是否要取整） 我们在 uCore 中进行的是动态内存分配，需要满足如下要求： 当程序被加载执行时，分配一个进程指定大小可变的分区（块） 分区的地址是连续的 一般来说，操作系统需要维护至少 2 个数据结构，里面存储的内容是： 所有进程的已分配分区 空闲分区 ( Empty-blocks ) 常见的几种连续内存分配策略包括： 最先匹配 (First-fit) 最佳匹配 (Best-fit) 最差匹配 (worst-fit) 总的来说，这些匹配方式各有优劣，至于到底是什么优劣，与使用场景关系很大。 三种不同的分类策略最先匹配 (First Fit Allocation) 策略 思路：需要分配 n 个字节时，使用第一个可用的空间比 n 打的空闲块 原理和实现： 空闲分区列表按地址顺序排序 分配时搜索第一个合适的分区 释放分区时，检查是否可与邻近的空闲分区合并 优点： 简单 在搞地质空间有大块的空闲分区 缺点 容易产生外部碎片 分配大块时较慢 最佳匹配 (Best Fit Allocation) 策略 思路：分配 n 字节内存时，查找并使用不小于 n 的最小空闲分区 原理和实现： 空闲分区列表按照大小排序 分配时，查找一个合适的分区 释放时，查找并合并邻近的空闲分区（如果找到） 优点： 大部分分配的尺寸较小时，效果很好 可避免大的空闲分区被拆分 可减少外部碎片的大小 相对简单 缺点： 外部碎片较多 释放分区较慢 容易产生很多无用的小碎片 最差匹配 (Worst Fit Allocation) 策略 思路：分配 n 字节时，使用尺寸不小于 n 的最大空闲分区 原理和实现： 空闲分区列表由大到小排序 分配时，选最大的分区 释放时检查是否可与邻近的空闲分区合并，进行可能的合并，并调整空闲分区列表顺序 优点： 中等大小的分配较多时，效果最好 避免出现太多的小碎片 缺点： 释放分区较慢 外部碎片较多 容易破坏打的空闲分区，因此难以分配大的分区 碎片整理上述方法都会产生外碎片。（但是不会产生内碎片，因为是按需分配的）如果碎片太多，就有可能出现，即使空余内存总数足够大，也无法分配出一块连续内存的情况。为此就需要进行碎片整理。碎片整理的定义是通过调整进程占用的分区位置来减少或避免分区碎片。一般有两种碎片整理的方法 紧凑（compaction）通过移动分配给进程的内存分区，以合并外部碎片 进行碎片紧凑的条件：所有的应用程序可动态重定位 需要在应用程序等待时进行移动 需要考虑开销 分区对换（Swapping in/out）：通过抢占并回收处于等待状态进程的分区，以增大可用内存空间 这就让更多进程能够在内存里交替运行 需要解决的问题：交换哪个（些）进程？ swap分区在linux中是耳熟能详的，在早期很有用，但代价很大，因为外存的速度远远慢于内存 有了虚拟页式存储之后，纯粹的分区对换的意义就不大了 伙伴系统伙伴系统（Buddy System）是一种连续存储分配的办法，它解决了分配位置和碎片的问题。 假定整个可分配的分区大小为2u，伙伴系统的分配和释放过程如下： 分配过程： 需要的分区大小为2u−1&lt;s≤2u时，把整个块分配给该进程 若s≤2i−1−1，则将大小为2i的当前空闲分区划分成两个大小为2i−1−1的空闲分区 重复划分过程，直到2i−1&lt;s≤2i，并把一个空闲分区分配给该进程 释放过程： 将进程占用的块释放 查看它能否与相邻的空闲块合并（注意边界条件） 如果能合并，则不断合并到不能再合并为止 由分析可知，内碎片的大小最多是2i−1−1，没有外碎片。 伙伴系统的具体实现数据结构： 空闲块按大小和起始地址组织成二维数组（或者说一维数组+一维链表） 第一维：大小；第二维：地址 初始状态：只有一个大小为2u的空闲块 分配过程： 由小到大 在空闲块数组中找最小的可用空闲块（只要有合适的空闲块，就不切分大块，这是隐含的一个原则吧） 如果块太大，则对可用空闲块进行二等分，直到得到合适大小的块 释放过程： 把释放的块放入空闲块数组 合并满足合并条件的空闲块，合并条件是： 大小相同，均为2i 地址相邻 相邻两块的低地址必须是2^(i+1)的倍数 练习选择填空题操作系统中可采用的内存管理方式包括() 重定位(relocation) 分段(segmentation 分页(paging) 段页式（segmentation+paging） 都有。虽然我还是很难想象重定位是内存管理方式，这难道不是进程的管理方式么，虽然能够把进程在内存中搬移大概是上述几种分配策略的前提…… 在启动页机制的情况下，在CPU运行的用户进程访问的地址空间是() 物理地址空间 逻辑地址空间 外设地址空间 都不是 用户进程访问的内存地址是虚拟地址。虚拟地址加上对应的段选择子构成逻辑地址。逻辑地址经过分段翻译成线性地址。线性地址经过分页翻译成物理地址。（但是，即使没有启动页机制，用户进程访问的地址空间也应该是逻辑地址空间吧） 连续内存分配的算法中，会产生外碎片的是() 最先匹配算法 最差匹配算法 最佳匹配算法 都不会 三种算法都会有外碎片，而没有内碎片。相比之下，分页不会有外碎片，只会有内碎片。伙伴系统是可能会产生外碎片的，当然也有内碎片。 在使能分页机制的情况下，更合适的外碎片整理方法是() 紧凑(compaction) 分区对换(Swapping in/out) 都不是 分页方式不会有外碎片。虽然很对，但这道题完全毫无意义。 描述伙伴系统(Buddy System)特征正确的是() 多个小空闲空间可合并为大的空闲空间 会产生外碎片 会产生内碎片 都不对 小空闲空间在满足一定条件时可以合并。因为是一个不断二分的过程，所以外碎片是可能会产生的。因为是分配2的幂大小的内存，所以内碎片也是有的。 简答题操作系统中存储管理的目标是什么？ 抽象 保护 共享 虚拟化 描述编译、汇编、链接和加载的过程是什么？ 编译：将程序源代码转换为汇编代码 汇编：将汇编代码转为二进制的机器码 链接：将多个二进制的机器码结合成一个可执行环境 加载：将程序从外存中加载到内存中 什么是内碎片、外碎片？ 内碎片是指分配给任务的内存大小比任务所要求的大小所多出来的内存。外碎片指分配给任务的内存之间无法利用的内存。当然，一块内存是否为外碎片取决于需要分配的内存的大小。 最先匹配会越用越慢吗？请说明理由（可来源于猜想或具体的实验）？ 最先匹配总是先找低地址空间的内存，到后期低地址空间都是大量小的不连续的内存空间，每次都要扫描低地址空间后到达高地质空间才能得到可用的内存。所以大概是会越用越慢的。 最差匹配的外碎片会比最优适配算法少吗？请说明理由（可来源于猜想或具体的实验） 应该会的。因为每次都找到最大的内存块进行分割，因此分割剩下的内存块也很大，往往还可以再装下一个程序。 理解0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm算法中分区释放后的合并处理过程？ (optional) 它们的处理方式都是查看边上是否也有空闲块，如果有，则合并空闲块，然后将空闲块管理数据插入链表中。如果能进行合并，都需要连续合并。当然，伙伴系统的合并过程需要判断是否满足条件。 对换和紧凑都是碎片整理技术，它们的主要区别是什么？为什么在早期的操作系统中采用对换技术？ 区别是，紧凑是在内存中搬动进程占用的内存位置，以合并出大块的空闲块；对换是把内存中的进程搬到外存中，以空出更多的内存空闲块。采用对换的原因是，处理简单。不过代价也比较高，因为外存比较慢。 伙伴系统的空闲块如何组织？ 按照内存的大小由一系列链表组织。类似于哈希表，将相同大小的内存区域首地址连接起来。（因为一般来说，内存要按首地址大小排列，链表的插入删除比较简单啊） 伙伴系统的内存分配流程？ 当向内核请求分配(2i−1，2i]数目的页块时，按照2i大小的块来请求处理。如果对应的块链表中没有空闲页块，则在更大的页块链表中找空闲块，并将大块进行切分，直到得到满足要求的块。如果切出了多余的块，伙伴系统会将这些块插入到对应的空闲页块链表中。 伙伴系统的内存回收流程？ 当释放多页的块时，内核首先计算出该内存块的伙伴的地址。内核将满足以下条件的三个块称为伙伴： 两个块具有相同的大小，记作b。 它们的物理地址是连续的。 第一块的第一个页的物理地址是2∗(2b)的倍数。 如果找到了该内存块的伙伴，确保该伙伴的所有页都是空闲的，以便进行合并。内存继续检查合并后页块的“伙伴”并检查是否可以合并，依次类推。 （所以才叫伙伴系统，了解了）","tags":"os"},{"title":"OS Summary 4 - 实验:系统软件启动过程","url":"/2018/12/08/os-lecture-4-summary/","text":"内容概述主要介绍了一些和 Lab1 相关的内容。（对 C++ 一窍不通。。羞耻，只是大致了解一下，有时间和精力要对照试验内容认真补一下。。。 系统启动过程 BIOS BootLoader 段机制 操作系统的加载 C 语言的一些相关的只是 函数调用过得实现（略） GCC 内联汇编（略） x86 架构下的中断处理过程 系统启动过程 BIOS BIOS 的工作过程已经在第三讲中详细说过了，在此不再重复。唯一值得注意的是，虽然实模式下的寻址方式是 Base (16 位寄存器 CS)*16+Offset (16位寄存器IP) = 线性地址( 20 位)，但这并不是段机制。 bootloader BIOS 将控制权转交给bootloader。它的工作内容主要包括： 使能保护模式 ( protection mode ) 和段机制 (segment level protection)，切换回 32 位 4G 的寻址空间，对段机制进行初始化 从硬盘上读取 ELF 格式的 ucore kernel (位于 MBR 后面的扇区) 并放到内存中固定的位置。 跳转到 ucore OS 的入口点 (entry point)，将控制权转交给 ucore OS 使能保护模式 将系统寄存器 CR0 的第 0 个 bit 置为 1，说明进入保护模式。当然，在此之前要开 A20，并准备好 GDT 表，将基址加载到 GDT 基址寄存器中。 段机制 保护模式下必须开启段机制。 总的来说，段机制其实是一种映射关系。一个段指向的是线性地址空间中一段连续的内存，有基址和 limit 。短与段之间是可以重叠的。 设置段机制的方法是，建立一个数组来存储段描述符表，称为全局描述符表 GDT (也称为段表，在 ucore 中是由 bootloader 建立的，因为开启保护模式之前就需要设置好 GDT )，其中包括描述符表的位置、大小等信息。这样 CPU 就可以找到段表了 (用 GDTR 寄存器保存表信息)。除了设置 GDT 之外，还要为 CS、DS 等段寄存器设置好对应的 index，使他们能够指向全局描述符表 GDT 对应的项，这可以在切换到保护模式之后进行。 硬件提供了一些段寄存器。这些段寄存器指向段描述符，比较重要的几个段寄存器包括： CS : 代码段寄存器 DS : 数据段寄存器 SS : 堆栈段寄存器 段寄存器的结构是这样的： 高 13 位：GDT index 1 位：TI，一般设置为0，因为没有用到 LDT (本地描述符表) 2位：RP，表明段优先级，有 4 个特权级，一般应用程序放在 3 , 操作系统放在 0 每个段寄存器指向一个 GDT 或者 LDT 中的段描述符。段描述符描述了一个段的起始地址和它的大小。(一个段描述符的大小是 8 字节，具体内容比较复杂。。。忽略) uCore 中采用过的应该是 Intel 手册中提到的扁平保护模型。 在设置完所需的表和寄存器之后，段机制就可以完成从逻辑地址到线性地址（在页机制没有开启的时候，线性地址 = 物理地址）的翻译了。 通过逻辑地址中的段选择子查找段描述符表项 从表项中读出段基址和段的大小 检查逻辑地址中的 offset 是否合法 安全性检查 段基址 (Base Address) + 段内偏移量 (offset) = 线性地址 (linear address) 代码实现过程（略。。。） x86 架构下的中断处理过程此处的 “中断” 包括两类： 中断 (Interrupts) 外部中断 (External (hardware generated) interrupts)：串口、硬盘、网卡、时钟 软件产生的中断 (Software generated interrupts)：INT n指令，通常用于系统调用 异常 (Exceptions) 程序错误 软件产生的异常 (Software generated excetpion)：INTO, INT 3 和 BOUND 机器检查出的异常 通过中断号确定中断服务例程 ( ISR )（略。。。）","tags":"os"},{"title":"OS Summary 3 - 启动、中断、异常和系统调用","url":"/2018/12/02/os-lecture-3-summary/","text":"内容概述 系统启动过程 BIOS 的原理 BIOS 的一些具体工作 系统启动规范 中断，异常和系统调用 中断 系统调用 系统启动过程 BIOS 的基本功能 计算机刚刚启动时的内存布局如图： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM 1MB ~ (4GB - 64KB) 空闲空间 640KB ~ 1MB 视频内存，BIOS启动固件（映射） 0 ~ 640KB 空闲空间 （这是一个非常简略的示意图，具体请见Memory Map (x86))） 这一复杂的映射机制是为了保证向后兼容而设计的。在8086时代，内存只有1MB大小，此时，BIOS的代码固化在EPROM中，且EPROM被编址在1MB内存地址空间的最高64KB中。PC加电后，CS寄存器初始化为0xF000，IP寄存器初始化为0xFFF0，所以CPU要执行的第一条指令的地址为CS:IP=0xF000:0XFFF0（ Segment:Offset表示） =0xFFFF0（ Linear表示） 。这个地址位于被固化的EPROM中，该地址存储了一条指令，它是一个长跳转指令JMP F000:E05B。这样就开启了BIOS的执行过程。 到了32位的80386 CPU时代，内存空间扩大到了4G，多了段机制和页机制。如果仍然把BIOS启动固件编址在0xF0000起始的64KB内存地址空间内，就会把整个物理内存地址空间隔离成不连续的两段，一段是0xF0000以前的地址，一段是1MB以后的地址，这很不协调。为此，intel采用了一个折中的方案：默认将执行BIOS ROM编址在32位内存地址空间的最高端，即位于4GB地址的最后一个64KB内。在PC系统开机复位时，CPU进入实模式，并将CS寄存器设置成0xF000，将它的shadow register的Base值初始化设置为0xFFFF0000，EIP寄存器初始化设置为0x0000FFF0。所以机器执行的第一条指令的物理地址是0xFFFFFFF0。80386的BIOS代码也要和以前8086的BIOS代码兼容，故地址0xFFFFFFF0处的指令还是一条长跳转指令jmp F000:E05B。注意，这个长跳转指令会更新CS寄存器和它的shadowregister，即执行jmp F000:E05B后，CS将被更新成0xF000。表面上看CS其实没有变化，但CS的shadow register被更新为另外一个值了，它的Base域被更新成0x000F0000，此时形成的物理地址为Base+EIP=0x000FE05B，这就是CPU执行的第二条指令的地址。此时这条指令的地址已经是1M以内了，且此地址不再位于BIOS ROM中，而是位于RAM空间中。由于Intel设计了一种映射机制，将内存高端的BIOS ROM映射到1MB以内的RAM空间里，并且可以使这一段被映射的RAM空间具有与ROM类似的只读属性。所以PC机启动时将开启这种映射机制，让4GB地址空间的最高一个64KB的内容等同于1MB地址空间的最高一个64K的内容，从而使得执行了长跳转指令后，其实是回到了早期的8086 CPU初始化控制流，保证了向下兼容。 上述说明指出，在 CPU 启动之后，它一直处于实模式之下，执行的第一条指令是 jmp F000:E05B ，跳转到 BIOS 程序中。此时，PC = 16 * CS + IP，系统地址空间只有 20 位（1MB）。 20 位地址空间：1MB 这之后 BIOS 会进入以下工作： 在实模式下提供基本输入输出方法 通过中断调用实现 只能在实模式下使用，操作系统无法使用 运行自检程序 用户选择引导设备（从什么介质启动） 将 BootLoader 从磁盘的引导扇区加载到内存中 0x7c00 开始的位置 跳转到 BootLoader的位置：CS:IP=0000:7C00 系统设置信息 开机后自检程序 系统自启动程序等 这之后，控制权就交给 BootLoader： 切换到保护模式 将操作系统的代码和数据从硬盘加载到内存中（因为 BIOS 无法处理硬件的文件系统） 跳转到操作系统的起始地址 加载之后的内存布局如下表： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM ? ~ (4GB - 64KB) 空闲空间 1MB ~ ? 操作系统 640KB ~ 1MB 视频内存，BIOS启动固件（映射） ? ~ 640KB 空闲空间 0x7c00 ~ ? bootloader 0 ~ 0x7c00 BIOS数据 最后，bootloader把控制权转交给操作系统。 BIOS 的一些具体工作BISO 本身的初始化内容 硬件自检 POST 检测系统中内存和显卡等关键部件的存在和工作状态 查找并执行显卡等接口卡 BIOS，进行设备初始化 执行系统 BIOS，进行系统检测：检测和配置系统中安装的即插即用设备 更新 CMOS 中的扩展系统配置数据 ESCD 按指定启动顺序从硬盘、软盘等设备启动 BIOS 如何读取 BootLoader Wiki上是这么说的： 系统开机或者重启。 BIOS加电（台湾用语：开机）自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示”NO ROM BASIC”然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 标准MBR的结构如下： 地址（十进制） 描述 长度（字节） 0 代码区 440（最大446） 440 选用磁盘标志 4 444 一般为空值; 0x0000 2 446 标准MBR分区表规划（四个16 byte的主分区表入口） 64 510 MBR有效标志：0x55AA 2 系统启动规范课程中还讲到了BIOS-MBR、BIOS-GPT、PXE和UEFI等系统启动规范，其中UEFI似乎还更重要一点。这似乎是通用的现代BIOS标准。 中断、异常和系统调用定义： 系统调用（System Call)：应用程序主动向操作系统发出的服务请求 异常（Exception)：非法指令或其他原因导致当前指令执行失败（如：内存出错）后的处理请求 中单（Hardware Interrupt）：来自硬件设备的处理请求 它们的相同之处是，采用的处理方式大致相同。无论发生异常、中断、还是系统调用，都需要由硬件保存现场和中断号，转到内核态，进入中断向量表，查找对应的设备驱动程序地址（异常）、异常服务例程地址（异常），或找到系统调用表，并在其中查找对应的系统调用实现的起始地址。处理完毕之后，在进行现场切换，会到用户态继续执行程序（如果可能继续的话）。它们的区别如下表： 源头 响应方式 处理机制 中断 外设 异步 持续，对用户应用程序是透明的 异常 应用程序或内核意想不到的行为 同步 杀死或重新执行意想不到的应用程序指令 系统调用 应用程序请求操作提供服务 异步或同步 等待和持续 这三者的处理有时可以嵌套，有时不可以。 相比于用户态的函数调用，中断和异常的开销是比较大的，因为他们需要进行： 特权级的切换 建立内核堆栈 验证参数的合法性（防止对内核的恶意攻击） 内核态需要映射到用户态的地址空间（因为需要访问用户程序的一些内容），因此㤇更新页面映射权限 内核态也拥有独立的地址空间，因此 TLB 会失效 中断的具体处理机制 中断处理的过程需要软件和硬件的配合（虽然系统调用和异常也是。。。） 硬件处理内容包括： 在 CPU 初始化时设置中断使能表示 依据内部或者外部事件设置中断标志 依据中断向量调用对应的中断服务例程 软件处理内容包括： 现场保存（编译器） 终端服务处理（服务例程） 清楚中断标记（服务例程）（系统调用只占用一个中断向量，另有系统调用表） 现场恢复（编译器） 系统调用 特点 系统调用时操作系统服务的编程接口 通常由高级语言编写（ C 或 C ++） 程序访问系统调用通常是高层次的 API 接口（比如封装到标准 C 库一）而不是直接进行系统调用 3中最常用的应用程序编程接口（API): Win32 API：Windows POSIX API：UNIX、LINUX、Mac OS X Java API：用于JAVA虚拟机（JVM），是对实际系统调用的进一步抽象 系统调用的实现 每个系统调用对应一个系统调用号 系统调用接口根据系统调用号来维护表的索引 系统调用接口调用内核态中的系统调用功能实现，并返回系统调用的状态和结果 用户不需要系统调用的实现 需要设置调用参数和获取返回结果 操作系统接口的细节大部分都隐藏在应用编程接口后 通过运行程序支持的库来管理 注意，系统调用时，堆栈需要切换（内核和用户程序使用的是不同的堆栈），特权级需要进行切换 习题简答题BIOS从磁盘读入的第一个扇区是是什么内容？为什么没有直接读入操作系统内核映像？ BIOS完成硬件初始化和自检后，会根据CMOS中设置的启动顺序启动相应的设备，这里假定按顺序系统要启动硬盘。但此时，文件系统并没有建立，BIOS也不知道硬盘里存放的是什么，所以BIOS是无法直接启动操作系统。另外一个硬盘可以有多个分区，每个分区都有可能包括一个不同的操作系统，BIOS也无从判断应该从哪个分区启动，所以对待硬盘，所有的BIOS都是读取硬盘的0磁头、0柱面、1扇区的内容，然后把控制权交给这里面的MBR (Main Boot Record）。 我认为上述答案并不十分确切。比如，在uCore中，虽然BIOS没有建立文件系统，bootloader也没有建立文件系统啊。但是，加载操作系统是个很复杂的过程：就比如uCore，我们需要完成对ELF文件格式的解析和文件本身的读入。BIOS工作在实模式，本身访存范围只有1MB（能使用的数据只有0 ~ 0x7c00的范围），而且代码长度被限制在64KB。为了将OS读入到高地址的内存中，需要BIOS进行模式的切换。但是，如果BIOS进行了实模式到保护模式的切换，就不能实现向后兼容了。而且不同的OS的文件格式和处理方法也有差异，这会导致BIOS十分复杂。因此，让OS提供自己的启动程序是最好的选择。 比较UEFI和BIOS的区别。 统一可扩展固件接口 (Unified Extensible Firmware Interface, UEFI) 是一种个人电脑系统规格，用来定义操作系统与系统固件之间的软件界面，作为BIOS的替代方案。 UEFI启动对比BIOS启动的优势有三点： 安全性更强：UEFI启动需要一个独立的分区，它将系统启动文件和操作系统本身隔离，可以更好的保护系统的启动； 启动配置更灵活：EFI启动和GRUB启动类似，在启动的时候可以调用EFIShell，在此可以加载指定硬件驱动，选择启动文件。比如默认启动失败，在EFIShell加载U盘上的启动文件继续启动系统； 支持容量更大：传统的BIOS启动由于MBR的限制，默认是无法引导超过2TB以上的硬盘的。随着硬盘价格的不断走低，2TB以上的硬盘会逐渐普及，因此UEFI启动也是今后主流的启动方式。 分区引导扇区的结束标志是什么？ 0X55AA。当然，上面也说到了，BIOS除此之外还会检查别的内容。 在UEFI中的可信启动有什么作用？ 通过启动前的数字签名检查来保证启动介质的安全性。 什么是中断、异常和系统调用？ 中断：外部意外的响应； 异常：指令执行意外的响应； 系统调用：系统调用指令的响应。 这个回答真是十分简洁明了。 中断、异常和系统调用的处理流程有什么异同？ 相同点：都会进入异常服务例程，切换为内核态。 不同点： 源头不同，中断源是外部设备，异常和系统调用源是应用程序； 响应方式不同，中断是异步的，异常是同步的，系统调用异步和同步都可以。 处理机制不同，中断对用户程序是透明的，异常会重新执行用户指令或杀死用户进程，系统调用一般是用户程序调用的 系统调用与函数调用的区别是什么？ 汇编指令的区别 系统调用：使用INT和IRET指令 函数调用：使用CALL和RET指令 安全性的区别 系统调用有堆栈和特权级的转换过程，函数调用没有这样的过程，系统调用相对更为安全 性能的区别 时间角度：系统调用比函数调用要做更多和特权级切换的工作，所以需要更多的时间开销 空间角度：在一些情况下，如果函数调用采用静态编译，往往需要大量的空间开销，此时系统调用更具有优势","tags":"os"},{"title":"OS Summary 2 - 操作系统实验环境","url":"/2018/11/27/os-lecture-2-summary/","text":"内容概述 实验内容的详细介绍 X86-32硬件的介绍 uCore 的部分编程技巧和数据结构 如何使用工具编写和调试实验 实验主要是使用 C 语言实现的，目前还没有认真动手操作，只是大概了解一下思路。 实验具体内容略。。。 X86-32硬件简单介绍 运行模式 80386 共有四中运行模式，我们只用到了其中两种 实模式：加电后的默认模式，在BootLoader中就会切换为保护模式 保护模式：一般的模式 寻址方法 逻辑地址：由16位的段选择子和32位的偏移量组成，是应用程序直接使用的地址空间（大概就是程序运行时访问的地址） 线性地址：由逻辑地址的偏移量 + 段基址得到，是虚存管理下每个运行的应用程序能访问的地址空间 物理地址：处理器提交到总线上用于访问计算机系统中内存和外设的最终地址。如果未开启页机制，则物理地址 = 线性地址；否则通过页表和线性地址可得到物理地址 寄存器 通用寄存器 EAX : 累加器 EBX : 基址寄存器 ECX : 计数器 EDX : 数据寄存器 ESI : 原地址指针寄存器 EDI : 目的地址指针寄存器 EBP : 基址指针寄存器 ESP : 堆栈指针寄存器 段寄存器 CS : 代码段 ( Code Segment) DS : 数据段（Data Segment） ES : 附加数据段（Extra Segment） SS : 堆栈段（Stack Segment FS : 附加段 GS : 附加段 指令寄存器 EIP : 指令的段内偏移地址 标志寄存器 EFLAGS : TF : 开启单步调试 IF : 开启硬件中断 IOPL : I/O特权级，CPL &lt;= IOPL 时才能进行 I/O 操作 选择题略。。。 简答题你理解的对于类似ucore这样需要进程/虚存/文件系统的操作系统，在硬件设计上至少需要有哪些直接的支持？至少应该提供哪些功能的特权指令？ 进程的切换需要硬件支持时钟中断；虚存管理需要地址映射机制，从而需要MMU等硬件；对于文件系统，需要硬件有稳定的存储介质来保证操作系统的持久性。对应的，应当提供中断使能，触发软中断等中断相关的，设置内存寻址模式，设置页表等内存管理相关的，执行 I/O 操作等文件系统相关的特权指令。 对于现代操作系统（每个进程占一个时间片）时钟中断是非常重要的。存储介质当然也是非常重要的。当然，事实上，MMU 没有也行，可以用用户态函数库来实现地址转换，但这样可能就保证不了安全性了。 Intel 手册第 3 卷 2.8 j节 “System Instruction Summary” 中给出了一个系统指令列表。 “系统指令完成的是系统级的功能，包括加载系统寄存器、管理 Cache、管理终端和设置调试寄存器。其中的大部分指令都必须由操作系统或特权级为 0 的进程执行；另一部分可以由任何特权级的进程执行。” 你理解的x86的实模式和保护模式有什么区别？物理地址、线性地址、逻辑地址的含义分别是什么？ 保护模式和实模式的根本区别是进程内存是否受保护。（作者的意见是，实模式既是一个历史包袱，又有一定的实际用途。在实模式下，BIOS 自检和加载 BootLoader 的程序可以尽可能简单，因为不需要建立复杂的段映射。但是段机制必须开启这一点也是历史包袱。总之，BootLoader 一开始就开了 A20 ，设置了GDT然后长跳转切换到保护模式了。）实模式将整个内存看成分段的区域，程序代码和数据位于不同的区域，系统程序和用户程序没有区别对待，而且没一个指针都是指向“实在”的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并改变了值，那么对于这个别修改的系统程序或用户程序，其后果可能是灾难性的。为了克服这种低劣的内存管理模式，处理器厂商开发出保护模式。这样，物理内存不能直接被程序访问，程序内部的地址（虚拟地址）要由操作系统转化为物理地址去访问，程序对此一无所知。 物理地址：是处理器提交到总线上用于访问计算机系统中的内存和外设的最终地址。 逻辑地址：在有地址变换功能的计算机中，访问指令给出的地址叫逻辑地址。（一般的定义是段选择子+段内偏移量是逻辑地址。大概） 线性地址：线性地址是逻辑地址和物理地址变换之间的中间层，是处理器通过段（Segment）机制控制下形成的地址空间 虚拟地址：对这个名称的定义总是模糊不清。在这门课中，似乎虚拟地址就是程序内存的地址。","tags":"os"},{"title":"OS Summary 1 - 操作系统概述","url":"/2018/11/21/os-lecture-1-summary/","text":"内容概述 什么是操作系统 操作系统的演变 操作系统结果的分类 什么是操作系统操作系统可以是： 一个控制程序 一个资源管理器 一套标准库 操作系统通常有内核、命令行和 GUI 组成。我们研究的主要是内核。可以分成以下4个层次 ： 应用程序 命令行程序、编译器、解释器、系统库 内核 内核向上提供系统调用接口 同时调用下层提供的硬件抽象 硬件设备 操作系统内核的特征： 并发：OS 需要管理和调度多个同时运行的程序 共享：对资源的互斥共享 虚拟：对 CUP 和内存资源的虚拟化 异步：程序的运行时时常会停止的，OS 需要保证程序展厅之后状态不变 操作系统的演变 单用户系统：1945 - 1955 OS = 装载器 + 通用子程序库 存在的问题：任务完全为穿行执行，由于读卡时间过长，执行时间比例降低 批处理系统：1955 - 1965 每个任务在每个组件中串行执行，总体看来是并行执行的 解决了利用率的问题 多道程序系统：1965 - 1980 将多个程序储存在内存中，复用 CPU 在程序进行 I/O 操作室将其阻塞，切换到别的程序 分时系统：1970 - 定义中断当前程序，实现对CPU的复用 个人电脑操作系统 分布式操作系统 …… 操作系统结构的分类操作系统的结构可以分为以下几种： 简单结构：没有拆分为模块，没有很好的分离接口和功能 应用程序可以直接访问最底层的服务，也可以使用操作系统的服务 例： MS-DOS 分层结构：将操作系统分为几层，每层建立在底层之上 优点：可移植性强 缺点：层次过多会导致效率降低 例：UNIX 微内核结构：将一些内核服务移动到用户态，内核只保留进程通信和硬件支持功能 优点：灵活，安全 缺点：性能差 例：目前的系统结构是微内核结构和分层结构的混合体 外核结构：内核只起到资源的保护和隔离功能，操作系统原有功能由用户态操作系统库支持 虚拟机结构：操作系统和虚拟机管理器交互，虚拟机管理器负责和硬件交互 习题选择填空题 当前常见的操作系统主要用C，C++，ASM编程语言编写。 “Operating system”这个单词起源于Operator。 指的是原来的系统操作员。 在计算机系统中，控制和管理各种资源、有效地组织多道程序运行的系统软件称作操作系统。 对操作系统定义的考察。当然我觉得这个答案并不全面，加上“提供了一套标准库”（也就是系统调用）会更好。 允许多用户将若干个作业提交给计算机系统集中处理的操作系统称为批处理操作系统。 这说明单用户系统是每个任务手动提交上去的。 你了解的当前世界上使用最多的32bit CPU是ARM，其上运行最多的操作系统是Android。 答案如此，没有找到信源。不过知道这个也没什么意义。 应用程序通过系统调用接口获得操作系统的服务。 系统调用是非常重要的。这是应用程序主动进入内核态的方式。 现代操作系统的特征包括并发性，共享性，虚拟性，异步性，持久性。 特征到底应该包括哪些也是见仁见智。OSTEP中总结出的三点是虚拟，并发和持久性。异步性和共享性大概可以归入并发性。同时我也觉得持久性未必是操作系统的特点，而是存储设备的特点。当然这也可能是我的理解不够。 UPD：操作系统本身也是需要从持久性存储设备中读入的。文件系统也是OS的重要组成成分。所以我想得可能太片面了。 操作系统内核的架构包括宏内核，微内核，外核。 这个答案和上面讲的并不相符。那么，当然应该填简单结构、分层结构、微内核结构、外核结构和虚拟机结构了。 简答题请总结你认为操作系统应该具有的特征有什么？并对其特征进行简要阐述。 操作系统应该具有的特征有：虚拟性、并发性、异步性、共享性和持久性。 虚拟性：虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备。 并发性：并发是指两个或多个事件在同一时间间隔内发生，在多道程序环境下，一段时间内宏观上有多个程序在同时执行，而在同一时刻，单处理器环境下实际上只有一个程序在执行，故微观上这些程序还是在分时的交替进行。操作系统的并发是通过分时得以实现的。操作系统的并发性是指计算机系统中同时存在多个运行着的程序，因此它具有处理和调度多个程序同时执行的能力。 异步性：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。异步性使得操作系统运行在一种随机的环境下，可能导致进程产生于时间有关的错误。但是只要运行环境相同，操作系统必须保证多次运行进程，都获得相同的结果。 共享性：系统中的资源可供内存中多个并发执行的进程共同使用。（事实上，只能做到互斥共享，或者说同时。） 持久性：通过实现文件系统，操作系统可以将程序以及数据存储在磁盘等存储介质中。 详细解释可以参考操作系统的特征。 为什么现在的操作系统基本上用C语言来实现？为什么没有人用python，java来实现操作系统？ C语言是编译型语言，有良好的性能，能够直接嵌入汇编，可以方便地操作硬件；Python，Java无法保证性能，不能直接操作硬件。 不过，仍然是有人用这些语言来编写操作系统的，比如： 用Java实现的操作系统：JavaOS 用Python实现的操作系统：pycorn，pythonix 用Rust实现的操作系统：Redox 参考： https://github.com/chyyuu/os_course_info https://zhanghuimeng.github.io/ http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240243X+sp/about","tags":"os"},{"title":"扫一扫下面的二维码图案，加我微信","url":"/about/wechat-id.html","text":"","tags":""},{"title":"About Me","url":"/about/index.html","text":"Hello my name is Shinhwa Wang, a programmer at AsiaInfo living in Kualua Lumpur, Malaysia. Current Focus Alogorithms Computer Systems Network Database Java English I’m interested in all kinds of technical stuff and like hiphop music and dance.If you’d like to know more about me, check out my Resume and GitHub. My Biggest Influences and fav 💕 blogsCS-Notes: The blog made me realize how much more I need to learn. Contact Me ​ For general communication, contact shinhwawang2015@gmail.com ​ My Wechat id wshpop","tags":""},{"title":"404","url":"/404.html","text":"* { -webkit-box-sizing: border-box; box-sizing: border-box; -webkit-user-select: none; /* Safari 3.1+ */ -moz-user-select: none; /* Firefox 2+ */ -ms-user-select: none; /* IE 10+ */ user-select: none; /* Standard syntax */ } body { padding: 0; margin: 0; } #notfound { position: relative; height: 90%; width: 100%; } #notfound .notfound { position: absolute; left: 50%; top: 50%; -webkit-transform: translate(-50%, -50%); -ms-transform: translate(-50%, -50%); transform: translate(-50%, -50%); } .notfound { max-width: 550px; width: 100%; line-height: 1.4; text-align: center; } .notfound .notfound-404 { position: relative; height: 200px; margin: 0px auto 20px; z-index: -1; } .notfound .notfound-404 h1 { font-family: 'Palatino', serif; font-size: 236px; font-weight: 200; margin: 0px; color: #211b19; text-transform: uppercase; position: absolute; left: 50%; top: 50%; -webkit-transform: translate(-50%, -50%); -ms-transform: translate(-50%, -50%); transform: translate(-50%, -50%); } .notfound .notfound-404 h2 { font-family: 'Palatino', serif; font-size: 36px; font-weight: 400; text-transform: uppercase; color: #211b19; background: #fff; padding-top: 20px; padding-bottom: 10px; margin: auto; display: inline-block; position: absolute; width: 120%; left: 50%; top: 50%; -webkit-transform: translate(-50%, -80%); -ms-transform: translate(-50%, -80%); transform: translate(-50%, -80%); } .notfound a { font-family: 'Palatino', serif; text-decoration: none; text-transform: uppercase; padding: 13px 23px; font-size: 18px; -webkit-transition: 0.2s all; transition: 0.2s all; display: inline-block; margin: 0 4px; padding: 4px 12px; background-color: #fff; border-bottom: 4px solid #b21c1c; border-radius: 4px; font-size: 14px; color: #fff; background-color: #e20b0b; text-align: center; cursor: pointer; } .notfound a:hover { background-color: #f21a1a; } @media only screen and (max-width: 600px) { .notfound .notfound-404 h1 { font-size: 120px; } .notfound .notfound-404 h2 { font-size: 18px; padding-top: 10px; padding-bottom: 5px; } } 404 - Page not found 404 🙃 Page is not found. Take me home!","tags":""},{"title":"","url":"/search/index.html","text":"","tags":""}]}